{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "831fb6c8",
   "metadata": {},
   "source": [
    "# rush-py\n",
    "\n",
    "> Python SDK for the QDX Quantum Chemistry workflow management system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79209088",
   "metadata": {},
   "source": [
    "Below we'll walk through the process of building and running a drug discovery workflow, where we prepare a protein and ligand for molecular dynamics simulation, run the molecular dynamics, perform a quantum lattice interaction energy calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5d03a3",
   "metadata": {},
   "source": [
    "First, install the following modules via pip - we require Python > 3.10\n",
    "```\n",
    "pip install rush-py pdb-tools\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f654b72",
   "metadata": {},
   "source": [
    "# 0) Setup\n",
    "This is where we prepare the rush client, directories, and input data we'll be working with"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1c8faf",
   "metadata": {},
   "source": [
    "## 0.0) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0f8880",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "from pdbtools import pdb_fetch, pdb_delhetatm, pdb_selchain, pdb_rplresname, pdb_keepcoord, pdb_selresname\n",
    "import requests\n",
    "import py3Dmol\n",
    "\n",
    "import rush"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe7cbe3",
   "metadata": {},
   "source": [
    "## 0.1) Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9503e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set our token - ensure you have exported RUSH_TOKEN in your shell; or just replace the os.getenv with your token\n",
    "TOKEN = os.getenv(\"RUSH_TOKEN\")\n",
    "# You might have a custom deployment url, by default it will use https://tengu.qdx.ai\n",
    "URL = os.getenv(\"RUSH_URL\") or \"https://tengu.qdx.ai\"\n",
    "# These env variables will be read by default, so you can skip this step in future"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67206d0d",
   "metadata": {},
   "source": [
    "## 0.2) Configuration\n",
    "Lets set some global variables that define our project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e248baa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our project information\n",
    "DESCRIPTION = \"rush-py demo notebook\"\n",
    "TAGS = [\"qdx\", \"rush-py-v2\", \"tutorial\", \"cdk2\"]\n",
    "WORK_DIR = Path.home() / \"qdx\" / \"rush-py-demo\"\n",
    "# Set our inputs\n",
    "SYSTEM_PDB_PATH = WORK_DIR / \"test.pdb\"\n",
    "PROTEIN_PDB_PATH = WORK_DIR / \"test_P.pdb\"\n",
    "LIGAND_SMILES_STR = (\n",
    "    \"c1nc(c2c(n1)n(cn2)[C@H]3[C@@H]([C@@H]([C@H](O3)CO[P@@](=O)(O)O[P@](=O)(O)OP(=O)(O)O)O)O)N\"\n",
    ")\n",
    "LIGAND_PDB_PATH = WORK_DIR / \"test_L.pdb\"\n",
    "# where want our jobs to run\n",
    "TARGET = \"NIX_SSH_3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2884437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "if WORK_DIR.exists():\n",
    "    client = rush.Provider(workspace=WORK_DIR)\n",
    "    await client.nuke(remote=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e7d70c",
   "metadata": {},
   "source": [
    "Ensure your workdir exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1c6518",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(WORK_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040844bd",
   "metadata": {},
   "source": [
    "## 0.2) Build your client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b5f39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get our client, for calling modules and using the rush API\n",
    "# Note, access_token and url are optional, if you have set the env variables RUSH_TOKEN and RUSH_URL\n",
    "# Workspace sets the location where we will store our session history file and module lock file\n",
    "# By using the `build_provider_with_functions` method, we will also build helper functions calling each module\n",
    "client = await rush.build_provider_with_functions(\n",
    "    access_token=TOKEN, url=URL, workspace=WORK_DIR, batch_tags=TAGS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2ae403",
   "metadata": {},
   "source": [
    "## 0.3) Input selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa43a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch datafiles\n",
    "complex = list(pdb_fetch.fetch_structure(\"1B39\"))\n",
    "protein = pdb_delhetatm.remove_hetatm(pdb_selchain.select_chain(complex, \"A\"))\n",
    "# select the ATP residue\n",
    "ligand = pdb_selresname.filter_residue_by_name(complex, \"ATP\")\n",
    "# we require ligands to be labelled as UNL\n",
    "ligand = pdb_rplresname.rename_residues(ligand, \"ATP\", \"UNL\")\n",
    "# we don't want to repeat all of the remark / metadata that is already in the protein\n",
    "ligand = pdb_keepcoord.keep_coordinates(ligand)\n",
    "# write our files to the locations defined in the config block\n",
    "with open(SYSTEM_PDB_PATH, \"w\") as f:\n",
    "    for l in complex:\n",
    "        f.write(str(l))\n",
    "with open(PROTEIN_PDB_PATH, \"w\") as f:\n",
    "    for l in protein:\n",
    "        f.write(str(l))\n",
    "with open(LIGAND_PDB_PATH, \"w\") as f:\n",
    "    for l in ligand:\n",
    "        f.write(str(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc724d8",
   "metadata": {},
   "source": [
    "## 0.4) View rush modules\n",
    "Rush modules are \"functions\" that perform various computational chemistry tasks can be run on HPC infrastructure. We maintain multiple versions of these functions so that your scripts will stay stable over upgrades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b729073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get our latest modules as a dict[module_name, module_path]\n",
    "# If a lock file exists, load it so that the run is reproducable\n",
    "# This will be done automatically if you use the `build_provider_with_functions` method\n",
    "modules = await client.get_latest_module_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d800c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "github:talo/tengu-prelude/efc6d8b3a8cc342cd9866d037abb77dac40a4d56#hermes_energy\n"
     ]
    }
   ],
   "source": [
    "module_name = \"hermes_energy\"\n",
    "module_path = modules[module_name]\n",
    "print(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca66469",
   "metadata": {},
   "source": [
    "  - `module_name` is a descriptive string and indicates the \"function\" the module is calling;\n",
    "  - `module_path` is a versioned rush \"endpoint\" for a module accessible via the client.\n",
    "\n",
    "Using the same `module_path` string across multiple runs provides reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe78f3e9",
   "metadata": {},
   "source": [
    "## 0.5) Use module functions\n",
    "Next, we'll use helper functions for the modules that we've fetched"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48eb5825",
   "metadata": {},
   "source": [
    "If we have built a provider with functions, we can use the python `help()` function to describe their usage.\n",
    "\n",
    "The QDX Type Description is a standard type definition across multiple programing languages to assist in interoperablility.\n",
    "@ indicates that the type is stored in a file, which will be synced to cloud storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24dea72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function convert in module rush.provider:\n",
      "\n",
      "async convert(*args: [list[typing.Union[str, ~T]], <class 'pathlib.Path'>], target: rush.graphql_client.enums.ModuleInstanceTarget | None = <ModuleInstanceTarget.NIX: 'NIX'>, resources: rush.graphql_client.input_types.ModuleInstanceResourcesInput | None = ModuleInstanceResourcesInput(gpus=0, gpu_mem=None, gpu_mem_units=None, cpus=None, nodes=None, mem=None, mem_units=None, storage=10, storage_units=<MemUnits.MB: 'MB'>, walltime=None, storage_mounts=None), tags: list[str] | None = None, restore: bool | None = None) -> [<class 'pathlib.Path'>]\n",
      "    Convert biomolecular and chemical file formats to the QDX file format. Supports PDB and SDF\n",
      "    \n",
      "    Module version: github:talo/tengu-prelude/efc6d8b3a8cc342cd9866d037abb77dac40a4d56#convert\n",
      "    \n",
      "    QDX Type Description:\n",
      "    \n",
      "        format: PDB|SDF;\n",
      "    \n",
      "        input: @bytes \n",
      "    \n",
      "    ->\n",
      "    \n",
      "        output: @[Conformer]\n",
      "    \n",
      "    \n",
      "    \n",
      "    :param format: the format of the input file\n",
      "    :param input: the input file\n",
      "    :return output: the output conformers\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(client.convert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14eaf8f1",
   "metadata": {},
   "source": [
    "# 1) Running Rush Modules\n",
    "Below we'll call modules using the functions created on the client.\n",
    "\n",
    "The parameters to a rush module function would look like the following\n",
    "\n",
    "  - `*args`: The values or ids passed to the :\n",
    "    1. For @Objects -  A `pathlib.Path` or a file-like object like `BufferedReader`, `FileIO`, `StringIO` etc.:\n",
    "         Loads the data in the file as an argument.\n",
    "         **NOTE**: The uploaded value isn't just the string of the file,\n",
    "         so don't pass the string directly; pass the path or wrap in StringIO.\n",
    "    2. An rush `Provider.Argument` or `ArgId` returned by a previous call to a rush module via `client.[some_module_name]()`:\n",
    "         The `ArgId` type wraps data for use within rush. It may refer to an object already\n",
    "         uploaded to rush storage, such as outputs of other run calls.\n",
    "         See below for more details. It's easier to understand when you see an example.\n",
    "    3. A parameter, i.e. a value of any other type, including `None`:\n",
    "         Ensure the values match what is outlined in the *args list\n",
    "  - **kwargs\n",
    "      - `target`: The machine we want to run on (eg. `NIX_SSH` for a cluster, `GADI` for a supercomputer).\n",
    "      - `resources`: The resources to use on the target. The most commonly provided being `{\"gpus\": n, \"storage\": storage_in_units, \"storage_units\": \"B\" | \"MB\" | \"GB\", \"walltime\": mins}`.\n",
    "      - `tags`: Tags to associate with our run, so we can easily look up our runs. They will be populated by the `batch_tags` passed to                 the cleint on constructionby default\n",
    "      - `restore`: If this is set to True - the function will check if a single module_instance exists for the same version of the                          function with the same tags, and return that instead of re-running.\n",
    "\n",
    "The return value is a list of `Provider.Arguments`. You can wait for them to resolve by calling `await your_argument.get()`, or pass the arguments directly to subsequent functions, which will cause Rush to do the waiting for you.\n",
    "\n",
    "You can see the status of all the the jobs submitted for your workspace or session by going `client.status()`\n",
    "\n",
    "We will now demonstrate how this works in action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f33f669",
   "metadata": {},
   "source": [
    "## 1.1) Input Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8feb11c",
   "metadata": {},
   "source": [
    "### 1.1.1) Prep the protein\n",
    "First we will run the protein preparation routine (using pdbfixer internally) to prepare the protein for molecular dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0071c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function prepare_protein in module rush.provider:\n",
      "\n",
      "async prepare_protein(*args: [<class 'pathlib.Path'>], target: rush.graphql_client.enums.ModuleInstanceTarget | None = <ModuleInstanceTarget.NIX_SSH_2: 'NIX_SSH_2'>, resources: rush.graphql_client.input_types.ModuleInstanceResourcesInput | None = ModuleInstanceResourcesInput(gpus=1, gpu_mem=None, gpu_mem_units=None, cpus=None, nodes=None, mem=None, mem_units=None, storage=138, storage_units=<MemUnits.MB: 'MB'>, walltime=None, storage_mounts=None), tags: list[str] | None = None, restore: bool | None = None) -> [<class 'pathlib.Path'>, <class 'pathlib.Path'>]\n",
      "    Prepare a PDB for downstream tasks: protonate, fill missing atoms, etc.\n",
      "    \n",
      "    Module version: github:talo/pdb2pqr/ff5abe87af13f31478ede490d37468a536621e9c#prepare_protein_tengu\n",
      "    \n",
      "    QDX Type Description:\n",
      "    \n",
      "        input_pdb: @bytes \n",
      "    \n",
      "    ->\n",
      "    \n",
      "        output_qdxf: @[Conformer];\n",
      "    \n",
      "        output_pdb: @bytes\n",
      "    \n",
      "    \n",
      "    \n",
      "    :param input_pdb: An input protein as a file: one PDB file\n",
      "    :return output_qdxf: An output protein a vec: one qdxf per model in pdb\n",
      "    :return output_pdb: An output protein as a file: one PDB file\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we can check the arguments and outputs for prepare_protein with help()\n",
    "help(client.prepare_protein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bc8e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:30:32.714308 | Running protein prep!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Arg(id=06f12e87-6545-4092-92ef-f67a1e8cf1de, value=None)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we run the function, it will return a Provider.Arg which you can use to fetch the results\n",
    "# We set restore = True so that we can restore a previous run to the same path with the same tags\n",
    "(prepared_protein_qdxf, prepared_protein_pdb) = await client.prepare_protein(\n",
    "    PROTEIN_PDB_PATH, target=TARGET, restore=True\n",
    ")\n",
    "print(f\"{datetime.now().time()} | Running protein prep!\")\n",
    "prepared_protein_qdxf  # this initially only have the id of your result, we will show how to fetch the actual value later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84aeb6c3",
   "metadata": {},
   "source": [
    "### 1.1.2) Checking results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01edef35",
   "metadata": {},
   "source": [
    "#### 1.1.2.1) Run statuses\n",
    "This will show the status of all of your runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be093c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'9e3b4032-e241-4675-8c16-fe56b139ce7e': (<ModuleInstanceStatus.RESOLVING: 'RESOLVING'>,\n",
       "  'prepare_protein',\n",
       "  1)}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await client.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5481a32",
   "metadata": {},
   "source": [
    "#### 1.1.2.2) Run Logs\n",
    "If any of our runs fail, we can check their logs with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd88d859",
   "metadata": {},
   "outputs": [],
   "source": [
    "for instance_id, (status, name, count) in (await client.status()).items():\n",
    "    if status.value == \"FAILED\":\n",
    "        async for log_page in client.logs(instance_id, \"stderr\"):\n",
    "            for log in log_page:\n",
    "                print(log)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc03dfb",
   "metadata": {},
   "source": [
    "#### 1.1.2.3) Run Values\n",
    "This will return the \"value\" of the output from the function - for files you will recieve a url that you can download, otherwise you will recieve them as python types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796b786f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-24 10:30:32,940 - rush - INFO - Argument 22c9ff71-3b4e-4aef-8407-655b9575f830 is now ModuleInstanceStatus.RESOLVING\n",
      "2024-01-24 10:30:34,063 - rush - INFO - Argument 22c9ff71-3b4e-4aef-8407-655b9575f830 is now ModuleInstanceStatus.ADMITTED\n",
      "2024-01-24 10:30:48,298 - rush - INFO - Argument 22c9ff71-3b4e-4aef-8407-655b9575f830 is now ModuleInstanceStatus.DISPATCHED\n",
      "2024-01-24 10:30:53,778 - rush - INFO - Argument 22c9ff71-3b4e-4aef-8407-655b9575f830 is now ModuleInstanceStatus.RUNNING\n",
      "2024-01-24 10:31:04,999 - rush - INFO - Argument 22c9ff71-3b4e-4aef-8407-655b9575f830 is now ModuleInstanceStatus.AWAITING_UPLOAD\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'url': 'https://storage.googleapis.com/qdx-store/a58eb07f-c59d-48d8-994b-d24873bf408d?x-goog-signature=81fad85408de4143b6e2ae2ddfd5cb2e0ee2f69020952714d0e63f12d71611cdc28fa53e9fc63f09dc8e336563c1db78c62f426be6bff87a656a90a82b4e0c3c52513d2cd9409ae1efffe3bef368a20638d4afa63d6872694b05f4b6fb896fc94634c066857e6ddb1cfe222bca6b2360d61f5770050169c9e46dbae116f984193a4678b33243564ed184a36ab538bb94dc9dbb3fe5233df6d99ab0060b0c3a719d9c4f195ec082c8ea178f2e711154587c2314e34b9854f33543c33912db27e1eced0ca68817865dd82181494088bd62410974a853ed4be437b3384d688a4b942388eb71c3f794a34b87836f60210c3ecbb01625e71b0535ff1b62d3b4946f7d&x-goog-algorithm=GOOG4-RSA-SHA256&x-goog-credential=qdx-store-user%40humming-bird-321603.iam.gserviceaccount.com%2F20240124%2Fasia-southeast1%2Fstorage%2Fgoog4_request&x-goog-date=20240124T023143Z&x-goog-expires=3600&x-goog-signedheaders=host'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await prepared_protein_pdb.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd4eafa",
   "metadata": {},
   "source": [
    "#### 1.1.2.3) Downloads\n",
    "We provide a utility to download files into your workspace, you can either provide a filename, which will be saved in `workspace/objects/[filename]`, or you can provide your own filepath which the client will use as-is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bd745b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    await prepared_protein_pdb.download(filename=\"01_prepared_protein.pdb\")\n",
    "except FileExistsError:\n",
    "    # we will raise an error if you try to overwrite an existing file, you can force the file to overwrite\n",
    "    # by passing an absolute filepath instead\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3845f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMARK   1 PDBFIXER FROM: /home/ubuntu/.cache/tengu_store/run/9e3b4032-e241-4675-8c16-fe56b139ce7e/.tmp/m2_protein.pdb\n",
      " ...\n"
     ]
    }
   ],
   "source": [
    "# we can read our prepared protein pdb like this\n",
    "with open(client.workspace / \"objects\" / \"01_prepared_protein.pdb\", \"r\") as f:\n",
    "    print(f.readline(), \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834d3248",
   "metadata": {},
   "source": [
    "You should visualize your prepared protein to spot check any incorrectly transformed residues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6f418e",
   "metadata": {},
   "outputs": [],
   "source": [
    "view = py3Dmol.view()\n",
    "with open(client.workspace / \"objects\" / \"01_prepared_protein.pdb\", \"r\") as f:\n",
    "    view.addModel(f.read(), \"pdb\")\n",
    "    view.setStyle({\"cartoon\": {\"color\": \"spectrum\"}})\n",
    "    view.zoomTo()\n",
    "    # view.show() # we can't have the widget in the readme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92391435",
   "metadata": {},
   "source": [
    "### 1.1.3) Prep the ligand\n",
    "Next we will prepare the ligand (using gypsum_dl internally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208d04f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function prepare_ligand in module rush.provider:\n",
      "\n",
      "async prepare_ligand(*args: [<class 'str'>, <class 'pathlib.Path'>, dict[str, ~T]], target: rush.graphql_client.enums.ModuleInstanceTarget | None = <ModuleInstanceTarget.NIX_SSH_3: 'NIX_SSH_3'>, resources: rush.graphql_client.input_types.ModuleInstanceResourcesInput | None = ModuleInstanceResourcesInput(gpus=1, gpu_mem=None, gpu_mem_units=None, cpus=None, nodes=None, mem=None, mem_units=None, storage=18, storage_units=<MemUnits.MB: 'MB'>, walltime=None, storage_mounts=None), tags: list[str] | None = None, restore: bool | None = None) -> [<class 'pathlib.Path'>, <class 'pathlib.Path'>]\n",
      "    Prepare ligand for sim. or quantum energy calc. using gypsum_dl\n",
      "    \n",
      "    Module version: github:talo/gypsum_dl/04acd1852cb3e2c8d0347e15763926fdf9a93a5d#prepare_ligand_tengu\n",
      "    \n",
      "    QDX Type Description:\n",
      "    \n",
      "        in: string;\n",
      "    \n",
      "        in: @bytes;\n",
      "    \n",
      "        in: {\n",
      "    \n",
      "        job_manager:string,\n",
      "    \n",
      "        let_tautomers_change_chirality:bool,\n",
      "    \n",
      "        max_ph:f32,\n",
      "    \n",
      "        max_variants_per_compound:i32,\n",
      "    \n",
      "        min_ph:f32,\n",
      "    \n",
      "        num_processors:i32,\n",
      "    \n",
      "        output_folder:string,\n",
      "    \n",
      "        pka_precision:f32,\n",
      "    \n",
      "        separate_output_files:bool,\n",
      "    \n",
      "        skip_adding_hydrogen:bool,\n",
      "    \n",
      "        skip_alternate_ring_conformations:bool,\n",
      "    \n",
      "        skip_enumerate_chiral_mol:bool,\n",
      "    \n",
      "        skip_enumerate_double_bonds:bool,\n",
      "    \n",
      "        skip_making_tautomers:bool,\n",
      "    \n",
      "        skip_optimize_geometry:bool,\n",
      "    \n",
      "        source:string,\n",
      "    \n",
      "        thoroughness:i32,\n",
      "    \n",
      "        use_durrant_lab_filters:bool\n",
      "    \n",
      "        } \n",
      "    \n",
      "    ->\n",
      "    \n",
      "        out: @bytes;\n",
      "    \n",
      "        out: @bytesPrepare ligand for sim. or quantum energy calc. using gypsum_dl.\n",
      "    \n",
      "    \n",
      "    Inputs:\n",
      "        - An input molecule as a SMILES string\n",
      "        - The same input molecule as a PDB file\n",
      "        - A json file representing any other options to pass; see gypsum_dl docs for details\n",
      "    \n",
      "    \n",
      "    Outputs:\n",
      "        - A pdb file containing the prepared version of the molecule, ready for downstream use\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we can check the inputs for prepare_ligand with help()\n",
    "help(client.prepare_ligand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa15399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:31:49.690332 | Running ligand prep!\n"
     ]
    }
   ],
   "source": [
    "ligand_prep_config = {\n",
    "    \"source\": \"\",\n",
    "    \"output_folder\": \"./\",\n",
    "    \"job_manager\": \"multiprocessing\",\n",
    "    \"num_processors\": -1,\n",
    "    \"max_variants_per_compound\": 1,\n",
    "    \"thoroughness\": 3,\n",
    "    \"separate_output_files\": True,\n",
    "    \"min_ph\": 6.4,\n",
    "    \"max_ph\": 8.4,\n",
    "    \"pka_precision\": 1.0,\n",
    "    \"skip_optimize_geometry\": True,\n",
    "    \"skip_alternate_ring_conformations\": True,\n",
    "    \"skip_adding_hydrogen\": False,\n",
    "    \"skip_making_tautomers\": True,\n",
    "    \"skip_enumerate_chiral_mol\": True,\n",
    "    \"skip_enumerate_double_bonds\": True,\n",
    "    \"let_tautomers_change_chirality\": False,\n",
    "    \"use_durrant_lab_filters\": True,\n",
    "}\n",
    "(prepared_ligand_pdb, prepared_ligand_sdf) = await client.prepare_ligand(\n",
    "    LIGAND_SMILES_STR,\n",
    "    LIGAND_PDB_PATH,\n",
    "    ligand_prep_config,\n",
    "    target=TARGET,\n",
    "    restore=True,\n",
    ")\n",
    "print(f\"{datetime.now().time()} | Running ligand prep!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71bb0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'98cf5555-0c4c-4432-bcfc-298a94f6f899': (<ModuleInstanceStatus.RESOLVING: 'RESOLVING'>,\n",
       "  'prepare_ligand',\n",
       "  1),\n",
       " '9e3b4032-e241-4675-8c16-fe56b139ce7e': (<ModuleInstanceStatus.COMPLETED: 'COMPLETED'>,\n",
       "  'prepare_protein',\n",
       "  1)}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can check the status again\n",
    "await client.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe0cbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-24 10:31:49,926 - rush - INFO - Argument 3f04bb48-cc3e-4164-afce-632cdcd50abb is now ModuleInstanceStatus.RESOLVING\n",
      "2024-01-24 10:31:53,280 - rush - INFO - Argument 3f04bb48-cc3e-4164-afce-632cdcd50abb is now ModuleInstanceStatus.ADMITTED\n",
      "2024-01-24 10:32:05,305 - rush - INFO - Argument 3f04bb48-cc3e-4164-afce-632cdcd50abb is now ModuleInstanceStatus.DISPATCHED\n",
      "2024-01-24 10:32:11,870 - rush - INFO - Argument 3f04bb48-cc3e-4164-afce-632cdcd50abb is now ModuleInstanceStatus.AWAITING_UPLOAD\n",
      "10:32:48.809029 | Downloaded prepped ligand!\n"
     ]
    }
   ],
   "source": [
    "# we can download our outputs\n",
    "try:\n",
    "    await prepared_ligand_pdb.download(filename=\"01_prepped_ligand.pdb\")\n",
    "    await prepared_ligand_sdf.download(filename=\"01_prepped_ligand.sdf\")\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "print(f\"{datetime.now().time()} | Downloaded prepped ligand!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b231ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "untitled_0_molnum_0\n",
      "      RDKit          3D\n",
      " ...\n"
     ]
    }
   ],
   "source": [
    "# we can read our outputs\n",
    "with open(client.workspace / \"objects\" / \"01_prepped_ligand.sdf\", \"r\") as f:\n",
    "    print(f.readline(), f.readline(), \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304dfa05",
   "metadata": {},
   "source": [
    "## 1.2) Run GROMACS (module: gmx_rush / gmx_rush_pdb)\n",
    "Next we will run a molecular dynamics simulation on our protein and ligand, using gromacs (gmx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95f1ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function gmx in module rush.provider:\n",
      "\n",
      "async gmx(*args: [typing.Optional[~T], typing.Optional[~T], typing.Optional[~T], dict[str, ~T]], target: rush.graphql_client.enums.ModuleInstanceTarget | None = <ModuleInstanceTarget.NIX_SSH: 'NIX_SSH'>, resources: rush.graphql_client.input_types.ModuleInstanceResourcesInput | None = ModuleInstanceResourcesInput(gpus=4, gpu_mem=None, gpu_mem_units=None, cpus=None, nodes=None, mem=None, mem_units=None, storage=1034, storage_units=<MemUnits.MB: 'MB'>, walltime=None, storage_mounts=None), tags: list[str] | None = None, restore: bool | None = None) -> [<class 'pathlib.Path'>, <class 'pathlib.Path'>, <class 'pathlib.Path'>, <class 'pathlib.Path'>, <class 'pathlib.Path'>, <class 'pathlib.Path'>, <class 'pathlib.Path'>, <class 'pathlib.Path'>]\n",
      "    Runs a molecular dynamics simluation using GROMACS from either protein, ligand pdbs or conformers as inputs\n",
      "    \n",
      "    Module version: github:talo/gmx_tengu_support/6bd881c6bb32ac85ab9cb9c95d2b16676cc72b7a#gmx_tengu\n",
      "    \n",
      "    QDX Type Description:\n",
      "    \n",
      "        conformer: @Conformer?;\n",
      "    \n",
      "        protein: @bytes?;\n",
      "    \n",
      "        ligand: @bytes?;\n",
      "    \n",
      "        gmx-config: {\n",
      "    \n",
      "        frame_sel:{\n",
      "    \n",
      "        end_frame:u32,\n",
      "    \n",
      "        interval:u32,\n",
      "    \n",
      "        start_frame:u32\n",
      "    \n",
      "        }?,\n",
      "    \n",
      "        ligand_charge:i8?,\n",
      "    \n",
      "        num_gpus:u8,\n",
      "    \n",
      "        num_replicas:u8?,\n",
      "    \n",
      "        params_overrides:{\n",
      "    \n",
      "        em:{\n",
      "    \n",
      "        coulombtype:string?,\n",
      "    \n",
      "        cutoff_scheme:string?,\n",
      "    \n",
      "        emstep:f64?,\n",
      "    \n",
      "        emtol:f64?,\n",
      "    \n",
      "        integrator:string?,\n",
      "    \n",
      "        ns_type:string?,\n",
      "    \n",
      "        nsteps:i32?,\n",
      "    \n",
      "        nstlist:i32?,\n",
      "    \n",
      "        pbc:string?,\n",
      "    \n",
      "        rcoulomb:f64?,\n",
      "    \n",
      "        rlist:f64?,\n",
      "    \n",
      "        rvdw:f64?\n",
      "    \n",
      "        }?,\n",
      "    \n",
      "        ions:{\n",
      "    \n",
      "        coulombtype:string?,\n",
      "    \n",
      "        cutoff_scheme:string?,\n",
      "    \n",
      "        emstep:f64?,\n",
      "    \n",
      "        emtol:f64?,\n",
      "    \n",
      "        integrator:string?,\n",
      "    \n",
      "        nsteps:i32?,\n",
      "    \n",
      "        nstlist:i32?,\n",
      "    \n",
      "        pbc:string?,\n",
      "    \n",
      "        rcoulomb:f64?,\n",
      "    \n",
      "        rlist:f64?,\n",
      "    \n",
      "        rvdw:f64?\n",
      "    \n",
      "        }?,\n",
      "    \n",
      "        md:{\n",
      "    \n",
      "        compressibility:f64?,\n",
      "    \n",
      "        constraint_algorithm:string?,\n",
      "    \n",
      "        constraints:string?,\n",
      "    \n",
      "        continuation:string?,\n",
      "    \n",
      "        coulombtype:string?,\n",
      "    \n",
      "        cutoff_scheme:string?,\n",
      "    \n",
      "        disp_corr:string?,\n",
      "    \n",
      "        dt:f64?,\n",
      "    \n",
      "        fourierspacing:f64?,\n",
      "    \n",
      "        gen_vel:string?,\n",
      "    \n",
      "        integrator:string?,\n",
      "    \n",
      "        lincs_iter:i32?,\n",
      "    \n",
      "        lincs_order:i32?,\n",
      "    \n",
      "        ns_type:string?,\n",
      "    \n",
      "        nstenergy:i32?,\n",
      "    \n",
      "        nsteps:i32?,\n",
      "    \n",
      "        nstlist:i32?,\n",
      "    \n",
      "        nstlog:i32?,\n",
      "    \n",
      "        nstxout_compressed:i32?,\n",
      "    \n",
      "        pbc:string?,\n",
      "    \n",
      "        pcoupl:string?,\n",
      "    \n",
      "        pcoupltype:string?,\n",
      "    \n",
      "        pme_order:i32?,\n",
      "    \n",
      "        rcoulomb:f64?,\n",
      "    \n",
      "        ref_p:f64?,\n",
      "    \n",
      "        ref_t:[f64]?,\n",
      "    \n",
      "        rlist:f64?,\n",
      "    \n",
      "        rvdw:f64?,\n",
      "    \n",
      "        rvdw_switch:f64?,\n",
      "    \n",
      "        tau_p:f64?,\n",
      "    \n",
      "        tau_t:[f64]?,\n",
      "    \n",
      "        tc_grps:string?,\n",
      "    \n",
      "        tcoupl:string?,\n",
      "    \n",
      "        vdw_modifier:string?,\n",
      "    \n",
      "        vdwtype:string?\n",
      "    \n",
      "        }?,\n",
      "    \n",
      "        npt:{\n",
      "    \n",
      "        compressibility:f64?,\n",
      "    \n",
      "        constraint_algorithm:string?,\n",
      "    \n",
      "        constraints:string?,\n",
      "    \n",
      "        continuation:string?,\n",
      "    \n",
      "        coulombtype:string?,\n",
      "    \n",
      "        cutoff_scheme:string?,\n",
      "    \n",
      "        define:string?,\n",
      "    \n",
      "        disp_corr:string?,\n",
      "    \n",
      "        dt:f64?,\n",
      "    \n",
      "        fourierspacing:f64?,\n",
      "    \n",
      "        gen_vel:string?,\n",
      "    \n",
      "        integrator:string?,\n",
      "    \n",
      "        lincs_iter:i32?,\n",
      "    \n",
      "        lincs_order:i32?,\n",
      "    \n",
      "        ns_type:string?,\n",
      "    \n",
      "        nstenergy:i32?,\n",
      "    \n",
      "        nsteps:i32?,\n",
      "    \n",
      "        nstlist:i32?,\n",
      "    \n",
      "        nstlog:i32?,\n",
      "    \n",
      "        nstxout_compressed:i32?,\n",
      "    \n",
      "        pbc:string?,\n",
      "    \n",
      "        pcoupl:string?,\n",
      "    \n",
      "        pcoupltype:string?,\n",
      "    \n",
      "        pme_order:i32?,\n",
      "    \n",
      "        rcoulomb:f64?,\n",
      "    \n",
      "        ref_p:f64?,\n",
      "    \n",
      "        ref_t:[f64]?,\n",
      "    \n",
      "        refcoord_scaling:string?,\n",
      "    \n",
      "        rlist:f64?,\n",
      "    \n",
      "        rvdw:f64?,\n",
      "    \n",
      "        rvdw_switch:f64?,\n",
      "    \n",
      "        tau_p:f64?,\n",
      "    \n",
      "        tau_t:[f64]?,\n",
      "    \n",
      "        tc_grps:string?,\n",
      "    \n",
      "        tcoupl:string?,\n",
      "    \n",
      "        vdw_modifier:string?,\n",
      "    \n",
      "        vdwtype:string?\n",
      "    \n",
      "        }?,\n",
      "    \n",
      "        nvt:{\n",
      "    \n",
      "        constraint_algorithm:string?,\n",
      "    \n",
      "        constraints:string?,\n",
      "    \n",
      "        continuation:string?,\n",
      "    \n",
      "        coulombtype:string?,\n",
      "    \n",
      "        cutoff_scheme:string?,\n",
      "    \n",
      "        define:string?,\n",
      "    \n",
      "        disp_corr:string?,\n",
      "    \n",
      "        dt:f64?,\n",
      "    \n",
      "        fourierspacing:f64?,\n",
      "    \n",
      "        gen_seed:i32?,\n",
      "    \n",
      "        gen_temp:f64?,\n",
      "    \n",
      "        gen_vel:string?,\n",
      "    \n",
      "        integrator:string?,\n",
      "    \n",
      "        lincs_iter:i32?,\n",
      "    \n",
      "        lincs_order:i32?,\n",
      "    \n",
      "        ns_type:string?,\n",
      "    \n",
      "        nstenergy:i32?,\n",
      "    \n",
      "        nsteps:i32?,\n",
      "    \n",
      "        nstlist:i32?,\n",
      "    \n",
      "        nstlog:i32?,\n",
      "    \n",
      "        nstxout_compressed:i32?,\n",
      "    \n",
      "        pbc:string?,\n",
      "    \n",
      "        pcoupl:string?,\n",
      "    \n",
      "        pme_order:i32?,\n",
      "    \n",
      "        rcoulomb:f64?,\n",
      "    \n",
      "        ref_t:[f64]?,\n",
      "    \n",
      "        rlist:f64?,\n",
      "    \n",
      "        rvdw:f64?,\n",
      "    \n",
      "        rvdw_switch:f64?,\n",
      "    \n",
      "        tau_t:[f64]?,\n",
      "    \n",
      "        tc_grps:string?,\n",
      "    \n",
      "        tcoupl:string?,\n",
      "    \n",
      "        vdw_modifier:string?,\n",
      "    \n",
      "        vdwtype:string?\n",
      "    \n",
      "        }?\n",
      "    \n",
      "        }?,\n",
      "    \n",
      "        save_wets:bool\n",
      "    \n",
      "        } \n",
      "    \n",
      "    ->\n",
      "    \n",
      "        output_gros: @bytes;\n",
      "    \n",
      "        outputs_tpr: @bytes;\n",
      "    \n",
      "        outputs_tops: @bytes;\n",
      "    \n",
      "        output_logs: @bytes;\n",
      "    \n",
      "        outputs_md.ligand_in.dry.xtc: @bytes;\n",
      "    \n",
      "        outputs_md.ligand_in.dry.pdb: @bytes;\n",
      "    \n",
      "        index.ligand_in.ndx: @bytes;\n",
      "    \n",
      "        outputs_md.ligand_in.xtc: @bytes\n",
      "    \n",
      "    \n",
      "    \n",
      "    :param conformer: Optional Conformer in QDXF format; must provide either this argument, or the Protein PDB argument .\n",
      "    :param protein: Protein PDB file; provide this if no Conformer qdxf is provided.\n",
      "    :param ligand: Ligand PDB file\n",
      "    :param gmx-config: Configuration record\n",
      "    :return output_gros: Intermediate and final structure files through the simulation\n",
      "    :return outputs_tpr: .tpr files of the production MD runs\n",
      "    :return outputs_tops: .top files, and relevant .itp files used in the simulation.\n",
      "    :return output_logs: Logs of the production MD runs\n",
      "    :return outputs_md.ligand_in.dry.xtc: Trajectories, i.e., without water molecules, from the production MD runs\n",
      "    :return outputs_md.ligand_in.dry.pdb: Outputs of select_frame, pdb frames without water\n",
      "    :return index.ligand_in.ndx: Index file\n",
      "    :return outputs_md.ligand_in.xtc: Wet trajectories, i.e., with water molecules, from the production MD runs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(client.gmx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fd0b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:32:48.888017 | Running GROMACS simulation!\n"
     ]
    }
   ],
   "source": [
    "gmx_config = {\n",
    "    \"param_overrides\": {\n",
    "        \"md\": {\"nsteps\", \"5000\"},\n",
    "        \"em\": {\"nsteps\", \"1000\"},\n",
    "        \"nvt\": {\"nsteps\", \"1000\"},\n",
    "        \"npt\": {\"nsteps\", \"1000\"},\n",
    "        \"ions\": {},\n",
    "    },\n",
    "    \"num_gpus\": 0,\n",
    "    \"num_replicas\": 1,\n",
    "    \"ligand_charge\": None,\n",
    "    \"save_wets\": False,\n",
    "    \"frame_sel\": {\n",
    "        \"start_frame\": 1,\n",
    "        \"end_frame\": 10,\n",
    "        \"interval\": 2,\n",
    "    },\n",
    "}\n",
    "# we pass the outputs from our prior runs directly, instead of their values, to prevent them from being re-uploaded\n",
    "gmx_results = await client.gmx(\n",
    "    None,\n",
    "    prepared_protein_pdb,\n",
    "    prepared_ligand_pdb,\n",
    "    gmx_config,\n",
    "    resources={\"gpus\": 0, \"storage\": 1, \"storage_units\": \"GB\", \"cpus\": 48, \"walltime\": 60},\n",
    "    target=TARGET,\n",
    ")\n",
    "print(f\"{datetime.now().time()} | Running GROMACS simulation!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0945349c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'18704b66-f74d-49f0-83ba-b1964c30339b': (<ModuleInstanceStatus.RESOLVING: 'RESOLVING'>,\n",
       "  'gmx',\n",
       "  1),\n",
       " '98cf5555-0c4c-4432-bcfc-298a94f6f899': (<ModuleInstanceStatus.COMPLETED: 'COMPLETED'>,\n",
       "  'prepare_ligand',\n",
       "  1),\n",
       " '9e3b4032-e241-4675-8c16-fe56b139ce7e': (<ModuleInstanceStatus.COMPLETED: 'COMPLETED'>,\n",
       "  'prepare_protein',\n",
       "  1)}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can check the status again\n",
    "await client.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07581d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching gmx results\n",
      "2024-01-24 10:32:49,109 - rush - INFO - Argument 7bc36817-f050-4c7d-8dac-7b70461d69b4 is now ModuleInstanceStatus.RESOLVING\n",
      "2024-01-24 10:32:50,229 - rush - INFO - Argument 7bc36817-f050-4c7d-8dac-7b70461d69b4 is now ModuleInstanceStatus.ADMITTED\n",
      "2024-01-24 10:33:01,203 - rush - INFO - Argument 7bc36817-f050-4c7d-8dac-7b70461d69b4 is now ModuleInstanceStatus.DISPATCHED\n",
      "2024-01-24 10:33:06,757 - rush - INFO - Argument 7bc36817-f050-4c7d-8dac-7b70461d69b4 is now ModuleInstanceStatus.RUNNING\n",
      "2024-01-24 10:50:47,692 - rush - INFO - Argument 7bc36817-f050-4c7d-8dac-7b70461d69b4 is now ModuleInstanceStatus.AWAITING_UPLOAD\n",
      "10:51:37.800711 | Downloaded GROMACS output!\n"
     ]
    }
   ],
   "source": [
    "print(\"Fetching gmx results\")\n",
    "try:\n",
    "    await gmx_results[5].download(filename=\"02_gmx_dry_frames.tar.gz\")\n",
    "    await gmx_results[0].download(filename=\"02_gmx_lig_gro.tar.gz\")\n",
    "\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "print(f\"{datetime.now().time()} | Downloaded GROMACS output!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6ca38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the \"dry\" (i.e. non-solvated) pdb frames we asked for\n",
    "with tarfile.open(client.workspace / \"objects\" / \"02_gmx_dry_frames.tar.gz\", \"r\") as tf:\n",
    "    selected_frame_pdbs = [\n",
    "        tf.extractfile(member).read() for member in tf if \"pdb\" in member.name and member.isfile()\n",
    "    ]\n",
    "    for i, frame in enumerate(selected_frame_pdbs):\n",
    "        with open(client.workspace / \"objects\" / f\"02_gmx_output_frame_{i}.pdb\", \"w\") as pf:\n",
    "            print(frame.decode(\"utf-8\"), file=pf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c546832a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the ligand.gro file\n",
    "with tarfile.open(client.workspace / \"objects\" / \"02_gmx_lig_gro.tar.gz\", \"r\") as tf:\n",
    "    gro = [tf.extractfile(member).read() for member in tf if \"md.ligand\" in member.name][0]\n",
    "    with open(client.workspace / \"objects\" / f\"02_gmx_lig.gro\", \"w\") as pf:\n",
    "        print(gro.decode(\"utf-8\"), file=pf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494623a4",
   "metadata": {},
   "source": [
    "## 1.3) Run MM-PBSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6ce874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function gmx_mmpbsa in module rush.provider:\n",
      "\n",
      "async gmx_mmpbsa(*args: [<class 'pathlib.Path'>, <class 'pathlib.Path'>, <class 'pathlib.Path'>, <class 'pathlib.Path'>, dict[str, ~T]], target: rush.graphql_client.enums.ModuleInstanceTarget | None = <ModuleInstanceTarget.NIX_SSH_3: 'NIX_SSH_3'>, resources: rush.graphql_client.input_types.ModuleInstanceResourcesInput | None = ModuleInstanceResourcesInput(gpus=0, gpu_mem=None, gpu_mem_units=None, cpus=None, nodes=None, mem=None, mem_units=None, storage=10, storage_units=<MemUnits.MB: 'MB'>, walltime=None, storage_mounts=None), tags: list[str] | None = None, restore: bool | None = None) -> [<class 'pathlib.Path'>]\n",
      "    Run gmx mmpbsa on the outputs of a gmx simulation \n",
      "    \n",
      "    Module version: github:talo/gmx_tengu_support/6bd881c6bb32ac85ab9cb9c95d2b16676cc72b7a#gmx_mmpbsa_tengu\n",
      "    \n",
      "    QDX Type Description:\n",
      "    \n",
      "        tpr_tar_gz: @bytes;\n",
      "    \n",
      "        dry_xtc_tar_gz: @bytes;\n",
      "    \n",
      "        index_file: @bytes;\n",
      "    \n",
      "        topol_file: @bytes;\n",
      "    \n",
      "        mmpbsa_config: {\n",
      "    \n",
      "        end_frame:u64,\n",
      "    \n",
      "        ie_segment:u32?,\n",
      "    \n",
      "        interaction_entropy:bool?,\n",
      "    \n",
      "        interval:u32?,\n",
      "    \n",
      "        num_cpus:u32,\n",
      "    \n",
      "        start_frame:u64,\n",
      "    \n",
      "        with_gb:bool?\n",
      "    \n",
      "        } \n",
      "    \n",
      "    ->\n",
      "    \n",
      "        output: @bytes\n",
      "    \n",
      "    \n",
      "    \n",
      "    :param tpr_tar_gz: Compressed GROMACS output folder\n",
      "    :param dry_xtc_tar_gz: Compressed GROMACS output folder\n",
      "    :param index_file: Compressed GROMACS output folder\n",
      "    :param topol_file: Compressed GROMACS output folder\n",
      "    :param mmpbsa_config: Configuration record for mmpbsa:\n",
      "        start_frame: Frame to start with\n",
      "        end_frame: Frame to end with\n",
      "        num_cpus: Number of CPUs to use - cannot be larger than the number of frames\n",
      "        interaction_entropy: Calculate interaction entropy\n",
      "        \n",
      "    :return output: Compressed mmpbsa output folder\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(client.gmx_mmpbsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2398f262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:51:37.932948 | Running GROMACS MM-PBSA calculation!\n"
     ]
    }
   ],
   "source": [
    "mmpbsa_config = {\n",
    "    \"start_frame\": 1,\n",
    "    \"end_frame\": 2,\n",
    "    \"num_cpus\": 1,  # cannot be greater than number of frames\n",
    "}\n",
    "(mmpbsa_result_tar,) = await client.gmx_mmpbsa(\n",
    "    gmx_results[1],\n",
    "    gmx_results[4],\n",
    "    gmx_results[6],\n",
    "    gmx_results[2],\n",
    "    mmpbsa_config,\n",
    "    resources=rush.Resources(storage=100, storage_units=\"MB\", cpus=42, gpus=0, walltime=60, mem=1024 * 42),\n",
    "    target=\"GADI\",\n",
    ")\n",
    "print(f\"{datetime.now().time()} | Running GROMACS MM-PBSA calculation!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08edf820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching gmx_mmpbsa results\n",
      "2024-01-24 10:51:38,107 - rush - INFO - Argument f4f59056-8bf7-490c-b905-d0c4fac1b254 is now ModuleInstanceStatus.RESOLVING\n",
      "2024-01-24 10:55:22,967 - rush - INFO - Argument f4f59056-8bf7-490c-b905-d0c4fac1b254 is now ModuleInstanceStatus.ADMITTED\n",
      "2024-01-24 10:55:53,845 - rush - INFO - Argument f4f59056-8bf7-490c-b905-d0c4fac1b254 is now ModuleInstanceStatus.DISPATCHED\n",
      "2024-01-24 10:55:58,254 - rush - INFO - Argument f4f59056-8bf7-490c-b905-d0c4fac1b254 is now ModuleInstanceStatus.QUEUED\n"
     ]
    }
   ],
   "source": [
    "print(\"Fetching gmx_mmpbsa results\")\n",
    "try:\n",
    "    await mmpbsa_result_tar.download(filename=\"04_gmx_mmpbsa_run_folder.tar.gz\")\n",
    "except FileExistsError:\n",
    "    pass\n",
    "print(f\"{datetime.now().time()} | Downloaded MM-PBSA results!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
