{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b3c1b49",
   "metadata": {},
   "source": [
    "# rush-py\n",
    "\n",
    "> Python SDK for the QDX Quantum Chemistry workflow management system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6163a1",
   "metadata": {},
   "source": [
    "# Quickstart\n",
    "This document will walk through executing jobs on the Rush platform. For a comprehensive guide on the concepts and constructing a full workflow, see the [full rush-py explainer](./Tutorials/full-rush-py-explainer.ipynb) document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2ed102",
   "metadata": {},
   "source": [
    "First, install the following modules via pip - we require Python > 3.10\n",
    "```\n",
    "pip install rush-py pdb-tools\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde61f2d",
   "metadata": {},
   "source": [
    "# 0) Setup\n",
    "This is where we prepare the rush client, directories, and input data we'll be working with"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3255512",
   "metadata": {},
   "source": [
    "## 0.0) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cdaade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "from pdbtools import pdb_fetch, pdb_delhetatm, pdb_selchain, pdb_rplresname, pdb_keepcoord, pdb_selresname\n",
    "import requests\n",
    "import py3Dmol\n",
    "\n",
    "import rush"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeff251d",
   "metadata": {},
   "source": [
    "## 0.1) Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4388592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set our token - ensure you have exported RUSH_TOKEN in your shell; or just replace the os.getenv with your token\n",
    "TOKEN = os.getenv(\"RUSH_TOKEN\")\n",
    "# You might have a custom deployment url, by default it will use https://tengu.qdx.ai\n",
    "URL = os.getenv(\"RUSH_URL\") or \"https://tengu.qdx.ai\"\n",
    "# These env variables will be read by default, so you can skip this step in future"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3346c341",
   "metadata": {},
   "source": [
    "## 0.2) Configuration\n",
    "Lets set some global variables that define our project, these are not required, but are good practice to help organize the jobs that will be persisted under your account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8153cd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you create a unique set of tags for each run.\n",
    "# Good practice is to have at least each of the experiment name and system name as a tag.\n",
    "EXPERIMENT = \"tengu-py-v2-quickstart\"\n",
    "SYSTEM = \"cdk2\"\n",
    "TAGS = [\"qdx\", EXPERIMENT, SYSTEM]\n",
    "# Set our inputs\n",
    "WORK_DIR = Path.home() / \"qdx\" / EXPERIMENT\n",
    "PROTEIN_PDB_PATH = WORK_DIR / \"test_P.pdb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baa8f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "if WORK_DIR.exists():\n",
    "    client = rush.Provider(workspace=WORK_DIR)\n",
    "    await client.nuke(remote=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c1b8b1",
   "metadata": {},
   "source": [
    "Ensure your workdir exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03360185",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(WORK_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3288a6",
   "metadata": {},
   "source": [
    "## 0.2) Build your client\n",
    "Get our client, for calling modules and using the Rush API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eef5d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note, access_token and url are optional, if you have set the env variables RUSH_TOKEN and RUSH_URL\n",
    "# Workspace sets the location where we will store our session history file and module lock file\n",
    "# By using the `build_provider_with_functions` method, we will also build helper functions calling each module\n",
    "client = await rush.build_provider_with_functions(\n",
    "    access_token=TOKEN, url=URL, workspace=WORK_DIR, batch_tags=TAGS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebee89a7",
   "metadata": {},
   "source": [
    "## 0.3) Input selection\n",
    "Fetch data files from RCSB to pass as input to the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002a0188",
   "metadata": {},
   "outputs": [],
   "source": [
    "complex = list(pdb_fetch.fetch_structure(\"1B39\"))\n",
    "protein = pdb_delhetatm.remove_hetatm(pdb_selchain.select_chain(complex, \"A\"))\n",
    "with open(PROTEIN_PDB_PATH, \"w\") as f:\n",
    "    for l in protein:\n",
    "        f.write(str(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb29959d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function convert in module rush.provider:\n",
      "\n",
      "async convert(*args: [list[typing.Union[str, ~T]], <class 'pathlib.Path'>], target: rush.graphql_client.enums.ModuleInstanceTarget | None = <ModuleInstanceTarget.NIX: 'NIX'>, resources: rush.graphql_client.input_types.ModuleInstanceResourcesInput | None = ModuleInstanceResourcesInput(gpus=0, gpu_mem=None, gpu_mem_units=None, cpus=None, nodes=None, mem=None, mem_units=None, storage=10, storage_units=<MemUnits.MB: 'MB'>, walltime=None, storage_mounts=None), tags: list[str] | None = None, restore: bool | None = None) -> [<class 'pathlib.Path'>]\n",
      "    Convert biomolecular and chemical file formats to the QDX file format. Supports PDB and SDF\n",
      "    \n",
      "    Module version: github:talo/tengu-prelude/efc6d8b3a8cc342cd9866d037abb77dac40a4d56#convert\n",
      "    \n",
      "    QDX Type Description:\n",
      "    \n",
      "        format: PDB|SDF;\n",
      "    \n",
      "        input: @bytes \n",
      "    \n",
      "    ->\n",
      "    \n",
      "        output: @[Conformer]\n",
      "    \n",
      "    \n",
      "    \n",
      "    :param format: the format of the input file\n",
      "    :param input: the input file\n",
      "    :return output: the output conformers\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(client.convert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf07726",
   "metadata": {},
   "source": [
    "# 1) Running Rush Modules\n",
    "You can view which modules are available, alongside their documentation, in the [API Dodumentation](./api/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522fc95b",
   "metadata": {},
   "source": [
    "## 1.1) Prep the protein\n",
    "First we will run the protein preparation routine (using pdbfixer internally) to prepare the protein for molecular dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805cfd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function prepare_protein in module rush.provider:\n",
      "\n",
      "async prepare_protein(*args: [<class 'pathlib.Path'>], target: rush.graphql_client.enums.ModuleInstanceTarget | None = <ModuleInstanceTarget.NIX_SSH_2: 'NIX_SSH_2'>, resources: rush.graphql_client.input_types.ModuleInstanceResourcesInput | None = ModuleInstanceResourcesInput(gpus=1, gpu_mem=None, gpu_mem_units=None, cpus=None, nodes=None, mem=None, mem_units=None, storage=138, storage_units=<MemUnits.MB: 'MB'>, walltime=None, storage_mounts=None), tags: list[str] | None = None, restore: bool | None = None) -> [<class 'pathlib.Path'>, <class 'pathlib.Path'>]\n",
      "    Prepare a PDB for downstream tasks: protonate, fill missing atoms, etc.\n",
      "    \n",
      "    Module version: github:talo/pdb2pqr/ff5abe87af13f31478ede490d37468a536621e9c#prepare_protein_tengu\n",
      "    \n",
      "    QDX Type Description:\n",
      "    \n",
      "        input_pdb: @bytes \n",
      "    \n",
      "    ->\n",
      "    \n",
      "        output_qdxf: @[Conformer];\n",
      "    \n",
      "        output_pdb: @bytes\n",
      "    \n",
      "    \n",
      "    \n",
      "    :param input_pdb: An input protein as a file: one PDB file\n",
      "    :return output_qdxf: An output protein a vec: one qdxf per model in pdb\n",
      "    :return output_pdb: An output protein as a file: one PDB file\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we can check the arguments and outputs for prepare_protein with help()\n",
    "help(client.prepare_protein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc1fb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:52:21.654575 | Running protein prep!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Arg(id=bd64bd44-118f-435b-be7a-64d25f76c5dc, value=None)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we run the function, it will return a Provider.Arg which you can use to fetch the results\n",
    "# We set restore = True so that we can restore a previous run to the same path with the same tags\n",
    "(prepared_protein_qdxf, prepared_protein_pdb) = await client.prepare_protein(\n",
    "    PROTEIN_PDB_PATH\n",
    ")\n",
    "print(f\"{datetime.now().time()} | Running protein prep!\")\n",
    "prepared_protein_qdxf  # this initially only have the id of your result, we will show how to fetch the actual value later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a9f6ab",
   "metadata": {},
   "source": [
    "## 1.3) Run statuses\n",
    "This will show the status of all of your runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cbd627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'687a9367-9866-4999-9586-7480ba581b54': (<ModuleInstanceStatus.RESOLVING: 'RESOLVING'>,\n",
       "  'prepare_protein',\n",
       "  1)}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await client.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17e51bf",
   "metadata": {},
   "source": [
    "## 1.4) Run Values\n",
    "This will return the \"value\" of the output from the function - for files you will recieve a url that you can download, otherwise you will recieve them as python types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89440719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4852"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein_qdxf_value = await prepared_protein_qdxf.get()\n",
    "len(protein_qdxf_value[0][\"topology\"][\"symbols\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560eb2ae",
   "metadata": {},
   "source": [
    "## 1.5) Downloads\n",
    "We provide a utility to download files into your workspace, you can either provide a filename, which will be saved in `workspace/objects/[filename]`, or you can provide your own filepath which the client will use as-is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a877d9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    await prepared_protein_pdb.download(filename=\"01_prepared_protein.pdb\")\n",
    "except FileExistsError:\n",
    "    # we will raise an error if you try to overwrite an existing file, you can force the file to overwrite\n",
    "    # by passing an absolute filepath instead\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ca488f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMARK   1 PDBFIXER FROM: /home/ubuntu/.cache/tengu_store/run/687a9367-9866-4999-9586-7480ba581b54/.tmp/m2_protein.pdb\n",
      " ...\n"
     ]
    }
   ],
   "source": [
    "# we can read our prepared protein pdb like this\n",
    "with open(client.workspace / \"objects\" / \"01_prepared_protein.pdb\", \"r\") as f:\n",
    "    print(f.readline(), \"...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
