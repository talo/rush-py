[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "rush-py",
    "section": "",
    "text": "First, install the following modules via the command-line (we require Python ≥ 3.11):\npip install rush-py\n\n\nYou can submit protocols for benchmarking using the rex workflow scripting language.\n\nfrom rush import build_blocking_provider\n\n\nclient = build_blocking_provider(\n    access_token=PUT_YOUR_TOKEN_HERE\n    # for example, if your token is 00000000-dddd-cccc-0000-11111111,\n    # then you should put access_token=\"00000000-dddd-cccc-0000-11111111\"\n    # (including the double quotes)\n)\n\n2025-02-05 18:16:46,831 - rush - INFO - Not restoring by default via env\n\n\n\nbenchmark = client.benchmark(name=\"OpenFF Protein-Ligand Binding Benchmark\")\n\n\n\nlet\n    auto3d = \\smi -&gt; map to_data (get 0 (auto3d_rex_s default_runspec_gpu { k = 1 } [smi])),\n    \n    p2rank = \\prot_conf -&gt; p2rank_rex_s default_runspec {} prot_conf,\n\n    gnina = \\prot_conf -&gt; \\bounding_box -&gt; \\smol_conf -&gt;\n        get 0 (get 0 (gnina_rex_s default_runspec_gpu {} [prot_conf] [bounding_box] smol_conf [])),\n\nin\n\\input -&gt;\n    let\n        protein = load (id (get 0 input)) \"ProteinConformer\",\n        smol_id = id (get 1 input),\n        smiles = smi (load smol_id \"Smol\"),\n\n        structure = load (structure_id protein) \"Structure\",\n        trc = [\n            topology structure,\n            residues structure,\n            chains structure\n        ],\n\n        bounding_box = get 0 (get 0 (p2rank trc)),\n\n        smol_structure = auto3d smiles,\n\n        docked_structure = gnina trc bounding_box [smol_structure],\n\n        min_affinity = list_min (map (get \"affinity\") (get \"scores\" docked_structure)),\n\n        binding_affinity = BindingAffinity {\n            affinity = min_affinity,\n            affinity_metric = \"kcal/mol\",\n            protein_id = protein_id protein,\n            smol_id = smol_id,\n            metadata = Metadata {\n                name = \"binding affinity for smol and protein\",\n                description = none,\n                tags = []\n            }\n        }\n    in\n        [BenchmarkArg {\n            entity = \"BindingAffinity\",\n            id = save binding_affinity\n        }]\n\n\n\nsubmission = client.run_benchmark(\n    benchmark.id, \n    rex_code_above, \n    \"simple submission\", \n    sample=0.2\n)\n\nView your submission at https://rush.cloud/project/f18faf61-5556-4a78-b983-e85a3c975fa6/runs?selectedRunId=ef3ecd6d-e1f8-43ee-a0cf-730a6be54eff",
    "crumbs": [
      "API Docs",
      "rush-py"
    ]
  },
  {
    "objectID": "index.html#running-benchmarks-of-computational-chemistry-workflows",
    "href": "index.html#running-benchmarks-of-computational-chemistry-workflows",
    "title": "rush-py",
    "section": "",
    "text": "You can submit protocols for benchmarking using the rex workflow scripting language.\n\nfrom rush import build_blocking_provider\n\n\nclient = build_blocking_provider(\n    access_token=PUT_YOUR_TOKEN_HERE\n    # for example, if your token is 00000000-dddd-cccc-0000-11111111,\n    # then you should put access_token=\"00000000-dddd-cccc-0000-11111111\"\n    # (including the double quotes)\n)\n\n2025-02-05 18:16:46,831 - rush - INFO - Not restoring by default via env\n\n\n\nbenchmark = client.benchmark(name=\"OpenFF Protein-Ligand Binding Benchmark\")\n\n\n\nlet\n    auto3d = \\smi -&gt; map to_data (get 0 (auto3d_rex_s default_runspec_gpu { k = 1 } [smi])),\n    \n    p2rank = \\prot_conf -&gt; p2rank_rex_s default_runspec {} prot_conf,\n\n    gnina = \\prot_conf -&gt; \\bounding_box -&gt; \\smol_conf -&gt;\n        get 0 (get 0 (gnina_rex_s default_runspec_gpu {} [prot_conf] [bounding_box] smol_conf [])),\n\nin\n\\input -&gt;\n    let\n        protein = load (id (get 0 input)) \"ProteinConformer\",\n        smol_id = id (get 1 input),\n        smiles = smi (load smol_id \"Smol\"),\n\n        structure = load (structure_id protein) \"Structure\",\n        trc = [\n            topology structure,\n            residues structure,\n            chains structure\n        ],\n\n        bounding_box = get 0 (get 0 (p2rank trc)),\n\n        smol_structure = auto3d smiles,\n\n        docked_structure = gnina trc bounding_box [smol_structure],\n\n        min_affinity = list_min (map (get \"affinity\") (get \"scores\" docked_structure)),\n\n        binding_affinity = BindingAffinity {\n            affinity = min_affinity,\n            affinity_metric = \"kcal/mol\",\n            protein_id = protein_id protein,\n            smol_id = smol_id,\n            metadata = Metadata {\n                name = \"binding affinity for smol and protein\",\n                description = none,\n                tags = []\n            }\n        }\n    in\n        [BenchmarkArg {\n            entity = \"BindingAffinity\",\n            id = save binding_affinity\n        }]\n\n\n\nsubmission = client.run_benchmark(\n    benchmark.id, \n    rex_code_above, \n    \"simple submission\", \n    sample=0.2\n)\n\nView your submission at https://rush.cloud/project/f18faf61-5556-4a78-b983-e85a3c975fa6/runs?selectedRunId=ef3ecd6d-e1f8-43ee-a0cf-730a6be54eff",
    "crumbs": [
      "API Docs",
      "rush-py"
    ]
  },
  {
    "objectID": "Modules/p2rank.html",
    "href": "Modules/p2rank.html",
    "title": "P2Rank",
    "section": "",
    "text": "The module takes an dict of module-specific options and a TRCObject representing a protein. It predicts binding sites and returns a list where each element specifies and provides info about a predicted binding site. That info includes a bounding box around the binding site, the surface atoms for the binding site, and scoring info about it.\n\n\n\noptions: dict\nprotein_trc: TRCObject\n\n\n\n\n\n[(BindingSiteBoundingBox, [uint], dict)] where the fields, in order, are:\n\nbinding_site_bounding_box: BindingSiteBoundingBox representing the predicted binding site on the protein\nsurface_atoms: [uint] listing the atom indices in the output Topology binding site’s surface\np2rank_score: dict\n\n\nThe p2rank_score dictionary fields are as follows:\n\n\n\nName\nType\nDescription\n\n\n\n\nrank\nint\n1st is best, and worse down the line\n\n\nscore\nfloat\nthe score of this configuration\n\n\nprobability\nfloat\nthe probability of seeing this configuration\n\n\n\n\n\n\nThere are no exposed options yet! Please just pass the empty dictionary for now.\n\n\n\nlet\n    p2rank = \\protein_trc -&gt;  p2rank_rex_s default_runspec {} protein_trc,\nin\n    \\protein_trc -&gt;\n        let\n            result                    = p2rank protein_trc\n            binding_site_bounding_box = get 0 result\n            surface_atoms             = get 1 result\n            score                     = get 2 result\n        in\n            {- do something with the result here :) -}",
    "crumbs": [
      "API Docs",
      "Modules",
      "P2Rank"
    ]
  },
  {
    "objectID": "Modules/p2rank.html#module-specification",
    "href": "Modules/p2rank.html#module-specification",
    "title": "P2Rank",
    "section": "",
    "text": "The module takes an dict of module-specific options and a TRCObject representing a protein. It predicts binding sites and returns a list where each element specifies and provides info about a predicted binding site. That info includes a bounding box around the binding site, the surface atoms for the binding site, and scoring info about it.\n\n\n\noptions: dict\nprotein_trc: TRCObject\n\n\n\n\n\n[(BindingSiteBoundingBox, [uint], dict)] where the fields, in order, are:\n\nbinding_site_bounding_box: BindingSiteBoundingBox representing the predicted binding site on the protein\nsurface_atoms: [uint] listing the atom indices in the output Topology binding site’s surface\np2rank_score: dict\n\n\nThe p2rank_score dictionary fields are as follows:\n\n\n\nName\nType\nDescription\n\n\n\n\nrank\nint\n1st is best, and worse down the line\n\n\nscore\nfloat\nthe score of this configuration\n\n\nprobability\nfloat\nthe probability of seeing this configuration\n\n\n\n\n\n\nThere are no exposed options yet! Please just pass the empty dictionary for now.\n\n\n\nlet\n    p2rank = \\protein_trc -&gt;  p2rank_rex_s default_runspec {} protein_trc,\nin\n    \\protein_trc -&gt;\n        let\n            result                    = p2rank protein_trc\n            binding_site_bounding_box = get 0 result\n            surface_atoms             = get 1 result\n            score                     = get 2 result\n        in\n            {- do something with the result here :) -}",
    "crumbs": [
      "API Docs",
      "Modules",
      "P2Rank"
    ]
  },
  {
    "objectID": "Modules/gnina.html",
    "href": "Modules/gnina.html",
    "title": "GNINA",
    "section": "",
    "text": "Inputs\n\noptions: dict\nprotein_trcs: [TRC], the proteins to dock the smols onto.\ndocking_sites: [GninaDockingSite], 1-to-1 with the proteins, specifying the docking site location on the protein.\nsmol_trcs: [TRC], to dock all against each protein.\nligand_libraries: LigandLibrary which provides a more storage-efficient way of passing very many smols for docking.\n\nThe docking_sites dictionary can either take the form of an “autobox”:\n\n\n\n\n\n\n\n\n\nName\nType\nDefault\nDescription\n\n\n\n\nautobox_ligand\nTR\nn/a\nThe reference ligand used to automatically determine the docking site box.\n\n\nautobox_add\nOption&lt;float&gt;\nnone\nThe additional padding distance to add around the autobox ligand.\n\n\n\nor the form of a BindingSiteBoundingBox.\n\n\nOutputs\n\nbinding_site_results: dict\nThe binding_site_results dictionary fields are as follows:\n\n\n\n\nName\nType\nDescription\n\n\n\n\npose_trcs\n[TR]\nA list of TRs representing the docking poses.\n\n\nscores\ndict\nA list of scoring results for each docking pose.\n\n\n\nand the scores dictionary fields are as follows:\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nmode\nint\nThe pose mode number for this scoring result.\n\n\ncnn_score\nfloat\nThe CNN-based scoring value for the pose.\n\n\ncnn_affinity\nfloat\nThe CNN-predicted binding affinity for the pose.\n\n\naffinity\nfloat\nThe calculated binding affinity for the pose.\n\n\n\n\n\nOptions\n\n\n\n\n\n\n\n\n\nName\nType\nDefault\nDescription\n\n\n\n\nminimize\nOption&lt;bool&gt;\nnone\nWhether to minimize the energy of the final pose.\n\n\nexhaustiveness\nOption&lt;uint&gt;\nnone\nThe search extent for the docking algorithm.\n\n\nnum_modes\nOption&lt;uint&gt;\nnone\nThe number of dock poses to report.\n\n\ncovalent_rec_atom\nOption&lt;str&gt;\nnone\nThe receptor atom that the ligand is bound to, specified as either “chain:resnum:atom_name” or x,y,z cartesian coordinates.\n\n\ncovalent_lig_atom_pattern\nOption&lt;str&gt;\nnone\nThe SMARTS expression for the ligand atom that binds to the receptor.\n\n\ncovalent_lig_atom_position\nOption&lt;str&gt;\nnone\nThe position of ligand in x,y,z cartesian coordinates.\n\n\ncovalent_optimize_lig\nOption&lt;bool&gt;\nnone\nWhether to optimize the covalent complex of ligand and residue with UFF.\n\n\n\n\n\nFunction usage\nlet\n    gnina = \\protein_trc -&gt; \\bounding_box -&gt; \\smol_tr -&gt;\n        get 0 (get 0 (\n            gnina_rex_s runspec {} [protein_trc] [bounding_box] [smol_tr] []\n        ))\nin\n    \\protein_trc -&gt; \\bounding_box -&gt; \\smol_tr -&gt;\n        let\n            result = gnina protein_trc bounding_box smol_tr\n        in\n            list_min (map (get \"affinity\") (get \"scores\" result)) {- get the best affinity value of all the docked poses -}",
    "crumbs": [
      "API Docs",
      "Modules",
      "GNINA"
    ]
  },
  {
    "objectID": "Modules/intro.html",
    "href": "Modules/intro.html",
    "title": "Introduction",
    "section": "",
    "text": "The way modules are designed in terms of their inputs and outputs follows a standardized structure.\n\n\nThe function for calling the module is named based on the software it will run followed by _rex, e.g. auto3d_rex. With this function you have the maximal ability to configure, run, and obtain output from the module as desired. This function returns a Result, and in the case of an err it will provide a string about what might have gone wrong.\nBut, there’s a simplified version of each module function with the extension _rex_s (s for “simplified), e.g. auto3d_rex_s. This automatically removes Result for you so you get immediate access to the module’s actual outputs. Most of the time you’ll want to use this, and this is what our examples will use.\n\n\n\n\nThe first argument is the RunSpec for the module;\nThe second argument is the configuration dict;\nFrom there, any additional parameters specific to the module will follow.\n\n\n\n\n\nEach module outputs a Result (automatically unwrapped) providing whatever output data specific to the module.\n\nHere’s a simple example:\n{- Returns (Object&lt;Topology&gt;, Object&lt;Residues&gt;, Object&lt;Chains&gt;) -}\nauto3d_rex_s default_runspec_gpu { k = 1, optimizing_engine = \"ANI2xt\" } [\"CC(=O)OC1=CC=CC=C1C(=O)O\"] \n\nThe default_runspec_gpu is a built-in shorthand to obtain a runspec that allows us to use one GPU;\n{ k = 1, optimizing_engine = \"ANI2xt\" } is our config dictionary;\nand [\"CC(=O)OC1=CC=CC=C1C(=O)O\"] is our module-specific argument, in this case, a list of SMILES strings.\n\nIn this case, auto3d is software that will generate a 3D conformation for each SMILES string in a list of them. See the auto3d page for more details: here, we’re just exhibiting the structure. All modules work in a similar way. For any module that takes a list of inputs, it’s even smart enough to return the sole output by itself rather than in a list with one element, for your convenience!",
    "crumbs": [
      "API Docs",
      "Modules",
      "Introduction"
    ]
  },
  {
    "objectID": "Modules/intro.html#common-module-design",
    "href": "Modules/intro.html#common-module-design",
    "title": "Introduction",
    "section": "",
    "text": "The way modules are designed in terms of their inputs and outputs follows a standardized structure.\n\n\nThe function for calling the module is named based on the software it will run followed by _rex, e.g. auto3d_rex. With this function you have the maximal ability to configure, run, and obtain output from the module as desired. This function returns a Result, and in the case of an err it will provide a string about what might have gone wrong.\nBut, there’s a simplified version of each module function with the extension _rex_s (s for “simplified), e.g. auto3d_rex_s. This automatically removes Result for you so you get immediate access to the module’s actual outputs. Most of the time you’ll want to use this, and this is what our examples will use.\n\n\n\n\nThe first argument is the RunSpec for the module;\nThe second argument is the configuration dict;\nFrom there, any additional parameters specific to the module will follow.\n\n\n\n\n\nEach module outputs a Result (automatically unwrapped) providing whatever output data specific to the module.\n\nHere’s a simple example:\n{- Returns (Object&lt;Topology&gt;, Object&lt;Residues&gt;, Object&lt;Chains&gt;) -}\nauto3d_rex_s default_runspec_gpu { k = 1, optimizing_engine = \"ANI2xt\" } [\"CC(=O)OC1=CC=CC=C1C(=O)O\"] \n\nThe default_runspec_gpu is a built-in shorthand to obtain a runspec that allows us to use one GPU;\n{ k = 1, optimizing_engine = \"ANI2xt\" } is our config dictionary;\nand [\"CC(=O)OC1=CC=CC=C1C(=O)O\"] is our module-specific argument, in this case, a list of SMILES strings.\n\nIn this case, auto3d is software that will generate a 3D conformation for each SMILES string in a list of them. See the auto3d page for more details: here, we’re just exhibiting the structure. All modules work in a similar way. For any module that takes a list of inputs, it’s even smart enough to return the sole output by itself rather than in a list with one element, for your convenience!",
    "crumbs": [
      "API Docs",
      "Modules",
      "Introduction"
    ]
  },
  {
    "objectID": "Modules/intro.html#using-objects-from-modules",
    "href": "Modules/intro.html#using-objects-from-modules",
    "title": "Introduction",
    "section": "Using Objects from Modules",
    "text": "Using Objects from Modules\nWhen we obtain an Object from a module, we have to do one extra step before we can use it as the input in another module. Technically, the data in that object needs to be repackaged, and there’s a rust built-in called to_data that does just this. We’re working on eliminating the need for this, but for now, make sure to call to_data on any Object types returned by modules, like so:\nlet\n    auto3d = \\smi -&gt;  {- write a simplified helper function for the auto3d module -}\n        map to_data ( {- map to_data over the tuple of Objects -}\n            get 0 (   {- get the first output conformer -}\n                auto3d_rex_s default_runspec_gpu { k = 1, optimizing_engine = \"ANI2xt\" } [smi]\n            )\n        )\nin\n    auto3d \"CC(=O)OC1=CC=CC=C1C(=O)O\" {- outputs the smol conformer TR, ready to be passed to another module  -}\nWe can use this let [...] in [...] syntax to make helper functions for calling modules that eliminate the repetitive bits. This helper function calls auto3d with a pre-specified runspec and config dict and allows us to easily pass just one SMILES string to the module, automatically “listifying” it and directly returning the sole output conformer.\n\nTRCObject\nWe’ve designed all modules to have a separate Object for each part of a TRC, so the common type is (Object&lt;Topology&gt;, Object&lt;Residues&gt;, Object&lt;Chains&gt;). This is pretty verbose, so in this documentation we’ll refer to this type with the shorthand TRCObject.",
    "crumbs": [
      "API Docs",
      "Modules",
      "Introduction"
    ]
  },
  {
    "objectID": "Modules/intro.html#using-modules-in-your-benchmark",
    "href": "Modules/intro.html#using-modules-in-your-benchmark",
    "title": "Introduction",
    "section": "Using Modules in your Benchmark",
    "text": "Using Modules in your Benchmark\nModules will make up the bulk of your rex scripts that you submit. In each module’s documentation page, you’ll find simple examples of how to call the modules, and in the full example on the rush-py documentation homepage you can see how to chain the modules together to do more meaningful tasks.",
    "crumbs": [
      "API Docs",
      "Modules",
      "Introduction"
    ]
  },
  {
    "objectID": "Hackathon/benchmarks.html",
    "href": "Hackathon/benchmarks.html",
    "title": "Benchmarks",
    "section": "",
    "text": "When submitting a benchmark, you must submit a lambda function that expects exactly one input. This input is a list: the first element is a ProteinConformer and the second a Smol\n\n\n(λ input → \n    let        \n        {- protein conformers are a single physical shape of a protein -}\n        protein_conformer = load (id (get 0 input)) \"ProteinConformer\",\n\n        {- protein is a description of the protein e.g. its amino acid sequence -}\n        protein = load (protein_id protein_conformer) \"Protein\",\n\n        {- smol is a description of a small molecule e.g. its SMILES string -}\n        smol = load (id (get 1 input)) \"Smol\",\n\n        {- TODO(you): this is where you need to write code that predicts the binding affinity -}\n        affinity = 0.5\n\n    in\n        {- the output must be a list with exactly one element: our binding affinity prediction for this input -}\n        [BenchmarkArg {\n            entity = \"BindingAffinity\", \n            id = save (BindingAffinity {\n                affinity = affinity,\n                affinity_metric = \"kcal/mol\",\n                protein_id = id protein,\n                smol_id = id smol,\n                metadata = Metadata {\n                    name = \"binding affinity for smol and protein\",\n                    description = none,\n                    tags = []\n                }\n            })\n        }]\n)",
    "crumbs": [
      "API Docs",
      "Hackathon",
      "Benchmarks"
    ]
  },
  {
    "objectID": "Hackathon/entities.html",
    "href": "Hackathon/entities.html",
    "title": "Rush Entities",
    "section": "",
    "text": "Rush workflows operate on entities, which are typed objects that serve as the core data structures in Rush.\nThese entities represent key biological and chemical data, ranging from molecular structures to docking results, and are passed between functions in rex expressions.\nThe table below summarizes the key entities used in Rush.\nAll entity contains internal attributes that define its structure and behavior. By default, all Rush entities will have the attributes id, metadata, project_id and account_id automatically generated. The rest of the attributes are decribed below as follows.",
    "crumbs": [
      "API Docs",
      "Hackathon",
      "Rush Entities"
    ]
  },
  {
    "objectID": "Hackathon/entities.html#entities-attributes",
    "href": "Hackathon/entities.html#entities-attributes",
    "title": "Rush Entities",
    "section": "Entities’ attributes",
    "text": "Entities’ attributes\n\nSmol\nA small molecule representation, containing SMILES, InChI, and associated metadata.\n\n\n\n\n\n\n\n\nAttribute\nType\nDescription\n\n\n\n\nsmi\nOption&lt;str&gt;\nThe SMILES str representation, if available.\n\n\ninchi\nOption&lt;str&gt;\nThe InChI str representation, if available.\n\n\ndata_blocks\nOption&lt;list&lt;(str, str)&gt;&gt;\nAdditional data blocks (e.g., molecular properties, annotations).\n\n\n\n\nExample Usage\nsmiles = smi (load smol_id \"Smol\")\n\n\n\nProtein\nRepresents a biological protein sequence, including metadata and external references.\n\n\n\n\n\n\n\n\nAttribute\nType\nDescription\n\n\n\n\nid\nstr\nUnique identifier for the protein.\n\n\nmetadata\nMetadata\nContains metadata about the protein.\n\n\nsequence\nstr\nThe amino acid sequence of the protein.\n\n\nuniprot_id\nOption&lt;str&gt;\n(Optional) The UniProt ID for the protein, if available.\n\n\nproject_id\nstr\nThe project associated with this protein.\n\n\naccount_id\nstr\nThe account that owns this protein.\n\n\n\n\nExample Usage\nprotein = Protein {\n    id = \"protein_ABC123\",\n    metadata = Metadata {\n        name = \"Example Protein\",\n        description = \"Hypothetical protein from UniProt\",\n        tags = [\"enzyme\", \"binding site\"]\n    },\n    sequence = \"MKTWLLALIFAVFNTLLPVTTIGVSPTAYGNRIT\",\n    uniprot_id = \"P12345\",\n    project_id = \"proj_9876\",\n    account_id = \"account_5432\"\n}\n\n\n\nStructure\nA molecular structure that represents either a protein or a small molecule in Rush workflows.\n\n\n\n\n\n\n\n\nAttribute\nType\nDescription\n\n\n\n\nrcsb_id\nOption&lt;str&gt;\nThe RCSB PDB ID, if available.\n\n\ntopology\nObject&lt;Topology&gt;\nFilepath to a Topology (stored in Rush’s S3 object store). A Topology describes the connectivity and molecular topology of the structure’s set of atoms.\n\n\nresidues\nObject&lt;Residues&gt;\nFilepath to a Residues. A Residues contains residue-level information for the structure.\n\n\nchains\nObject&lt;Chains&gt;\nFilepath to a Chains. A Chains contains chain information in the structure.\n\n\n\nstructure = load (structure_id protein) \"Structure\"\n\n\nProteinConformer\nA protein structure used in docking calculations.\n\n\n\n\n\n\n\n\nAttribute\nType\nDescription\n\n\n\n\nprotein_id\nstr\nReference to the original protein.\n\n\nstructure_id\nstr\nReference to the Sructure associated with this conformer.\n\n\nresidues\nlist&lt;int&gt;\nList of residue indices in the protein.\n\n\npdb_id\nOption&lt;str&gt;\nThe PDB ID if available.\n\n\n\nprotein = load (id (get 0 input)) \"ProteinConformer\",\n\n\nSmolConformer\nA small molecule (ligand) structure used in docking calculations.\n\n\n\n\n\n\n\n\nAttribute\nType\nDescription\n\n\n\n\nsmol_id\nstr\nReference to the original small molecule.\n\n\nstructure_id\nstr\nReference to the Structure associated with this conformer.\n\n\natoms\nlist&lt;int&gt;\nList of atom indices in the small molecule.\n\n\ninchi_key\nOption&lt;str&gt;\nThe InChI Key if available.\n\n\n\nsmol_id = id (get 1 input)\nsmiles = smi (load smol_id \"Smol\")\nsmol_structure = auto3d smiles\n\n\nBoundingBox\nA predicted binding site on a protein, defined by its minimum and maximum coordinates in space.\n\n\n\n\n\n\n\n\nAttribute\nType\nDescription\n\n\n\n\nmin\nlist&lt;float&gt;\nThe minimum coordinates [x, y, z] defining one corner of the bounding box.\n\n\nmax\nlist&lt;float&gt;\nThe maximum coordinates [x, y, z] defining the opposite corner of the bounding box.\n\n\n\nIn OpenFF Protein-Ligand Binding Benchmark, a bounding box is typically obtained using p2rank:\nbounding_box = get 0 (get 0 (p2rank trc))\n\n\nBindingAffinity\nRepresents a processed docking affinity result, including metadata and molecule identifiers.\n\n\n\n\n\n\n\n\nAttribute\nType\nDescription\n\n\n\n\nprotein_id\nstr\nIdentifier for the protein involved in docking.\n\n\nsmol_id\nstr\nIdentifier for the small molecule (ligand) involved in docking.\n\n\naffinity\nfloat\nThe predicted binding affinity value.\n\n\naffinity_metric\nstr\nThe unit of measurement for binding affinity (e.g., \"kcal/mol\").\n\n\n\n\nExample Usage\nbinding_affinity = BindingAffinity {\n    affinity = -8.32,\n    affinity_metric = \"kcal/mol\",\n    protein_id = protein_123,\n    smol_id = smol_id,\n    metadata = Metadata {\n        name = \"Binding affinity for smol:\" + smol_id + \" and protein \" + (protein_id protein),\n        description = none,\n        tags = []\n    }\n}\n\n\n\nBenchmarkArg\nRepresents an argument used for benchmarking, linking a specific entity-instance to an entity type.\n\n\n\n\n\n\n\n\nAttribute\nType\nDescription\n\n\n\n\nentity\nstr\nThe type of entity being benchmarked (e.g., \"BindingAffinity\").\n\n\nid\nstr\nThe unique identifier of the specific entity instance.\n\n\n\n\nExample Usage\nBenchmarkArg {\n    entity = \"BindingAffinity\",\n    id = save binding_affinity\n}",
    "crumbs": [
      "API Docs",
      "Hackathon",
      "Rush Entities"
    ]
  },
  {
    "objectID": "Hackathon/basics.html",
    "href": "Hackathon/basics.html",
    "title": "Rex language basics",
    "section": "",
    "text": "Rex – short for Rush Expressions – is a purely functional programming language. It is a domain-specific language used by the Rush platform to compose different computational drug discovery modules together to create complex protocols.\nIn this quick start guide we will go through a short tour of the basics of the Rex programming language.",
    "crumbs": [
      "API Docs",
      "Hackathon",
      "Rex language basics"
    ]
  },
  {
    "objectID": "Hackathon/basics.html#tuples",
    "href": "Hackathon/basics.html#tuples",
    "title": "Rex language basics",
    "section": "Tuples",
    "text": "Tuples\nWe create tuples using parentheses:\n(\"this is a tuple\", 420, true)\nWe can also use the get function to get specific elements from the tuple. For example:\nlet\n    tuple = (\"this is a \", 420, true)\nin\n    (get 0 tuple) ++ \"tuple\"\nwill result in the value \"this is a tuple\" (we are using the ++ concatentation operator, which works on strings and lists).",
    "crumbs": [
      "API Docs",
      "Hackathon",
      "Rex language basics"
    ]
  },
  {
    "objectID": "Hackathon/basics.html#lists",
    "href": "Hackathon/basics.html#lists",
    "title": "Rex language basics",
    "section": "Lists",
    "text": "Lists\nWe create lists using brackets:\n[\"this\", \"is\", \"a\", \"list\", \"of\", \"strings\" ]\nSimilar to tuples, we can use the get function to get specific elements from the list:\nlet\n    list = [\"this\", \"is\", \"a\", \"list\", \"of\", \"strings\"]\nin\n    (get 0 list) ++ \" \" ++ (get 1 list) ++ \"a string\"\nWe can also use the take function to take a sub-list from the front of the list. For example:\nlet\n    list = [\"this\", \"is\", \"a\", \"list\", \"of\", \"strings\"]\nin\n    take 3 list\nwill return [\"this\", \"is\", \"a\"]. We can combine this with skip to take sub-lists from deeper in the list. For example:\nlet\n    list = [\"this\", \"is\", \"a\", \"list\", \"of\", \"strings\"]\nin\n    take 2 (skip 2 list)\nwill return [\"a\", \"list\"].",
    "crumbs": [
      "API Docs",
      "Hackathon",
      "Rex language basics"
    ]
  },
  {
    "objectID": "Hackathon/basics.html#dictionaries",
    "href": "Hackathon/basics.html#dictionaries",
    "title": "Rex language basics",
    "section": "Dictionaries",
    "text": "Dictionaries\nWe create dictionaries using braces:\n{ key1: \"value1\", key2: 420, key3: true }",
    "crumbs": [
      "API Docs",
      "Hackathon",
      "Rex language basics"
    ]
  },
  {
    "objectID": "Previous Versions/index.html",
    "href": "Previous Versions/index.html",
    "title": "rush-py",
    "section": "",
    "text": "This guide will walk you through executing a basic job using Rush, by demonstrating how to generate 3D small molecule conformers. For a deeper dive and an example of a full end-to-end in silico protocol, see the Comprehensive Guide.",
    "crumbs": [
      "API Docs",
      "Previous Versions"
    ]
  },
  {
    "objectID": "Previous Versions/index.html#import-the-rush-python-library",
    "href": "Previous Versions/index.html#import-the-rush-python-library",
    "title": "rush-py",
    "section": "Import the Rush Python library",
    "text": "Import the Rush Python library\nThe first thing we do is import the rush Python library:\n\nimport rush",
    "crumbs": [
      "API Docs",
      "Previous Versions"
    ]
  },
  {
    "objectID": "Previous Versions/index.html#create-a-rush-client",
    "href": "Previous Versions/index.html#create-a-rush-client",
    "title": "rush-py",
    "section": "Create a Rush client",
    "text": "Create a Rush client\nThe next step is to create a client. This client will be used to interact with the Rush API. You will need to provide your Access Token to authenticate with the API. You can get your Access Token by signing up at https://rush.qdx.co and going into your account settings.\nUsually, you should store your Access Token somewhere safe and not hardcode it into your scripts (e.g. in a configuration file or environment variable). For the sake of this example, we will hardcode it:\n\nclient = rush.build_blocking_provider_with_functions(\n    access_token=PUT_YOUR_TOKEN_HERE  # for example, if your token is 00000000-dddd-cccc-0000-11111111,\n    # then you should put access_token=\"00000000-dddd-cccc-0000-11111111\"\n    # (including the double quotes)\n)\n\nBut specifying that we want a “blocking provider” we are telling Rush that whenever we interact with the API we want to wait for the response before continuing. This is useful for simple scripts that are not running lots of jobs in parallel.",
    "crumbs": [
      "API Docs",
      "Previous Versions"
    ]
  },
  {
    "objectID": "Previous Versions/index.html#create-an-example-smiles-file",
    "href": "Previous Versions/index.html#create-an-example-smiles-file",
    "title": "rush-py",
    "section": "Create an example SMILES file",
    "text": "Create an example SMILES file\nTo run Auto3D we need to specify the SMILES strings for which we want 3D conformers to be generated. These SMILES strings must be stored in a .smi file. For this example, we will use a sample file that contains the SMILES strings for one simple small molecule:\n\n# setup an SMI file that contains the SMILES string of our ligand\nligand_smi_filename = client.workspace / \"ligand.smi\"\nligand_smi_filename.write_text(\"CN1C=NC2=C1C(=O)N(C(=O)N2C)C 1\")\n\n\nA small note about workspaces\nBy default, the client.workspace will be your current working directory, so after this code runs you should see a file in your current working directory called \"ligand.smi\". If you want to specify a different workspace directory, you can do so by specifying the workspace argument when building the client:\n\n# instead of creating a client with this code\nclient = rush.build_blocking_provider_with_functions(\n    access_token=PUT_YOUR_TOKEN_HERE\n)\n\n# you can create a client with this code, and explicitly set the workspace\nclient = rush.build_blocking_provider_with_functions(\n    access_token=PUT_YOUR_TOKEN_HERE,\n    workspace=PUT_YOUR_PREFERRED_WORKING_DIRECTORY_HERE,  # for example, if you\n    # want your run data to be saved in a subfolder called job1, you should put\n    # workspace = \"./job1\"\n)",
    "crumbs": [
      "API Docs",
      "Previous Versions"
    ]
  },
  {
    "objectID": "Previous Versions/index.html#run-auto3d",
    "href": "Previous Versions/index.html#run-auto3d",
    "title": "rush-py",
    "section": "Run Auto3D",
    "text": "Run Auto3D\nNow that we have our SMILES file, we can use it as input to run the Auto3D module. This will generate 3D conformers (in a variety of possible protonation states) for each SMILES string in the SMILES file:\n\n# run Auto3D which will give us 3 conformers of our ligand\n# in the SDF format and the QDXF format\nligand_sdf_handle, ligand_qdxf_handle = client.auto3d(\n    ligand_smi_filename,  # the filename that stores our ligand\n    \"smi\",  # the format of the file\n    {\n        \"k\": 3,  # number of conformers to generate\n        \"use_gpu\": True,  # use GPU for faster compute\n    },\n    tags=[\n        \"your_job_name\"\n    ],  # Add your own identifiers to keep track of your simulations,\n    # separated by , e.g. tags=[\"small ligands\", \"smiles\"]\n    resources={\n        \"gpus\": 1,  # the number of GPUs to use\n        \"storage\": 5,  # the amount of storage to use\n        \"storage_units\": \"MB\",  # the units of storage (here we are using megabytes)\n    },\n)\n\n\nA small note about resources\nIn addition to their module-specific inputs, all modules also accept the resource= parameter. This parameter specifies the computational resources that you want to use to run the module. In this example, we have asked Rush to run the Auto3D module using 1 GPU and 5 megabytes of storage space.",
    "crumbs": [
      "API Docs",
      "Previous Versions"
    ]
  },
  {
    "objectID": "Previous Versions/index.html#see-the-job-status",
    "href": "Previous Versions/index.html#see-the-job-status",
    "title": "rush-py",
    "section": "See the job status",
    "text": "See the job status\nCalling client.auto3d will tell Rush to run a new Auto3D job. However, it will not wait for the job to complete before continuing. This is convenient, because sometimes jobs can take a long time to run, and we might have other code we want to run in the meantime. If we want to track the status of all of our jobs, we can use the client.status function:\n\n# print the status of all jobs\nprint(client.status())",
    "crumbs": [
      "API Docs",
      "Previous Versions"
    ]
  },
  {
    "objectID": "Previous Versions/index.html#download-the-results",
    "href": "Previous Versions/index.html#download-the-results",
    "title": "rush-py",
    "section": "Download the results",
    "text": "Download the results\nAfter calling client.auto3d, we got back two handles: ligand_sdf_handle and ligand_qdxf_handle. These handles are references to the results of the Auto3D job. They are stored in Rush and we can access them from anywhere at any time. We can use these handles as inputs to other modules, we can download their contents, and we can even use them to check the status of the Auto3D job that we ran.\nFor now, we simply download the results and print them out:\n\n# download the results (this will block until the Auto3D job has completed)\nligand_sdf = ligand_sdf_handle.download()\nligand_qdxf = ligand_qdxf_handle.download()\n\nprint(ligand_sdf.read_text()[0:100])  # print the SDF version of the result\nprint(ligand_qdxf.read_text()[0:100])  # print the QDXF version of the result\n\nIf you want to find the actual files, they will be in the objects directory inside your client.workspace directory. Remember, by default, the client.workspace is the current working directory.\n\nA note about handles\nFor most things that we are interested in doing, we do not have to wait for the job created by client.auto3d to actually complete. We can start using ligand_sdf_handle and ligand_qdxf_handle straight away. For example, we could pass them as inputs to a molecular dynamics simulation job. This would tell Rush to automatically run the molecular dynamics simulation job as soon as the Auto3D job completes.\nHowever, the download function is kind of special and will explicitly block our program from continuing until the Auto3D job is complete. This is because download actually fetches the contents of the handles from Rush, and to do so it needs to be sure the contents actually exists.",
    "crumbs": [
      "API Docs",
      "Previous Versions"
    ]
  },
  {
    "objectID": "Previous Versions/Quickstarts/exess_rex.html",
    "href": "Previous Versions/Quickstarts/exess_rex.html",
    "title": "PLIP — Protein ligand interaction profiling",
    "section": "",
    "text": "See the tutorial.\n\n# Get a pdb to work with\n# We use the pdb-tools cli here but you can download directly from rcsb.org\n!pdb_fetch '1MBN' &gt; '1MBN.pdb'\n\n\nfrom pathlib import Path\n\nimport rush\n\nclient = rush.build_blocking_provider_with_functions(batch_tags=[\"exess_rex\"])\no = client.exess_rex(\n      {\n    \"driver\": \"Optimization\",\n    \"model\": {\n      \"method\": \"RestrictedHF\",\n      \"basis\": \"STO-3G\",\n      \"standard_orientation\": \"None\"\n    },\n    \"system\": {\n      \"max_gpu_memory_mb\": 1000\n    },\n    \"keywords\": {\n      \"scf\": {\n        \"use_ri\": False,\n        \"max_iters\": 100,\n        \"max_diis_history_length\": 8,\n        \"convergence_threshold\": 1e-10,\n        \"convergence_metric\": \"DIIS\"\n      },\n      \"optimization\": {\n        \"max_iters\": 200,\n        \"convergence_criteria\": {\n          \"metric\": \"Baker\",\n          \"gradient_threshold\": 5.66918e-4,\n          \"delta_energy_threshold\": 1e-6,\n          \"step_component_threshold\": 1.2e-3\n        }\n      },\n      \"export\": {\n        \"export_bond_orders\": True,\n        \"export_gradient\": True\n      }\n    },\n    \"schema_version\": \"0.2.0\"\n  },\n  [Path(\"/home/machineer/Programming/tengu-hermes/tests/exess_basic/input_topology.json\")],\n  resources={\"gpus\": 1, \"storage\": 100, \"storage_units\": \"MB\", \"walltime\": 60}, target=\"BULLET\"\n)\n\n\no\n\n(Arg(id=0d92aa69-ec20-4804-98e2-592ea2fae6d2, value=None),)\n\n\n\nhelp(client.exess_rex)\n\nHelp on function exess_rex in module rush.provider:\n\nexess_rex(*args: *tuple[Record, list[RushObject[Record]]], target: 'Target | None' = None, resources: 'Resources | None' = None, tags: 'list[str] | None' = None, restore: 'bool | None' = None) -&gt; tuple[typing.Tuple[Optional[None], Optional[str]]]\n    Runs an arbitrary EXESS calculation, provided with valid parameters as described by the input.md document\n\n    Module version:\n    `github:talo/tengu-exess/bf963c302854d00dfacf11ea592f0ddbef1a4f50#exess_rex`\n\n    QDX Type Description:\n\n        in: ExessParams {\n            keywords: Keywords {\n                force_field: ForceFieldKeywords {ff_filename: string}?,\n                rtat: RTATKeywords {\n                    enabled: bool?,\n                    json_file_dump_prefix: string?,\n                    synchronous: bool?\n                }?,\n                boundary: BoundaryKeywords {\n                    y: BoundaryCondition {\n                        kind: BoundaryConditionKind[Periodic = 1 | Rigid = 2 | Delete = 3],\n                        range: Range {upper: f64, lower: f64}\n                    }?,\n                    z: BoundaryCondition {\n                        kind: BoundaryConditionKind[Periodic = 1 | Rigid = 2 | Delete = 3],\n                        range: Range {upper: f64, lower: f64}\n                    }?,\n                    x: BoundaryCondition {\n                        range: Range {lower: f64, upper: f64},\n                        kind: BoundaryConditionKind[Periodic = 1 | Rigid = 2 | Delete = 3]\n                    }?\n                }?,\n                optimization: OptimizationKeywords {\n                    constraints: [[_(u32)]]?,\n                    optimiser_reset_interval: u64?,\n                    convergence_criteria: OptimizationConvergenceCriteria {\n                        delta_energy_threshold: f64?,\n                        step_component_threshold: f64?,\n                        gradient_threshold: f64?\n                    }?,\n                    frozen_distance_slippage_tolerance_angstroms: f64?,\n                    trust_region_keywords: TrustRegionKeywords {\n                        decrease_threshold: f64?,\n                        initial_radius: f64?,\n                        rejection_threshold: f64?,\n                        decrease_factor: f64?,\n                        constrict_factor: f64?,\n                        max_radius: f64?,\n                        min_radius: f64?,\n                        increase_factor: f64?,\n                        increase_threshold: f64?\n                    }?,\n                    max_iters: u64,\n                    frozen_angle_slippage_tolerance_degrees: f64?\n                }?,\n                dynamics: DynamicsKeywords {\n                    use_async_timesteps: bool?,\n                    n_timesteps: u64,\n                    dt: f64\n                }?,\n                scf: SCFKeywords {\n                    density_threshold: f64?,\n                    convergence_threshold: f64?,\n                    compress_ri_b: bool?,\n                    max_diis_history_length: u32?,\n                    use_ri: bool?,\n                    store_ri_b_on_host: bool?,\n                    max_iters: u32?,\n                    batch_size: u32?,\n                    density_basis_set_projection_fallback_enabled: bool?,\n                }?,\n                log: LoggingKeywords {\n                    console: LogSettings {\n                        prefix_fmt: string?\n                    }?,\n                    logfiles: [FileLogSettings {\n                        prefix_fmt: string?,\n                        directory: string?\n                    }]?\n                }?,\n                debug: DebugKeywords {\n                    print_subfragment_xyz: bool?,\n                    skip_calcs: bool?,\n                    max_fragments: i32?,\n                    dry_run: bool?,\n                    ignore_fragments: bool?\n                }?,\n                frag: FragKeywords {\n                    cutoff_type: FragmentDistanceMetric[Centroid = 1 | ClosestPair = 2]?,\n                    reference_fragment: _(u32)?,\n                    cutoffs: FragmentCutoffs {trimer: f64?, tetramer: f64?, dimer: f64?}?,\n                    included_fragments: [_(u32)]?,\n                    enable_speed: bool?\n                }?,\n                guess: GuessKeywords {\n                    ssfd: bool?,\n                    hcore: bool?,\n                    bsp: bool?,\n                    smd: bool?,\n                    external_initial_density_path: Object {size: u64, path: @$HDF5}?,\n                    ssfd_scf_keywords: GuessSCF {\n                        compress_ri_b: bool?,\n                        max_iters: u32?,\n                        density_basis_set_projection_fallback_enabled: bool?,\n                        use_ri: bool?,\n                        batch_size: u32?,\n                        store_ri_b_on_host: bool?,\n                        convergence_threshold: f64?,\n                        density_threshold: f64?,\n                        max_diis_history_length: u32?\n                    }?,\n                    bsp_scf_keywords: SCFKeywords {\n                        density_threshold: f64?,\n                        store_ri_b_on_host: bool?,\n                        convergence_threshold: f64?,\n                        max_diis_history_length: u32?,\n                        use_ri: bool?,\n                        compress_ri_b: bool?,\n                        batch_size: u32?,\n                        density_basis_set_projection_fallback_enabled: bool?,\n                        max_iters: u32?\n                    }?,\n                    bsp_basis: string?,\n                    ssfd_target_size: u32?,\n                    ssfd_only_converge_in_bsp_basis: bool?\n                }?,\n                export: ExportKeywords {\n                    export_fock: bool?,\n                    export_h_core: bool?,\n                    export_molecular_orbital_coeffs: bool?,\n                    export_gradient: bool?,\n                    export_basis_labels: bool?,\n                    export_esp_descriptors: bool?,\n                    export_density: bool?,\n                    export_h_caps: bool?,\n                    export_mulliken_charges: bool?,\n                    export_expanded_gradient: bool?,\n                    export_relaxed_mp2_density_correction: bool?,\n                    export_overlap: bool?,\n                    export_bond_orders: bool?,\n                    export_expanded_density: bool?,\n                    flatten_symmetric: bool?,\n                    export_density_descriptors: bool?,\n                    concatenate_hdf5_files: bool?,\n                    descriptor_grid: DescriptorGridOptions {\n                        standard {\n                            StandardGrid[SG1 = 1 | SG2 = 2]\n                        } | params {\n\n                         {\n                            Grid {\n                                scale: f64,\n                                points_per_shell: u32,\n                                order: GridOrder[One = 1 | Two = 2]\n                            }\n                        } | custom {[f64]}\n                    }?\n                }?\n            },\n            model: Model {\n                basis: string,\n                aux_basis: string?,\n                standard_orientation: string?,\n                force_cartesian_basis_sets: bool?\n            },\n            driver: Driver[Energy = 1 | Gradient = 2 | Dynamics = 3 | Optimization = 4],\n            system: System {\n                max_gpu_memory_mb: u64?,\n                gpus_per_team: u32?,\n                teams_per_node: u32?,\n                oversubscribe_gpus: bool?\n            },\n            schema_version: _(string)\n        };\n        in: [Object {\n            format: ObjectFormat[json | bin]?,\n            path: @Topology {\n                fragment_multiplicities: [_(u8)]?,\n                schema_version: _(string),\n                formal_charges: [_(i32)]?,\n                labels: [string]?,\n                fragment_formal_charges: [_(i32)]?,\n                fragment_partial_charges: [_(f32)]?,\n                geometry: [f32],\n                fragments: [[_(u32)]]?,\n                connectivity: [_(\n                    (\n                        _(u32),\n                        _(u32),\n                    )\n                )]?,\n                velocities: [f32]?,\n                partial_charges: [_(f32)]?\n            },\n            size: u64\n        }]\n        -&gt;\n        out: Object {\n            size: u64,\n            path: @Output {\n                trajectory: Trajectory {\n                    frames: [Frame {\n                        velocities: [f64]?,\n                        time_delta: f64,\n                        simulation_time: f64,\n                        kinetic_energy: f64,\n                        estimated_temperature: f64,\n                        step: u64,\n                        positions: [f64]?,\n                        forces: [f64]?,\n                        parent: FrameRef {u32}?,\n                        changeset: Changeset {\n                            add: Topology {\n                                partial_charges: [_(f32)]?,\n                                schema_version: _(string),\n                                fragment_multiplicities: [_(u8)]?,\n                                fragments: [[_(u32)]]?,\n                                fragment_partial_charges: [_(f32)]?,\n                                connectivity: [_(\n                                    (\n                                        _(u32),\n                                        _(u32),\n                                    )\n                                )]?,\n                                labels: [string]?,\n                                geometry: [f32],\n                                velocities: [f32]?,\n                                formal_charges: [_(i32)]?,\n                                fragment_formal_charges: [_(i32)]?\n                            }?,\n                            sub: [_(u32)]?\n                        }?\n                    }]\n                }?,\n                trajectory_qmmbes: [QMMBE {\n                    reference_fragment: _(u32)?,\n                    classical_water_energy: f64?,\n                    expanded_mp2_gradients: [f64]?,\n                    nmers: [[Nmer {\n                        schema_version: _(string),\n                        mp2_os_correction: f64?,\n                        delta_mp2_os_correction: f64?,\n                        delta_mp2_ss_correction: f64?,\n                        h_core: Tensorf64 {\n                            data: [f64],\n                            shape: [u32],\n                        }?,\n                        mulliken_charges: [f64]?,\n                        bond_orders: [[f64]]?,\n                        mp2_gradients: [f64]?,\n                        density: Tensorf64 {\n                            shape: [u32],\n                            data: [f64]\n                        }?,\n                        hf_gradients: [f64]?,\n                        delta_hf_energy: f64?,\n                        molecular_orbital_energies: [f64]?,\n                        fragments: [_(u32)],\n                        coeffs_final: Tensorf64 {\n                            shape: [u32],\n                            data: [f64]\n                        }?,\n                        fragment_distance: f64?,\n                        h_caps: [_(u32)]?,\n                        coeffs_initial: Tensorf64 {\n                            shape: [u32],\n                            data: [f64]\n                        }?,\n                        mp2_ss_correction: f64?,\n                        fock: Tensorf64 {\n                            data: [f64],\n                            shape: [u32],\n                        }?,\n                        hf_energy: f64?,\n                        num_iters: u32,\n                        num_basis_fns: u32,\n                        overlap: Tensorf64 {\n                            data: [f64],\n                            shape: [u32]\n                        }?\n                    }]],\n                    num_iters: u32,\n                    expanded_mp2_os_correction: f64?,\n                    expanded_mp2_ss_correction: f64?,\n                    expanded_density: Tensorf64 {\n                        data: [f64],\n                        shape: [u32],\n                    }?,\n                    expanded_hf_energy: f64?,\n                    schema_version: _(string),\n                    expanded_hf_gradients: [f64]?\n                }]?,\n                qmmbe: QMMBE {\n                    expanded_hf_gradients: [f64]?,\n                    expanded_mp2_gradients: [f64]?,\n                    expanded_mp2_os_correction: f64?,\n                    nmers: [[Nmer {\n                        hf_energy: f64?,\n                        mp2_gradients: [f64]?,\n                        schema_version: _(string),\n                        h_caps: [_(u32)]?,\n                        fock: Tensorf64 {\n                            shape: [u32],\n                            data: [f64],\n                        }?,\n                        num_iters: u32,\n                        num_basis_fns: u32,\n                        delta_hf_energy: f64?,\n                        fragment_distance: f64?,\n                        delta_mp2_os_correction: f64?,\n                        delta_mp2_ss_correction: f64?,\n                        fragments: [_(u32)],\n                        overlap: Tensorf64 {\n                            shape: [u32],\n                            data: [f64],\n                        }?,\n                        coeffs_final: Tensorf64 {\n                            shape: [u32],\n                            data: [f64],\n                        }?,\n                        h_core: Tensorf64 {\n                            shape: [u32],\n                            data: [f64],\n                        }?,\n                        molecular_orbital_energies: [f64]?,\n                        bond_orders: [[f64]]?,\n                        hf_gradients: [f64]?,\n                        coeffs_initial: Tensorf64 {\n                            data: [f64],\n                            shape: [u32],\n                        }?,\n                        mulliken_charges: [f64]?,\n                        density: Tensorf64 {\n                            shape: [u32],\n                            data: [f64],\n                        }?,\n                        mp2_os_correction: f64?,\n                        mp2_ss_correction: f64?\n                    }]],\n                    expanded_density: Tensorf64 {\n                        data: [f64],\n                        shape: [u32]\n                    }?,\n                    reference_fragment: _(u32)?,\n                    expanded_mp2_ss_correction: f64?,\n                    num_iters: u32,\n                    classical_water_energy: f64?,\n                    expanded_hf_energy: f64?,\n                    schema_version: _(string)\n                }?,\n                schema_version: _(string),\n                calculation_time: f64\n            },\n            format: ObjectFormat[json | bin]?\n        }!\n\n\n\n\no[0].get()\n\n2024-12-26 14:33:14,415 - rush - INFO - Argument 0d92aa69-ec20-4804-98e2-592ea2fae6d2 is now ModuleInstanceStatus.ADMITTED\n2024-12-26 14:33:28,546 - rush - INFO - Argument 0d92aa69-ec20-4804-98e2-592ea2fae6d2 is now ModuleInstanceStatus.DISPATCHED\n2024-12-26 14:33:34,256 - rush - INFO - Argument 0d92aa69-ec20-4804-98e2-592ea2fae6d2 is now ModuleInstanceStatus.AWAITING_UPLOAD\n\n\n{'Ok': {'path': 'e08d8a3d-4453-420e-92ae-c4c45f537663',\n  'size': 0,\n  'format': 'json'}}\n\n\n\no[0].download()\n\nPosixPath('objects/e08d8a3d-4453-420e-92ae-c4c45f537663')\n\n\n\no[0].typeinfo\n\n{'k': 'fallible',\n 't': [{'k': 'record',\n   't': {'path': {'k': '@',\n     't': {'doc': {'fields': {'trajectory_qmmbes': 'The trajectory of the QM/MMBE energy for each fragment.\\nThe `i`th index corresponds to the `i`th frame of a `Dynamics` calculation. Not present in non-`Dynamics` calculations',\n        'trajectory': 'The trajectory of the QM/MMBE energy.',\n        'qmmbe': 'The QM/MMBE energy.',\n        'calculation_time': 'The time it took to run the calculation.'}},\n      'k': 'record',\n      't': {'trajectory': {'k': 'optional',\n        't': {'doc': {'fields': {}},\n         'k': 'record',\n         't': {'frames': {'k': 'array',\n           't': {'doc': {'fields': {}},\n            'k': 'record',\n            't': {'estimated_temperature': 'f64',\n             'velocities': {'k': 'optional', 't': {'k': 'array', 't': 'f64'}},\n             'parent': {'k': 'optional',\n              't': {'k': 'record', 't': ['u32'], 'n': 'FrameRef'}},\n             'simulation_time': 'f64',\n             'forces': {'k': 'optional', 't': {'k': 'array', 't': 'f64'}},\n             'kinetic_energy': 'f64',\n             'time_delta': 'f64',\n             'changeset': {'k': 'optional',\n              't': {'doc': {'fields': {}},\n               'k': 'record',\n               't': {'add': {'k': 'optional',\n                 't': {'doc': {'fields': {'formal_charges': 'Optional list of the formal charge of each atom. If present, then it\\nmust be the same length as `symbols`.',\n                    'partial_charges': 'Optional list of the partial charge of each atom. If present, then it\\nmust be the same length as `symbols`.',\n                    'geometry': 'XYZ coordinates of each atom. It must be 3 times the length of\\n`symbols`.',\n                    'fragment_partial_charges': 'Optional list of the formal charge of each fragment. If present, then it\\nmust be the same length as `fragments`.',\n                    'fragment_multiplicities': 'Optional list of the multiplicity of each fragment. This is only\\nrelevant for open-shell systems. If present, then it must be the same\\nlength as `fragments`.',\n                    'labels': 'Optional list of the label of each atom. Often this is used for\\nlabelling specific atoms within residues (e.g. alpha carbons). If\\npresent, then it must be the same length as `symbols`.',\n                    'symbols': 'Element of each atom.',\n                    'connectivity': 'Optional list of bonds. Because bonds are perceived, this list should\\nnot be considered a reliable source of bond information.',\n                    'fragment_formal_charges': 'Optional list of the formal charge of each fragment. If present, then it\\nmust be the same length as `fragments`.',\n                    'fragments': 'Optional list of fragments. If present, then all atoms must be in\\nexactly one fragment.',\n                    'velocities': 'Contains the x, y, z components of initial atom velocities in Angstroms/ps\\nV1 only'}},\n                  'k': 'record',\n                  't': {'fragments': {'k': 'optional',\n                    't': {'k': 'array',\n                     't': {'k': 'array', 't': {'k': 'alias', 't': 'u32'}}}},\n                   'formal_charges': {'k': 'optional',\n                    't': {'k': 'array', 't': {'k': 'alias', 't': 'i32'}}},\n                   'schema_version': {'k': 'alias', 't': 'string'},\n                   'fragment_formal_charges': {'k': 'optional',\n                    't': {'k': 'array', 't': {'k': 'alias', 't': 'i32'}}},\n                   'labels': {'k': 'optional',\n                    't': {'k': 'array', 't': 'string'}},\n                   'velocities': {'k': 'optional',\n                    't': {'k': 'array', 't': 'f32'}},\n                   'symbols': {'k': 'array',\n                    't': {'k': 'enum',\n                     't': [{'H': 1},\n                      'He',\n                      'Li',\n                      'Be',\n                      'B',\n                      'C',\n                      'N',\n                      'O',\n                      'F',\n                      'Ne',\n                      'Na',\n                      'Mg',\n                      'Al',\n                      'Si',\n                      'P',\n                      'S',\n                      'Cl',\n                      'Ar',\n                      'K',\n                      'Ca',\n                      'Sc',\n                      'Ti',\n                      'V',\n                      'Cr',\n                      'Mn',\n                      'Fe',\n                      'Co',\n                      'Ni',\n                      'Cu',\n                      'Zn',\n                      'Ga',\n                      'Ge',\n                      'As',\n                      'Se',\n                      'Br',\n                      'Kr',\n                      'Rb',\n                      'Sr',\n                      'Y',\n                      'Zr',\n                      'Nb',\n                      'Mo',\n                      'Tc',\n                      'Ru',\n                      'Rh',\n                      'Pd',\n                      'Ag',\n                      'Cd',\n                      'In',\n                      'Sn',\n                      'Sb',\n                      'Te',\n                      'I',\n                      'Xe',\n                      'Cs',\n                      'Ba',\n                      'La',\n                      'Ce',\n                      'Pr',\n                      'Nd',\n                      'Pm',\n                      'Sm',\n                      'Eu',\n                      'Gd',\n                      'Tb',\n                      'Dy',\n                      'Ho',\n                      'Er',\n                      'Tm',\n                      'Yb',\n                      'Lu',\n                      'Hf',\n                      'Ta',\n                      'W',\n                      'Re',\n                      'Os',\n                      'Ir',\n                      'Pt',\n                      'Au',\n                      'Hg',\n                      'Tl',\n                      'Pb',\n                      'Bi',\n                      'Po',\n                      'At',\n                      'Rn',\n                      'Fr',\n                      'Ra',\n                      'Ac',\n                      'Th',\n                      'Pa',\n                      'U',\n                      'Np',\n                      'Pu',\n                      'Am',\n                      'Cm',\n                      'Bk',\n                      'Cf',\n                      'Es',\n                      'Fm',\n                      'Md',\n                      'No',\n                      'Lr',\n                      'Rf',\n                      'Db',\n                      'Sg',\n                      'Bh',\n                      'Hs',\n                      'Mt',\n                      'Ds',\n                      'Rg',\n                      'Cn',\n                      'Nh',\n                      'Fl',\n                      'Mc',\n                      'Lv',\n                      'Ts',\n                      'Og'],\n                     'n': 'Element'}},\n                   'fragment_multiplicities': {'k': 'optional',\n                    't': {'k': 'array', 't': {'k': 'alias', 't': 'u8'}}},\n                   'partial_charges': {'k': 'optional',\n                    't': {'k': 'array', 't': {'k': 'alias', 't': 'f32'}}},\n                   'fragment_partial_charges': {'k': 'optional',\n                    't': {'k': 'array', 't': {'k': 'alias', 't': 'f32'}}},\n                   'geometry': {'k': 'array', 't': 'f32'},\n                   'connectivity': {'k': 'optional',\n                    't': {'k': 'array',\n                     't': {'k': 'alias',\n                      't': {'k': 'tuple',\n                       't': [{'k': 'alias', 't': 'u32'},\n                        {'k': 'alias', 't': 'u32'},\n                        {'k': 'enum',\n                         't': [{'Unspecified': 0},\n                          {'Single': 1},\n                          {'Double': 2},\n                          {'Triple': 3},\n                          {'Quadriple': 4},\n                          {'Quintuple': 5},\n                          {'Sextuple': 6},\n                          {'FiveAndAHalf': 250},\n                          {'FourAndAHalf': 251},\n                          {'ThreeAndAHalf': 252},\n                          {'TwoAndAHalf': 253},\n                          {'OneAndAHalf': 254},\n                          {'Ring': 255}],\n                         'n': 'BondOrder'}]}}}}},\n                  'n': 'Topology'}},\n                'sub': {'k': 'optional',\n                 't': {'k': 'array', 't': {'k': 'alias', 't': 'u32'}}}},\n               'n': 'Changeset'}},\n             'positions': {'k': 'optional', 't': {'k': 'array', 't': 'f64'}},\n             'step': 'u64'},\n            'n': 'Frame'}}},\n         'n': 'Trajectory'}},\n       'qmmbe': {'k': 'optional',\n        't': {'doc': {'fields': {'expanded_hf_energy': 'Either the total HF energy of the system or the total HF interaction\\nenergy between the `reference_fragment` and the rest of the system. This\\nvalue is only present when `method` is one of the HF or MP2 methods.',\n           'nmers': 'The 1st element contains all monomers, the 2nd element contains all\\ndimers, the 3rd element contains all trimers, and so on.',\n           'expanded_mp2_gradients': 'MP2 gradient vectors for each atom in the entire system. The gradients\\nare ordered according to the atom ordering in respective `Topology`. If\\n`expanded_mp2_gradients` is `Some`, then `expanded_hf_gradients` must be\\n`None`.\\nIf `reference_fragment` is `Some`, then `expanded_mp2_gradients` must be\\n`None`.',\n           'expanded_hf_gradients': 'Hartree-Fock gradient vectors for each atom in the entire system. The\\ngradients are ordered according to the atom ordering in respective\\n`Topology`. If `expanded_hf_gradients` is `Some`, then\\n`expanded_mp2_gradients` must be `None`.\\nIf `reference_fragment` is `Some`, then `expanded_hf_gradients` must be\\n`None`.',\n           'expanded_density': 'The converged density matrix of the entire system in either\\nsquare-symmetric or vectorised lower-triangular form.\\n\\nIf `reference_fragment` is `Some`, then `expanded_density` must be\\n`None`.',\n           'distance_metric': 'Distance metric used to compute fragment distances for this computation.',\n           'reference_fragment': 'Index into the first element of `nmers` that identifies the monomer used\\nas the reference monomer for the interaction calculation. If this value\\nis `None` then the `expanded_hf_energy`, `expanded_mp2_ss_correction`,\\nand `expanded_mp2_os_correction` energies should be interpreted as the\\ntotal energy of the system. Otherwise, these energies should be\\ninterpreted as the interaction energy between the reference monomer and\\nthe rest of the system.',\n           'expanded_mp2_os_correction': 'Either the total MP2 opposite-spin energy correction of the system or\\nthe total MP2 opposite-spin energy correction for the interaction energy\\nbetween the `reference_fragment` and the rest of the system. This value\\nis only present when `method` is one of the MP2 methods.',\n           'expanded_mp2_ss_correction': 'Either the total MP2 same-spin energy correction of the system or the\\ntotal MP2 same-spin energy correction for the interaction energy between\\nthe `reference_fragment` and the rest of the system. This value is only\\npresent when `method` is one of the MP2 methods.',\n           'method': 'Method used to compute this output.',\n           'num_iters': 'Number of SCF iterations required to reach convergence across all\\n`Nmers`.'}},\n         'k': 'record',\n         't': {'method': {'k': 'enum',\n           't': [{'RestrictedHF': 1},\n            {'UnrestrictedHF': 2},\n            {'RestrictedRIMP2': 7},\n            {'UnrestrictedRIMP2': 8}],\n           'n': 'Method'},\n          'distance_metric': {'k': 'optional',\n           't': {'k': 'enum',\n            't': [{'Centroid': 1}, {'ClosestPair': 2}],\n            'n': 'FragmentDistanceMetric'}},\n          'expanded_density': {'k': 'optional',\n           't': {'doc': {'fields': {'kind': 'In combination with `shape`, the `kind` tells us how to parse the `data`\\nfield.',\n              'data': 'Densely packed data. To parse it, we need to consdier `kind` and\\n`shape`.',\n              'shape': 'The size of each dimensions of `Tensor`. The length of this field tells\\nus the dimension of the `Tensor`. The value of each element tells us the\\nsize of that dimension. For example, if `shape` is `[2, 3, 4]`, then the\\n`Tensor` is 3-dimensional, and the size of the first dimension is 2, the\\nsize of the second dimension is 3, and the size of the third dimension\\nis 4. In combination with `kind`, the `shape` tells us how to parse the\\n`data` field.'}},\n            'k': 'record',\n            't': {'data': {'k': 'array', 't': 'f64'},\n             'kind': {'k': 'enum',\n              't': [{'Dense': 1},\n               {'SquareSymmetric': 2},\n               {'LowerTriangular': 3}],\n              'n': 'TensorKind'},\n             'shape': {'k': 'array', 't': 'u32'}},\n            'n': 'Tensorf64'}},\n          'expanded_mp2_ss_correction': {'k': 'optional', 't': 'f64'},\n          'expanded_hf_gradients': {'k': 'optional',\n           't': {'k': 'array', 't': 'f64'}},\n          'reference_fragment': {'k': 'optional',\n           't': {'k': 'alias', 't': 'u32'}},\n          'expanded_mp2_os_correction': {'k': 'optional', 't': 'f64'},\n          'classical_water_energy': {'k': 'optional', 't': 'f64'},\n          'num_iters': 'u32',\n          'expanded_mp2_gradients': {'k': 'optional',\n           't': {'k': 'array', 't': 'f64'}},\n          'schema_version': {'k': 'alias', 't': 'string'},\n          'expanded_hf_energy': {'k': 'optional', 't': 'f64'},\n          'nmers': {'k': 'array',\n           't': {'k': 'array',\n            't': {'doc': {'fields': {'molecular_orbital_energies': 'The molecular orbital energies for the n-mer. If present, there must be\\none entry per basis function.',\n               'h_core': 'The core hamiltonian matrix for this n-mer in either square-symmetric or\\nvectorised lower-triangular form.',\n               'overlap': 'The overlap matrix for this n-mer in either square-symmetric or\\nvectorised lower-triangular form.',\n               'fock': 'The converged fock matrix for this n-mer in either square-symmetric or\\nvectorised lower-triangular form.',\n               'mp2_ss_correction': 'MP2 same-spin correction to the total Hartree-Fock energy.',\n               'fragments': 'List of fragments that are in this n-mer. Monomers have 1 fragment,\\ndimers have 2 fragments, trimers have 3 fragments, and so on. These\\nfragments are references to the fragments defined by a `Topology`.',\n               'h_caps': 'List of atoms in this fragment that are hydrogen caps added by the\\nfragmentation process. Elements of the list are indices relative to\\nthis fragment after the addition of hydrogen caps. The `h_caps` list\\nmust be present whenever matrices are exported (`density`, `fock`,\\n`overlap`, etc).\\n\\nWARNING: these indices are local to this fragment. That is, an index\\nof 0 represents the first atom in this fragment, and not in the\\nfirst atom in the full system topology.',\n               'mp2_os_correction': 'MP2 opposite-spin correction to the total Hartree-Fock energy.',\n               'mulliken_charges': 'Mulliken charges of each atom in the fragment. If `None`, then this\\nvalue was not exported.',\n               'fragment_distance': 'Distance between monomers in the dimer. If the nmer is not a dimer, this\\nwill not be present.',\n               'delta_mp2_os_correction': 'MP2 opposite-spin correction to the Hartree-Fock delta energy.',\n               'num_iters': 'Number of SCF iterations required to reach convergence.',\n               'hf_gradients': 'Hartree-Fock gradient vectors for each atom in this n-mer. The gradients\\nare orderd by fragment (as specified by this n-mer) and then by atom\\nordering (as specified by the referenced fragment). For example, in a\\ndimer, all XYZ gradient vectors for the 1st fragment will appear before\\nall XYZ gradients for the 2nd fragment; and the XYZ gradient vectors of\\neach fragment will be ordered according to the atom ordering in the\\nreferenced element of the `fragments` field of the respective\\n`Topology`. If `hf_gradients` is `Some`, then `mp2_gradients` must be\\n`None`.',\n               'hf_energy': 'Hartree-Fock total energy of this n-mer.',\n               'num_basis_fns': 'Number of basis functions used in the calculation.',\n               'mp2_gradients': 'MP2 gradient vectors for each atom in this n-mer. The gradients are\\norderd by fragment (\\nas specified by this n-mer) and then by atom\\nordering (as specified by the referenced fragment). For example, in a\\ndimer, all XYZ gradient vectors for the 1st fragment will appear before\\nall XYZ gradients for the 2nd fragment; and the XYZ gradient vectors of\\neach fragment will be ordered according to the atom ordering in the\\nreferenced element of the `fragments` field of the respective\\n`Topology`. If `mp2_gradients` is `Some`, then `hf_gradients` must be\\n`None`.',\n               'coeffs_initial': 'The initial coefficient matrix for the n-mer.',\n               'delta_mp2_ss_correction': 'MP2 same-spin correction to the Hartree-Fock delta energy.',\n               'density': 'The converged density matrix for this n-mer in either square-symmetric or\\nvectorised lower-triangular form.',\n               'bond_orders': 'Bond order adjacency matrix. If `None`, then this value was not\\nexported.',\n               'delta_hf_energy': 'Hartree-Fock delta energy of this n-mer. For example, in a dimer, this\\nwould be the interaction energy between the 2 udnerlying monomers.',\n               'coeffs_final': 'The final coefficient matrix for the n-mer.'}},\n             'k': 'record',\n             't': {'h_caps': {'k': 'optional',\n               't': {'k': 'array', 't': {'k': 'alias', 't': 'u32'}}},\n              'fragments': {'k': 'array', 't': {'k': 'alias', 't': 'u32'}},\n              'mulliken_charges': {'k': 'optional',\n               't': {'k': 'array', 't': 'f64'}},\n              'overlap': {'k': 'optional',\n               't': {'doc': {'fields': {'kind': 'In combination with `shape`, the `kind` tells us how to parse the `data`\\nfield.',\n                  'data': 'Densely packed data. To parse it, we need to consdier `kind` and\\n`shape`.',\n                  'shape': 'The size of each dimensions of `Tensor`. The length of this field tells\\nus the dimension of the `Tensor`. The value of each element tells us the\\nsize of that dimension. For example, if `shape` is `[2, 3, 4]`, then the\\n`Tensor` is 3-dimensional, and the size of the first dimension is 2, the\\nsize of the second dimension is 3, and the size of the third dimension\\nis 4. In combination with `kind`, the `shape` tells us how to parse the\\n`data` field.'}},\n                'k': 'record',\n                't': {'kind': {'k': 'enum',\n                  't': [{'Dense': 1},\n                   {'SquareSymmetric': 2},\n                   {'LowerTriangular': 3}],\n                  'n': 'TensorKind'},\n                 'data': {'k': 'array', 't': 'f64'},\n                 'shape': {'k': 'array', 't': 'u32'}},\n                'n': 'Tensorf64'}},\n              'num_iters': 'u32',\n              'h_core': {'k': 'optional',\n               't': {'doc': {'fields': {'kind': 'In combination with `shape`, the `kind` tells us how to parse the `data`\\nfield.',\n                  'shape': 'The size of each dimensions of `Tensor`. The length of this field tells\\nus the dimension of the `Tensor`. The value of each element tells us the\\nsize of that dimension. For example, if `shape` is `[2, 3, 4]`, then the\\n`Tensor` is 3-dimensional, and the size of the first dimension is 2, the\\nsize of the second dimension is 3, and the size of the third dimension\\nis 4. In combination with `kind`, the `shape` tells us how to parse the\\n`data` field.',\n                  'data': 'Densely packed data. To parse it, we need to consdier `kind` and\\n`shape`.'}},\n                'k': 'record',\n                't': {'shape': {'k': 'array', 't': 'u32'},\n                 'kind': {'k': 'enum',\n                  't': [{'Dense': 1},\n                   {'SquareSymmetric': 2},\n                   {'LowerTriangular': 3}],\n                  'n': 'TensorKind'},\n                 'data': {'k': 'array', 't': 'f64'}},\n                'n': 'Tensorf64'}},\n              'hf_gradients': {'k': 'optional',\n               't': {'k': 'array', 't': 'f64'}},\n              'mp2_os_correction': {'k': 'optional', 't': 'f64'},\n              'fragment_distance': {'k': 'optional', 't': 'f64'},\n              'fock': {'k': 'optional',\n               't': {'doc': {'fields': {'data': 'Densely packed data. To parse it, we need to consdier `kind` and\\n`shape`.',\n                  'kind': 'In combination with `shape`, the `kind` tells us how to parse the `data`\\nfield.',\n                  'shape': 'The size of each dimensions of `Tensor`. The length of this field tells\\nus the dimension of the `Tensor`. The value of each element tells us the\\nsize of that dimension. For example, if `shape` is `[2, 3, 4]`, then the\\n`Tensor` is 3-dimensional, and the size of the first dimension is 2, the\\nsize of the second dimension is 3, and the size of the third dimension\\nis 4. In combination with `kind`, the `shape` tells us how to parse the\\n`data` field.'}},\n                'k': 'record',\n                't': {'shape': {'k': 'array', 't': 'u32'},\n                 'data': {'k': 'array', 't': 'f64'},\n                 'kind': {'k': 'enum',\n                  't': [{'Dense': 1},\n                   {'SquareSymmetric': 2},\n                   {'LowerTriangular': 3}],\n                  'n': 'TensorKind'}},\n                'n': 'Tensorf64'}},\n              'molecular_orbital_energies': {'k': 'optional',\n               't': {'k': 'array', 't': 'f64'}},\n              'mp2_ss_correction': {'k': 'optional', 't': 'f64'},\n              'num_basis_fns': 'u32',\n              'hf_energy': {'k': 'optional', 't': 'f64'},\n              'schema_version': {'k': 'alias', 't': 'string'},\n              'mp2_gradients': {'k': 'optional',\n               't': {'k': 'array', 't': 'f64'}},\n              'delta_mp2_ss_correction': {'k': 'optional', 't': 'f64'},\n              'coeffs_final': {'k': 'optional',\n               't': {'doc': {'fields': {'shape': 'The size of each dimensions of `Tensor`. The length of this field tells\\nus the dimension of the `Tensor`. The value of each element tells us the\\nsize of that dimension. For example, if `shape` is `[2, 3, 4]`, then the\\n`Tensor` is 3-dimensional, and the size of the first dimension is 2, the\\nsize of the second dimension is 3, and the size of the third dimension\\nis 4. In combination with `kind`, the `shape` tells us how to parse the\\n`data` field.',\n                  'data': 'Densely packed data. To parse it, we need to consdier `kind` and\\n`shape`.',\n                  'kind': 'In combination with `shape`, the `kind` tells us how to parse the `data`\\nfield.'}},\n                'k': 'record',\n                't': {'data': {'k': 'array', 't': 'f64'},\n                 'kind': {'k': 'enum',\n                  't': [{'Dense': 1},\n                   {'SquareSymmetric': 2},\n                   {'LowerTriangular': 3}],\n                  'n': 'TensorKind'},\n                 'shape': {'k': 'array', 't': 'u32'}},\n                'n': 'Tensorf64'}},\n              'delta_hf_energy': {'k': 'optional', 't': 'f64'},\n              'delta_mp2_os_correction': {'k': 'optional', 't': 'f64'},\n              'density': {'k': 'optional',\n               't': {'doc': {'fields': {'shape': 'The size of each dimensions of `Tensor`. The length of this field tells\\nus the dimension of the `Tensor`. The value of each element tells us the\\nsize of that dimension. For example, if `shape` is `[2, 3, 4]`, then the\\n`Tensor` is 3-dimensional, and the size of the first dimension is 2, the\\nsize of the second dimension is 3, and the size of the third dimension\\nis 4. In combination with `kind`, the `shape` tells us how to parse the\\n`data` field.',\n                  'kind': 'In combination with `shape`, the `kind` tells us how to parse the `data`\\nfield.',\n                  'data': 'Densely packed data. To parse it, we need to consdier `kind` and\\n`shape`.'}},\n                'k': 'record',\n                't': {'data': {'k': 'array', 't': 'f64'},\n                 'kind': {'k': 'enum',\n                  't': [{'Dense': 1},\n                   {'SquareSymmetric': 2},\n                   {'LowerTriangular': 3}],\n                  'n': 'TensorKind'},\n                 'shape': {'k': 'array', 't': 'u32'}},\n                'n': 'Tensorf64'}},\n              'coeffs_initial': {'k': 'optional',\n               't': {'doc': {'fields': {'data': 'Densely packed data. To parse it, we need to consdier `kind` and\\n`shape`.',\n                  'shape': 'The size of each dimensions of `Tensor`. The length of this field tells\\nus the dimension of the `Tensor`. The value of each element tells us the\\nsize of that dimension. For example, if `shape` is `[2, 3, 4]`, then the\\n`Tensor` is 3-dimensional, and the size of the first dimension is 2, the\\nsize of the second dimension is 3, and the size of the third dimension\\nis 4. In combination with `kind`, the `shape` tells us how to parse the\\n`data` field.',\n                  'kind': 'In combination with `shape`, the `kind` tells us how to parse the `data`\\nfield.'}},\n                'k': 'record',\n                't': {'kind': {'k': 'enum',\n                  't': [{'Dense': 1},\n                   {'SquareSymmetric': 2},\n                   {'LowerTriangular': 3}],\n                  'n': 'TensorKind'},\n                 'shape': {'k': 'array', 't': 'u32'},\n                 'data': {'k': 'array', 't': 'f64'}},\n                'n': 'Tensorf64'}},\n              'bond_orders': {'k': 'optional',\n               't': {'k': 'array', 't': {'k': 'array', 't': 'f64'}}}},\n             'n': 'Nmer'}}}},\n         'n': 'QMMBE'}},\n       'calculation_time': 'f64',\n       'trajectory_qmmbes': {'k': 'optional',\n        't': {'k': 'array',\n         't': {'doc': {'fields': {'expanded_mp2_gradients': 'MP2 gradient vectors for each atom in the entire system. The gradients\\nare ordered according to the atom ordering in respective `Topology`. If\\n`expanded_mp2_gradients` is `Some`, then `expanded_hf_gradients` must be\\n`None`.\\nIf `reference_fragment` is `Some`, then `expanded_mp2_gradients` must be\\n`None`.',\n            'expanded_hf_energy': 'Either the total HF energy of the system or the total HF interaction\\nenergy between the `reference_fragment` and the rest of the system. This\\nvalue is only present when `method` is one of the HF or MP2 methods.',\n            'expanded_density': 'The converged density matrix of the entire system in either\\nsquare-symmetric or vectorised lower-triangular form.\\n\\nIf `reference_fragment` is `Some`, then `expanded_density` must be\\n`None`.',\n            'expanded_mp2_ss_correction': 'Either the total MP2 same-spin energy correction of the system or the\\ntotal MP2 same-spin energy correction for the interaction energy between\\nthe `reference_fragment` and the rest of the system. This value is only\\npresent when `method` is one of the MP2 methods.',\n            'method': 'Method used to compute this output.',\n            'reference_fragment': 'Index into the first element of `nmers` that identifies the monomer used\\nas the reference monomer for the interaction calculation. If this value\\nis `None` then the `expanded_hf_energy`, `expanded_mp2_ss_correction`,\\nand `expanded_mp2_os_correction` energies should be interpreted as the\\ntotal energy of the system. Otherwise, these energies should be\\ninterpreted as the interaction energy between the reference monomer and\\nthe rest of the system.',\n            'distance_metric': 'Distance metric used to compute fragment distances for this computation.',\n            'nmers': 'The 1st element contains all monomers, the 2nd element contains all\\ndimers, the 3rd element contains all trimers, and so on.',\n            'expanded_hf_gradients': 'Hartree-Fock gradient vectors for each atom in the entire system. The\\ngradients are ordered according to the atom ordering in respective\\n`Topology`. If `expanded_hf_gradients` is `Some`, then\\n`expanded_mp2_gradients` must be `None`.\\nIf `reference_fragment` is `Some`, then `expanded_hf_gradients` must be\\n`None`.',\n            'num_iters': 'Number of SCF iterations required to reach convergence across all\\n`Nmers`.',\n            'expanded_mp2_os_correction': 'Either the total MP2 opposite-spin energy correction of the system or\\nthe total MP2 opposite-spin energy correction for the interaction energy\\nbetween the `reference_fragment` and the rest of the system. This value\\nis only present when `method` is one of the MP2 methods.'}},\n          'k': 'record',\n          't': {'expanded_hf_gradients': {'k': 'optional',\n            't': {'k': 'array', 't': 'f64'}},\n           'reference_fragment': {'k': 'optional',\n            't': {'k': 'alias', 't': 'u32'}},\n           'expanded_mp2_os_correction': {'k': 'optional', 't': 'f64'},\n           'expanded_mp2_gradients': {'k': 'optional',\n            't': {'k': 'array', 't': 'f64'}},\n           'schema_version': {'k': 'alias', 't': 'string'},\n           'expanded_hf_energy': {'k': 'optional', 't': 'f64'},\n           'method': {'k': 'enum',\n            't': [{'RestrictedHF': 1},\n             {'UnrestrictedHF': 2},\n             {'RestrictedRIMP2': 7},\n             {'UnrestrictedRIMP2': 8}],\n            'n': 'Method'},\n           'nmers': {'k': 'array',\n            't': {'k': 'array',\n             't': {'doc': {'fields': {'num_basis_fns': 'Number of basis functions used in the calculation.',\n                'hf_gradients': 'Hartree-Fock gradient vectors for each atom in this n-mer. The gradients\\nare orderd by fragment (as specified by this n-mer) and then by atom\\nordering (as specified by the referenced fragment). For example, in a\\ndimer, all XYZ gradient vectors for the 1st fragment will appear before\\nall XYZ gradients for the 2nd fragment; and the XYZ gradient vectors of\\neach fragment will be ordered according to the atom ordering in the\\nreferenced element of the `fragments` field of the respective\\n`Topology`. If `hf_gradients` is `Some`, then `mp2_gradients` must be\\n`None`.',\n                'mp2_gradients': 'MP2 gradient vectors for each atom in this n-mer. The gradients are\\norderd by fragment (\\nas specified by this n-mer) and then by atom\\nordering (as specified by the referenced fragment). For example, in a\\ndimer, all XYZ gradient vectors for the 1st fragment will appear before\\nall XYZ gradients for the 2nd fragment; and the XYZ gradient vectors of\\neach fragment will be ordered according to the atom ordering in the\\nreferenced element of the `fragments` field of the respective\\n`Topology`. If `mp2_gradients` is `Some`, then `hf_gradients` must be\\n`None`.',\n                'delta_mp2_ss_correction': 'MP2 same-spin correction to the Hartree-Fock delta energy.',\n                'delta_mp2_os_correction': 'MP2 opposite-spin correction to the Hartree-Fock delta energy.',\n                'bond_orders': 'Bond order adjacency matrix. If `None`, then this value was not\\nexported.',\n                'coeffs_initial': 'The initial coefficient matrix for the n-mer.',\n                'fock': 'The converged fock matrix for this n-mer in either square-symmetric or\\nvectorised lower-triangular form.',\n                'hf_energy': 'Hartree-Fock total energy of this n-mer.',\n                'mp2_os_correction': 'MP2 opposite-spin correction to the total Hartree-Fock energy.',\n                'coeffs_final': 'The final coefficient matrix for the n-mer.',\n                'num_iters': 'Number of SCF iterations required to reach convergence.',\n                'mp2_ss_correction': 'MP2 same-spin correction to the total Hartree-Fock energy.',\n                'mulliken_charges': 'Mulliken charges of each atom in the fragment. If `None`, then this\\nvalue was not exported.',\n                'fragments': 'List of fragments that are in this n-mer. Monomers have 1 fragment,\\ndimers have 2 fragments, trimers have 3 fragments, and so on. These\\nfragments are references to the fragments defined by a `Topology`.',\n                'overlap': 'The overlap matrix for this n-mer in either square-symmetric or\\nvectorised lower-triangular form.',\n                'delta_hf_energy': 'Hartree-Fock delta energy of this n-mer. For example, in a dimer, this\\nwould be the interaction energy between the 2 udnerlying monomers.',\n                'h_core': 'The core hamiltonian matrix for this n-mer in either square-symmetric or\\nvectorised lower-triangular form.',\n                'density': 'The converged density matrix for this n-mer in either square-symmetric or\\nvectorised lower-triangular form.',\n                'h_caps': 'List of atoms in this fragment that are hydrogen caps added by the\\nfragmentation process. Elements of the list are indices relative to\\nthis fragment after the addition of hydrogen caps. The `h_caps` list\\nmust be present whenever matrices are exported (`density`, `fock`,\\n`overlap`, etc).\\n\\nWARNING: these indices are local to this fragment. That is, an index\\nof 0 represents the first atom in this fragment, and not in the\\nfirst atom in the full system topology.',\n                'fragment_distance': 'Distance between monomers in the dimer. If the nmer is not a dimer, this\\nwill not be present.',\n                'molecular_orbital_energies': 'The molecular orbital energies for the n-mer. If present, there must be\\none entry per basis function.'}},\n              'k': 'record',\n              't': {'h_core': {'k': 'optional',\n                't': {'doc': {'fields': {'shape': 'The size of each dimensions of `Tensor`. The length of this field tells\\nus the dimension of the `Tensor`. The value of each element tells us the\\nsize of that dimension. For example, if `shape` is `[2, 3, 4]`, then the\\n`Tensor` is 3-dimensional, and the size of the first dimension is 2, the\\nsize of the second dimension is 3, and the size of the third dimension\\nis 4. In combination with `kind`, the `shape` tells us how to parse the\\n`data` field.',\n                   'data': 'Densely packed data. To parse it, we need to consdier `kind` and\\n`shape`.',\n                   'kind': 'In combination with `shape`, the `kind` tells us how to parse the `data`\\nfield.'}},\n                 'k': 'record',\n                 't': {'shape': {'k': 'array', 't': 'u32'},\n                  'data': {'k': 'array', 't': 'f64'},\n                  'kind': {'k': 'enum',\n                   't': [{'Dense': 1},\n                    {'SquareSymmetric': 2},\n                    {'LowerTriangular': 3}],\n                   'n': 'TensorKind'}},\n                 'n': 'Tensorf64'}},\n               'hf_energy': {'k': 'optional', 't': 'f64'},\n               'num_iters': 'u32',\n               'fock': {'k': 'optional',\n                't': {'doc': {'fields': {'data': 'Densely packed data. To parse it, we need to consdier `kind` and\\n`shape`.',\n                   'kind': 'In combination with `shape`, the `kind` tells us how to parse the `data`\\nfield.',\n                   'shape': 'The size of each dimensions of `Tensor`. The length of this field tells\\nus the dimension of the `Tensor`. The value of each element tells us the\\nsize of that dimension. For example, if `shape` is `[2, 3, 4]`, then the\\n`Tensor` is 3-dimensional, and the size of the first dimension is 2, the\\nsize of the second dimension is 3, and the size of the third dimension\\nis 4. In combination with `kind`, the `shape` tells us how to parse the\\n`data` field.'}},\n                 'k': 'record',\n                 't': {'kind': {'k': 'enum',\n                   't': [{'Dense': 1},\n                    {'SquareSymmetric': 2},\n                    {'LowerTriangular': 3}],\n                   'n': 'TensorKind'},\n                  'shape': {'k': 'array', 't': 'u32'},\n                  'data': {'k': 'array', 't': 'f64'}},\n                 'n': 'Tensorf64'}},\n               'h_caps': {'k': 'optional',\n                't': {'k': 'array', 't': {'k': 'alias', 't': 'u32'}}},\n               'hf_gradients': {'k': 'optional',\n                't': {'k': 'array', 't': 'f64'}},\n               'delta_mp2_ss_correction': {'k': 'optional', 't': 'f64'},\n               'bond_orders': {'k': 'optional',\n                't': {'k': 'array', 't': {'k': 'array', 't': 'f64'}}},\n               'fragment_distance': {'k': 'optional', 't': 'f64'},\n               'density': {'k': 'optional',\n                't': {'doc': {'fields': {'shape': 'The size of each dimensions of `Tensor`. The length of this field tells\\nus the dimension of the `Tensor`. The value of each element tells us the\\nsize of that dimension. For example, if `shape` is `[2, 3, 4]`, then the\\n`Tensor` is 3-dimensional, and the size of the first dimension is 2, the\\nsize of the second dimension is 3, and the size of the third dimension\\nis 4. In combination with `kind`, the `shape` tells us how to parse the\\n`data` field.',\n                   'data': 'Densely packed data. To parse it, we need to consdier `kind` and\\n`shape`.',\n                   'kind': 'In combination with `shape`, the `kind` tells us how to parse the `data`\\nfield.'}},\n                 'k': 'record',\n                 't': {'kind': {'k': 'enum',\n                   't': [{'Dense': 1},\n                    {'SquareSymmetric': 2},\n                    {'LowerTriangular': 3}],\n                   'n': 'TensorKind'},\n                  'data': {'k': 'array', 't': 'f64'},\n                  'shape': {'k': 'array', 't': 'u32'}},\n                 'n': 'Tensorf64'}},\n               'schema_version': {'k': 'alias', 't': 'string'},\n               'mp2_os_correction': {'k': 'optional', 't': 'f64'},\n               'delta_hf_energy': {'k': 'optional', 't': 'f64'},\n               'mp2_ss_correction': {'k': 'optional', 't': 'f64'},\n               'coeffs_initial': {'k': 'optional',\n                't': {'doc': {'fields': {'data': 'Densely packed data. To parse it, we need to consdier `kind` and\\n`shape`.',\n                   'shape': 'The size of each dimensions of `Tensor`. The length of this field tells\\nus the dimension of the `Tensor`. The value of each element tells us the\\nsize of that dimension. For example, if `shape` is `[2, 3, 4]`, then the\\n`Tensor` is 3-dimensional, and the size of the first dimension is 2, the\\nsize of the second dimension is 3, and the size of the third dimension\\nis 4. In combination with `kind`, the `shape` tells us how to parse the\\n`data` field.',\n                   'kind': 'In combination with `shape`, the `kind` tells us how to parse the `data`\\nfield.'}},\n                 'k': 'record',\n                 't': {'shape': {'k': 'array', 't': 'u32'},\n                  'kind': {'k': 'enum',\n                   't': [{'Dense': 1},\n                    {'SquareSymmetric': 2},\n                    {'LowerTriangular': 3}],\n                   'n': 'TensorKind'},\n                  'data': {'k': 'array', 't': 'f64'}},\n                 'n': 'Tensorf64'}},\n               'coeffs_final': {'k': 'optional',\n                't': {'doc': {'fields': {'data': 'Densely packed data. To parse it, we need to consdier `kind` and\\n`shape`.',\n                   'shape': 'The size of each dimensions of `Tensor`. The length of this field tells\\nus the dimension of the `Tensor`. The value of each element tells us the\\nsize of that dimension. For example, if `shape` is `[2, 3, 4]`, then the\\n`Tensor` is 3-dimensional, and the size of the first dimension is 2, the\\nsize of the second dimension is 3, and the size of the third dimension\\nis 4. In combination with `kind`, the `shape` tells us how to parse the\\n`data` field.',\n                   'kind': 'In combination with `shape`, the `kind` tells us how to parse the `data`\\nfield.'}},\n                 'k': 'record',\n                 't': {'data': {'k': 'array', 't': 'f64'},\n                  'shape': {'k': 'array', 't': 'u32'},\n                  'kind': {'k': 'enum',\n                   't': [{'Dense': 1},\n                    {'SquareSymmetric': 2},\n                    {'LowerTriangular': 3}],\n                   'n': 'TensorKind'}},\n                 'n': 'Tensorf64'}},\n               'delta_mp2_os_correction': {'k': 'optional', 't': 'f64'},\n               'num_basis_fns': 'u32',\n               'fragments': {'k': 'array', 't': {'k': 'alias', 't': 'u32'}},\n               'overlap': {'k': 'optional',\n                't': {'doc': {'fields': {'data': 'Densely packed data. To parse it, we need to consdier `kind` and\\n`shape`.',\n                   'kind': 'In combination with `shape`, the `kind` tells us how to parse the `data`\\nfield.',\n                   'shape': 'The size of each dimensions of `Tensor`. The length of this field tells\\nus the dimension of the `Tensor`. The value of each element tells us the\\nsize of that dimension. For example, if `shape` is `[2, 3, 4]`, then the\\n`Tensor` is 3-dimensional, and the size of the first dimension is 2, the\\nsize of the second dimension is 3, and the size of the third dimension\\nis 4. In combination with `kind`, the `shape` tells us how to parse the\\n`data` field.'}},\n                 'k': 'record',\n                 't': {'kind': {'k': 'enum',\n                   't': [{'Dense': 1},\n                    {'SquareSymmetric': 2},\n                    {'LowerTriangular': 3}],\n                   'n': 'TensorKind'},\n                  'shape': {'k': 'array', 't': 'u32'},\n                  'data': {'k': 'array', 't': 'f64'}},\n                 'n': 'Tensorf64'}},\n               'molecular_orbital_energies': {'k': 'optional',\n                't': {'k': 'array', 't': 'f64'}},\n               'mulliken_charges': {'k': 'optional',\n                't': {'k': 'array', 't': 'f64'}},\n               'mp2_gradients': {'k': 'optional',\n                't': {'k': 'array', 't': 'f64'}}},\n              'n': 'Nmer'}}},\n           'expanded_density': {'k': 'optional',\n            't': {'doc': {'fields': {'data': 'Densely packed data. To parse it, we need to consdier `kind` and\\n`shape`.',\n               'kind': 'In combination with `shape`, the `kind` tells us how to parse the `data`\\nfield.',\n               'shape': 'The size of each dimensions of `Tensor`. The length of this field tells\\nus the dimension of the `Tensor`. The value of each element tells us the\\nsize of that dimension. For example, if `shape` is `[2, 3, 4]`, then the\\n`Tensor` is 3-dimensional, and the size of the first dimension is 2, the\\nsize of the second dimension is 3, and the size of the third dimension\\nis 4. In combination with `kind`, the `shape` tells us how to parse the\\n`data` field.'}},\n             'k': 'record',\n             't': {'shape': {'k': 'array', 't': 'u32'},\n              'data': {'k': 'array', 't': 'f64'},\n              'kind': {'k': 'enum',\n               't': [{'Dense': 1},\n                {'SquareSymmetric': 2},\n                {'LowerTriangular': 3}],\n               'n': 'TensorKind'}},\n             'n': 'Tensorf64'}},\n           'num_iters': 'u32',\n           'classical_water_energy': {'k': 'optional', 't': 'f64'},\n           'expanded_mp2_ss_correction': {'k': 'optional', 't': 'f64'},\n           'distance_metric': {'k': 'optional',\n            't': {'k': 'enum',\n             't': [{'Centroid': 1}, {'ClosestPair': 2}],\n             'n': 'FragmentDistanceMetric'}}},\n          'n': 'QMMBE'}}},\n       'schema_version': {'k': 'alias', 't': 'string'}},\n      'n': 'Output'}},\n    'size': 'u64',\n    'format': {'k': 'optional',\n     't': {'k': 'enum', 't': ['json', 'bin'], 'n': 'ObjectFormat'}}},\n   'n': 'Object'},\n  'string']}",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Quickstarts",
      "PLIP — Protein ligand interaction profiling"
    ]
  },
  {
    "objectID": "Previous Versions/Quickstarts/auto3d.html",
    "href": "Previous Versions/Quickstarts/auto3d.html",
    "title": "Auto3D",
    "section": "",
    "text": "Auto3D is a module for generating low-energy conformers from SMILES/SDF. Over the development process, we also added the APIs for computing single point energies, optimizing geometries, find stable tautomers. Please cite “Auto3D: Automatic Generation of the Low-Energy 3D Structures with ANI Neural Network Potentials”. https://doi.org/10.1021/acs.jcim.2c00817”\n\nFull Code\n\nimport rush\n\nclient = rush.build_blocking_provider_with_functions(\n    access_token=PUT_YOUR_TOKEN_HERE\n    # for example, if your token is 00000000-dddd-cccc-0000-11111111,\n    # then you should put access_token=\"00000000-dddd-cccc-0000-11111111\"\n    # (including the double quotes)\n)\n\n# setup an SMI file that contains the SMILES string of our ligand\nligand_smi_filename = client.workspace / \"ligand.smi\"\nligand_smi_filename.write_text(\n    \"c1nc(c2c(n1)n(cn2)[C@H]3[C@@H]([C@@H]([C@H](O3)CO[P@@](=O)(O)O[P@](=O)(O)OP(=O)(O)O)O)O)N 1\"\n)\n\n# run Auto3D which will give us 3 conformers of our ligand\n# in the SDF format and the QDXF format\nligand_sdf_handle, ligand_qdxf_handle = client.auto3d(\n    ligand_smi_filename,  # the filename that stores our ligand\n    \"smi\",  # the format of the file\n    {\n        \"k\": 3,  # number of conformers to generate\n        \"use_gpu\": True,  # use GPU for faster compute\n    },\n    tags=[\"auto3d_quickstart\"],\n    resources={\n        \"gpus\": 1,  # the number of GPUs to use\n        \"storage\": 5,  # the amount of storage to use\n        \"storage_units\": \"MB\",  # the units of storage (here we are using megabytes)\n    },\n)\n\n# print the status of all jobs\nprint(client.status())\n\n# download the results (this will block until the Auto3D job has completed)\nligand_sdf = ligand_sdf_handle.download()\nligand_qdxf = ligand_qdxf_handle.download()\n\nprint(\n    ligand_sdf.read_text()[0:100]\n)  # print the first 100 characters of the SDF version of the result\nprint(\n    ligand_qdxf.read_text()[0:100]\n)  # print the first 100 characters of the QDXF version of the result\n\n2024-05-13 14:10:32,457 - rush - INFO - Restoring by default via env\n2024-05-13 14:10:35,656 - rush - INFO - Trying to restore job with tags: ['auto3d_quickstart'] and path: github:talo/tengu-auto3d/05fbc5014bf4e7f2890e70428c62234cdb902336#auto3d_tengu\n2024-05-13 14:10:35,771 - rush - INFO - Restoring job from previous run with id fc079059-cad1-40cd-b08e-27bb3242c198\n{}\n1\n     RDKit          3D\n\n 47 49  0  0  0  0  0  0  0  0999 V2000\n   -2.9826    3.5317    1.6056 N  \n[\n  {\n    \"topology\": {\n      \"version\": \"V1\",\n      \"symbols\": [\n        \"N\",\n        \"C\",",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Quickstarts",
      "Auto3D"
    ]
  },
  {
    "objectID": "Previous Versions/Quickstarts/protein-ligand-interactions-sample.html",
    "href": "Previous Versions/Quickstarts/protein-ligand-interactions-sample.html",
    "title": "PLIP — Protein ligand interaction profiling",
    "section": "",
    "text": "See the tutorial.\n\n# Get a pdb to work with\n# We use the pdb-tools cli here but you can download directly from rcsb.org\n!pdb_fetch '1MBN' &gt; '1MBN.pdb'\n\n\nfrom pathlib import Path\n\nimport rush\n\nclient = rush.build_blocking_provider_with_functions(batch_tags=[\"plip\"])\noutput_conformer, output_txt = client.plip_pdb(client.workspace / \"1MBN.pdb\")\n\nprint(output_conformer.download().read_text()[0:50], \"...\")\nprint(output_txt.download().read_text()[0:50], \"...\")\n\n2024-05-07 21:38:46,369 - rush - INFO - Argument a889c69b-eb73-4909-9e5e-838262608630 is now ModuleInstanceStatus.RESOLVING\n2024-05-07 21:38:51,112 - rush - INFO - Argument a889c69b-eb73-4909-9e5e-838262608630 is now ModuleInstanceStatus.ADMITTED\n2024-05-07 21:38:58,150 - rush - INFO - Argument a889c69b-eb73-4909-9e5e-838262608630 is now ModuleInstanceStatus.DISPATCHED\n2024-05-07 21:38:59,312 - rush - INFO - Argument a889c69b-eb73-4909-9e5e-838262608630 is now ModuleInstanceStatus.AWAITING_UPLOAD\n{\n  \"topology\": {\n    \"version\": \"V1\",\n    \"symbol ...\nPrediction of noncovalent interactions for PDB str ...",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Quickstarts",
      "PLIP — Protein ligand interaction profiling"
    ]
  },
  {
    "objectID": "Previous Versions/Quickstarts/hermes_hartree_fock_energy_calculation-sample.html",
    "href": "Previous Versions/Quickstarts/hermes_hartree_fock_energy_calculation-sample.html",
    "title": "Hermes — Run a basic Hartree-Fock energy calculation",
    "section": "",
    "text": "See the tutorial for an in-depth explanation of how the Hermes Hartree-Fock energy calculation works.\n\n# Get a pdb to work with\n# We use the pdb-tools cli here, but you can download directly from rcsb.org\n!pdb_fetch '1brs' | pdb_selchain -A | pdb_delhetatm &gt; '1B39_A_nohet.pdb'\n!ls\n\n1B39_A_nohet.pdb\n\n\n\nimport json\nfrom pathlib import Path\n\nimport rush\n\nclient = rush.build_blocking_provider_with_functions(\n    batch_tags=[\"hermes_quickstart\"],\n)\n\nprepared_protein_qdxf, prepared_protein_pdb = client.prepare_protein(\n    client.workspace / \"1B39_A_nohet.pdb\", None, None\n)\n\n# There may be multiple conformers, so select the first one\n(first_conformer,) = client.pick_conformer(prepared_protein_qdxf, 0)\n\n# Fragment the protein so that we can run a quantum energy calculation\n(fragmented_protein,) = client.fragment_aa(first_conformer, 1, \"All\", 30)\n\nfragmented_protein_contents = json.loads(\n    fragmented_protein.download().read_text()\n)\n\n# Quantum energy calculation\n(hermes_energy,) = client.hermes_energy(\n    fragmented_protein,\n    {},\n    {\n        \"basis\": \"STO-3G\",\n        \"aux_basis\": \"6-31G\",\n        \"method\": \"RestrictedHF\",\n    },  # configuration for a fast converging, low accuracy run\n    None,\n    {\n        \"level\": \"Dimer\",\n        \"cutoffs\": {\"dimer\": 15},\n        \"reference_fragment\": len(\n            fragmented_protein_contents[\"topology\"][\"fragments\"]\n        )\n        - 1,\n    },\n    None,\n    resources={\"gpus\": 1, \"storage\": 100, \"storage_units\": \"MB\", \"walltime\": 60},\n)\n\nenergy = json.load(open(hermes_energy.download(), \"r\"))\n# Let's look at the expanded Hartree Fock energy\nenergy[\"expanded_hf_energy\"]\n\n2024-04-10 15:48:19,452 - rush - INFO - Not restoring by default via default\n2024-04-10 15:48:22,228 - rush - INFO - Argument 3d0e45e8-af50-4a37-bdb3-9de0c3cb0110 is now ModuleInstanceStatus.RESOLVING\n2024-04-10 15:49:11,312 - rush - INFO - Argument 3d0e45e8-af50-4a37-bdb3-9de0c3cb0110 is now ModuleInstanceStatus.ADMITTED\n2024-04-10 15:49:14,572 - rush - INFO - Argument 3d0e45e8-af50-4a37-bdb3-9de0c3cb0110 is now ModuleInstanceStatus.DISPATCHED\n2024-04-10 15:49:15,666 - rush - INFO - Argument 3d0e45e8-af50-4a37-bdb3-9de0c3cb0110 is now ModuleInstanceStatus.AWAITING_UPLOAD\n2024-04-10 15:49:31,258 - rush - INFO - Argument 607a0a9f-17c4-4fa4-bb6b-59fd8048116d is now ModuleInstanceStatus.RESOLVING\n2024-04-10 15:49:36,729 - rush - INFO - Argument 607a0a9f-17c4-4fa4-bb6b-59fd8048116d is now ModuleInstanceStatus.ADMITTED\n2024-04-10 15:49:38,919 - rush - INFO - Argument 607a0a9f-17c4-4fa4-bb6b-59fd8048116d is now ModuleInstanceStatus.DISPATCHED\n2024-04-10 15:49:40,058 - rush - INFO - Argument 607a0a9f-17c4-4fa4-bb6b-59fd8048116d is now ModuleInstanceStatus.RUNNING\n2024-04-10 15:55:35,729 - rush - INFO - Argument 607a0a9f-17c4-4fa4-bb6b-59fd8048116d is now ModuleInstanceStatus.AWAITING_UPLOAD\n\n\n0.5647421741541621",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Quickstarts",
      "Hermes — Run a basic Hartree-Fock energy calculation"
    ]
  },
  {
    "objectID": "Previous Versions/Tutorials/auto3d_conformer_tautomer_generation.html",
    "href": "Previous Versions/Tutorials/auto3d_conformer_tautomer_generation.html",
    "title": "Run a basic Hermes Hartree-Fock energy calculation on ligand conformers from Auto3d",
    "section": "",
    "text": "In this notebook, we’ll perform a hermes energy calculation on a ligand derived from a smiles string",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Tutorials",
      "Run a basic Hermes Hartree-Fock energy calculation on ligand conformers from Auto3d"
    ]
  },
  {
    "objectID": "Previous Versions/Tutorials/auto3d_conformer_tautomer_generation.html#imports",
    "href": "Previous Versions/Tutorials/auto3d_conformer_tautomer_generation.html#imports",
    "title": "Run a basic Hermes Hartree-Fock energy calculation on ligand conformers from Auto3d",
    "section": "1.0) Imports",
    "text": "1.0) Imports\n\nimport json\nimport os\nimport sys\nimport tarfile\n\nfrom pdbtools import *\nimport requests\nfrom datetime import datetime\nfrom pathlib import Path\nimport py3Dmol\n\nimport rush",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Tutorials",
      "Run a basic Hermes Hartree-Fock energy calculation on ligand conformers from Auto3d"
    ]
  },
  {
    "objectID": "Previous Versions/Tutorials/auto3d_conformer_tautomer_generation.html#configuration",
    "href": "Previous Versions/Tutorials/auto3d_conformer_tautomer_generation.html#configuration",
    "title": "Run a basic Hermes Hartree-Fock energy calculation on ligand conformers from Auto3d",
    "section": "1.1) Configuration",
    "text": "1.1) Configuration\n\nEXPERIMENT = \"tengu-py-auto3d_hermes\"\nLIGAND_SMILES = \"CC(=O)OC1=CC=CC=C1C(=O)O \"\nLIGAND = \"ASPRIN\"\nTAGS = [\"qdx\", EXPERIMENT, LIGAND]",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Tutorials",
      "Run a basic Hermes Hartree-Fock energy calculation on ligand conformers from Auto3d"
    ]
  },
  {
    "objectID": "Previous Versions/Tutorials/auto3d_conformer_tautomer_generation.html#build-your-client",
    "href": "Previous Versions/Tutorials/auto3d_conformer_tautomer_generation.html#build-your-client",
    "title": "Run a basic Hermes Hartree-Fock energy calculation on ligand conformers from Auto3d",
    "section": "1.2) Build your client",
    "text": "1.2) Build your client\n\n# Get our client, for calling modules and using the rush API\nclient = rush.build_blocking_provider_with_functions(batch_tags=TAGS)",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Tutorials",
      "Run a basic Hermes Hartree-Fock energy calculation on ligand conformers from Auto3d"
    ]
  },
  {
    "objectID": "Previous Versions/Tutorials/protein_ligand_interactions.html",
    "href": "Previous Versions/Tutorials/protein_ligand_interactions.html",
    "title": "PLIP — Protein ligand interaction profiling",
    "section": "",
    "text": "This notebook will walk us through using PLIP for identification of non-covalent interactions between biological macromolecules and their ligands.\nPLIP implementation paper: Adasme et al. PLIP 2021: expanding the scope of the protein-ligand interaction profiler to DNA and RNA. NAR 2021",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Tutorials",
      "PLIP — Protein ligand interaction profiling"
    ]
  },
  {
    "objectID": "Previous Versions/Tutorials/protein_ligand_interactions.html#imports",
    "href": "Previous Versions/Tutorials/protein_ligand_interactions.html#imports",
    "title": "PLIP — Protein ligand interaction profiling",
    "section": "1.0) Imports",
    "text": "1.0) Imports\n\nimport os\nimport json\nfrom pathlib import Path\n\nimport rush\nfrom pdbtools import pdb_fetch",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Tutorials",
      "PLIP — Protein ligand interaction profiling"
    ]
  },
  {
    "objectID": "Previous Versions/Tutorials/protein_ligand_interactions.html#configuration",
    "href": "Previous Versions/Tutorials/protein_ligand_interactions.html#configuration",
    "title": "PLIP — Protein ligand interaction profiling",
    "section": "1.1) Configuration",
    "text": "1.1) Configuration\nLet’s set some global variables that define our project.\n\nDESCRIPTION = \"plip-inference-notebook\"\nTAGS = [\"rush-py\", \"plip\", \"notebook\"]",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Tutorials",
      "PLIP — Protein ligand interaction profiling"
    ]
  },
  {
    "objectID": "Previous Versions/Tutorials/protein_ligand_interactions.html#build-your-client",
    "href": "Previous Versions/Tutorials/protein_ligand_interactions.html#build-your-client",
    "title": "PLIP — Protein ligand interaction profiling",
    "section": "1.2) Build your client",
    "text": "1.2) Build your client\n\nos.environ[\"RUSH_TOKEN\"] = YOUR_TOKEN\nclient = rush.build_blocking_provider_with_functions(\n    batch_tags=TAGS, workspace=WORK_DIR\n)",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Tutorials",
      "PLIP — Protein ligand interaction profiling"
    ]
  },
  {
    "objectID": "Previous Versions/Tutorials/protein_ligand_interactions.html#fetch-example-pdb",
    "href": "Previous Versions/Tutorials/protein_ligand_interactions.html#fetch-example-pdb",
    "title": "PLIP — Protein ligand interaction profiling",
    "section": "2.0) Fetch example PDB",
    "text": "2.0) Fetch example PDB\nNote that PLIP requires a PDB file of a protein-ligand complex.\n\nPDB_ID = \"1GIH\"\nFILE_NAME = f\"{PDB_ID}.pdb\"\nFILE_PATH = WORK_DIR / FILE_NAME\n\n\ncomplex = list(pdb_fetch.fetch_structure(PDB_ID))\n\nwith open(FILE_PATH, \"w\") as f:\n    for line in complex:\n        f.write(line)",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Tutorials",
      "PLIP — Protein ligand interaction profiling"
    ]
  },
  {
    "objectID": "Previous Versions/Tutorials/protein_ligand_interactions.html#arguments",
    "href": "Previous Versions/Tutorials/protein_ligand_interactions.html#arguments",
    "title": "PLIP — Protein ligand interaction profiling",
    "section": "3.1) Arguments",
    "text": "3.1) Arguments\n\nhelp(client.plip_pdb)\n\nHelp on function plip_pdb in module rush.provider:\n\nplip_pdb(*args: *tuple[RushObject[bytes]], target: 'Target | None' = None, resources: 'Resources | None' = None, tags: 'list[str] | None' = None, restore: 'bool | None' = None) -&gt; tuple[RushObject[Record], RushObject[bytes]]\n    Run PLIP on the input PDB file of a protein-ligand complex to obtain interaction data.\n\n\n    Module version:\n    `github:talo/tengu-plip/790c01804c0942fb11df8bc91c5d3d983ca092af#plip_tengu_pdb`\n\n    QDX Type Description:\n\n        input_complex_pdb_file: Object {\n            size: u32,\n            path: @$PDB,\n            format: ObjectFormat[json | bin]?\n        }\n        -&gt;\n        output_conformer: Object[Conformer];\n        output_txt_file: Object[@$PDB]\n\n\n    :param input_complex_pdb_file: The protein-ligand complex as a PDB file; ligand should be the only HETATM lines.\n    :return output_conformer: A QDX Conformer of the complex with the computed interaction data\n    :return output_txt_file: The output txt report from the PLIP run\n\n\n\nWe can see from the above help documentation that we need to pass the Path to our PDB file as an argument.",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Tutorials",
      "PLIP — Protein ligand interaction profiling"
    ]
  },
  {
    "objectID": "Previous Versions/Tutorials/protein_ligand_interactions.html#run-plip",
    "href": "Previous Versions/Tutorials/protein_ligand_interactions.html#run-plip",
    "title": "PLIP — Protein ligand interaction profiling",
    "section": "3.2) Run PLIP",
    "text": "3.2) Run PLIP\nFinally, we run PLIP so we can identify interactions between the ligand and the protein within our protein complex.\n\nPLIP_RESOURCES = {\"storage\": 1024_000}\n\noutput_conformer, output_txt = client.plip_pdb(\n    FILE_PATH, resources=PLIP_RESOURCES\n)",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Tutorials",
      "PLIP — Protein ligand interaction profiling"
    ]
  },
  {
    "objectID": "Previous Versions/Tutorials/protein_ligand_interactions.html#get-output-conformer",
    "href": "Previous Versions/Tutorials/protein_ligand_interactions.html#get-output-conformer",
    "title": "PLIP — Protein ligand interaction profiling",
    "section": "3.3) Get output conformer",
    "text": "3.3) Get output conformer\nHere, we get the output Conformer (in QDXF format) that is enriched with binding_site_interactions by PLIP.\n\noutput_conformer = json.load(output_conformer.download().open())\n\n2024-05-07 21:33:35,990 - rush - INFO - Argument c3bed94c-2586-46fb-97db-eeab1217c00c is now ModuleInstanceStatus.RESOLVING\n2024-05-07 21:33:40,599 - rush - INFO - Argument c3bed94c-2586-46fb-97db-eeab1217c00c is now ModuleInstanceStatus.ADMITTED\n2024-05-07 21:33:46,334 - rush - INFO - Argument c3bed94c-2586-46fb-97db-eeab1217c00c is now ModuleInstanceStatus.DISPATCHED\n2024-05-07 21:33:47,497 - rush - INFO - Argument c3bed94c-2586-46fb-97db-eeab1217c00c is now ModuleInstanceStatus.AWAITING_UPLOAD\n\n\n\noutput_conformer[\"binding_site_interactions\"]\n\n[{'kind': 'Hydrophobic',\n  'ligand_residue_idx': 501,\n  'ligand_atom_idx': 2227,\n  'ligand_xyz': [5.034, 10.623, 29.029],\n  'receptor_amino_acid_idx': 18,\n  'receptor_atom_idx': 140,\n  'receptor_xyz': [6.814, 7.439, 30.53],\n  'receptor_is_donor': False,\n  'receptor_is_charged': False,\n  'receptor_is_positively_charged': False,\n  'pi_stack_kind': None},\n {'kind': 'Hydrophobic',\n  'ligand_residue_idx': 501,\n  'ligand_atom_idx': 2233,\n  'ligand_xyz': [3.287, 9.093, 27.493],\n  'receptor_amino_acid_idx': 31,\n  'receptor_atom_idx': 242,\n  'receptor_xyz': [3.539, 5.677, 28.924],\n  'receptor_is_donor': False,\n  'receptor_is_charged': False,\n  'receptor_is_positively_charged': False,\n  'pi_stack_kind': None},\n {'kind': 'Hydrophobic',\n  'ligand_residue_idx': 501,\n  'ligand_atom_idx': 2238,\n  'ligand_xyz': [2.847, 9.698, 28.682],\n  'receptor_amino_acid_idx': 64,\n  'receptor_atom_idx': 443,\n  'receptor_xyz': [-0.699, 10.68, 27.296],\n  'receptor_is_donor': False,\n  'receptor_is_charged': False,\n  'receptor_is_positively_charged': False,\n  'pi_stack_kind': None},\n {'kind': 'Hydrophobic',\n  'ligand_residue_idx': 501,\n  'ligand_atom_idx': 2238,\n  'ligand_xyz': [2.847, 9.698, 28.682],\n  'receptor_amino_acid_idx': 80,\n  'receptor_atom_idx': 575,\n  'receptor_xyz': [0.229, 7.961, 30.384],\n  'receptor_is_donor': False,\n  'receptor_is_charged': False,\n  'receptor_is_positively_charged': False,\n  'pi_stack_kind': None},\n {'kind': 'Hydrophobic',\n  'ligand_residue_idx': 501,\n  'ligand_atom_idx': 2232,\n  'ligand_xyz': [3.705, 10.464, 29.46],\n  'receptor_amino_acid_idx': 80,\n  'receptor_atom_idx': 578,\n  'receptor_xyz': [1.594, 9.055, 32.199],\n  'receptor_is_donor': False,\n  'receptor_is_charged': False,\n  'receptor_is_positively_charged': False,\n  'pi_stack_kind': None},\n {'kind': 'Hydrophobic',\n  'ligand_residue_idx': 501,\n  'ligand_atom_idx': 2233,\n  'ligand_xyz': [3.287, 9.093, 27.493],\n  'receptor_amino_acid_idx': 134,\n  'receptor_atom_idx': 1021,\n  'receptor_xyz': [2.881, 10.821, 24.334],\n  'receptor_is_donor': False,\n  'receptor_is_charged': False,\n  'receptor_is_positively_charged': False,\n  'pi_stack_kind': None},\n {'kind': 'HydrogenBond',\n  'ligand_residue_idx': 501,\n  'ligand_atom_idx': 2237,\n  'ligand_xyz': [6.061, 11.989, 30.681],\n  'receptor_amino_acid_idx': 33,\n  'receptor_atom_idx': 259,\n  'receptor_xyz': [7.625, 11.678, 33.692],\n  'receptor_is_donor': True,\n  'receptor_is_charged': False,\n  'receptor_is_positively_charged': False,\n  'pi_stack_kind': None},\n {'kind': 'HydrogenBond',\n  'ligand_residue_idx': 501,\n  'ligand_atom_idx': 2241,\n  'ligand_xyz': [3.359, 7.522, 24.975],\n  'receptor_amino_acid_idx': 83,\n  'receptor_atom_idx': 602,\n  'receptor_xyz': [1.8, 6.045, 23.112],\n  'receptor_is_donor': True,\n  'receptor_is_charged': False,\n  'receptor_is_positively_charged': False,\n  'pi_stack_kind': None},\n {'kind': 'HydrogenBond',\n  'ligand_residue_idx': 501,\n  'ligand_atom_idx': 2240,\n  'ligand_xyz': [5.341, 7.404, 23.937],\n  'receptor_amino_acid_idx': 83,\n  'receptor_atom_idx': 605,\n  'receptor_xyz': [4.17, 6.19, 22.039],\n  'receptor_is_donor': False,\n  'receptor_is_charged': False,\n  'receptor_is_positively_charged': False,\n  'pi_stack_kind': None}]",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Tutorials",
      "PLIP — Protein ligand interaction profiling"
    ]
  },
  {
    "objectID": "Previous Versions/Tutorials/protein_ligand_interactions.html#get-plip-output-document",
    "href": "Previous Versions/Tutorials/protein_ligand_interactions.html#get-plip-output-document",
    "title": "PLIP — Protein ligand interaction profiling",
    "section": "3.4) Get PLIP output document",
    "text": "3.4) Get PLIP output document\nPLIP also returns a link to the output document of the results of the PLIP output.\n\noutput_txt.download(\"plip_output.txt\", overwrite=True).open().readline()\n\n'Prediction of noncovalent interactions for PDB structure 1GIH\\n'",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Tutorials",
      "PLIP — Protein ligand interaction profiling"
    ]
  },
  {
    "objectID": "Previous Versions/Tutorials/gmx_restart.html",
    "href": "Previous Versions/Tutorials/gmx_restart.html",
    "title": "GROMACS Resume - Start a long GROMACS run that times out, and resume it",
    "section": "",
    "text": "On the supercomputers, a maximum runtime of 24h is enforced. If a longer GROMACS run is needed, the run can easily be resumed. One of the outputs provided by the Rush gmx module is designed to be used as the input to the gmx_resume module, which will resume the run from the latest checkpoint. The outputs to this module are identical to those of the gmx module itself, so the run can be resumed as many times as necessary to finish it.",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Tutorials",
      "GROMACS Resume -  Start a long GROMACS run that times out, and resume it"
    ]
  },
  {
    "objectID": "Previous Versions/Tutorials/gmx_restart.html#imports",
    "href": "Previous Versions/Tutorials/gmx_restart.html#imports",
    "title": "GROMACS Resume - Start a long GROMACS run that times out, and resume it",
    "section": "0.0) Imports",
    "text": "0.0) Imports\n\nfrom pathlib import Path\nimport time\n\nimport rush\n\n\nRUSH_TOKEN = os.getenv(\"RUSH_TOKEN\") or \"YOUR_TOKEN_HERE\"\nclient = rush.build_blocking_provider_with_functions(access_token=RUSH_TOKEN)\n\n2024-04-10 17:21:43,456 - rush - INFO - Not restoring by default via default\n2024-04-10 17:21:43,633 - rush - WARNING - Module plip has a different version on the server: github:talo/tengu-plip/1776ec43500276f85b33e53d900388134b00992f#plip_tengu.\n                                Use `.update_modules()` to update the lock file\n2024-04-10 17:21:43,633 - rush - WARNING - Module auto3d has a different version on the server: github:talo/tengu-auto3d/e1a1a06ea10a6baefea33f2bd0be8c1e0df5d56c#auto3d_tengu.\n                                Use `.update_modules()` to update the lock file\n2024-04-10 17:21:43,633 - rush - WARNING - Module hermes_energy has a different version on the server: github:talo/tengu-prelude/d14c895b2bc40ab59136382f5b848523bf70436c#hermes_energy.\n                                Use `.update_modules()` to update the lock file\n2024-04-10 17:21:43,634 - rush - WARNING - Module github:talo/tengu-p2rank/42e6c56a5bfa027d4ca3e8d190b9469b561cf37c#p2rank_tengu is not in the lock file\n2024-04-10 17:21:43,634 - rush - WARNING - Module pick_conformer has a different version on the server: github:talo/tengu-prelude/6fa3b9382a0011780681cec36e014dc9cc7686df#pick_conformer.\n                                Use `.update_modules()` to update the lock file\n2024-04-10 17:21:43,634 - rush - WARNING - Module fragment_aa has a different version on the server: github:talo/tengu-prelude/6fa3b9382a0011780681cec36e014dc9cc7686df#fragment_aa.\n                                Use `.update_modules()` to update the lock file\n2024-04-10 17:21:43,634 - rush - WARNING - Module fragment has a different version on the server: github:talo/tengu-prelude/6fa3b9382a0011780681cec36e014dc9cc7686df#fragment.\n                                Use `.update_modules()` to update the lock file\n2024-04-10 17:21:43,634 - rush - WARNING - Module concat has a different version on the server: github:talo/tengu-prelude/6fa3b9382a0011780681cec36e014dc9cc7686df#concat.\n                                Use `.update_modules()` to update the lock file\n2024-04-10 17:21:43,634 - rush - WARNING - Module convert has a different version on the server: github:talo/tengu-prelude/6fa3b9382a0011780681cec36e014dc9cc7686df#convert.\n                                Use `.update_modules()` to update the lock file\n2024-04-10 17:21:43,635 - rush - WARNING - Module github:talo/tengu-module-example/5cbcd752c614769b2e1bf18a9bc8031034e471a8#tengu_echo is not in the lock file\n2024-04-10 17:21:43,635 - rush - WARNING - Module github:talo/tengu-module-example/d7b013bf8024c75410928e037fbaae0a01b74613#spam is not in the lock file\n2024-04-10 17:21:43,635 - rush - WARNING - Module github:talo/tengu-module-example/d7b013bf8024c75410928e037fbaae0a01b74613#delay is not in the lock file\n2024-04-10 17:21:43,635 - rush - WARNING - Module github:talo/qm_geo_opt/8030ca9dd1da58c9ef526ac7432523a2aa308a37#qm_geo_opt_tengu is not in the lock file\n2024-04-10 17:21:43,635 - rush - WARNING - Module gmx_resume has a different version on the server: github:talo/tengu-gmx/eaaa2472bd2dc67eed931fa1816fd0b46c509599#gmx_resume_tengu.\n                                Use `.update_modules()` to update the lock file\n2024-04-10 17:21:43,635 - rush - WARNING - Module gmx has a different version on the server: github:talo/tengu-gmx/9eab938f2ac983ce6764c1473851849b5e4d9b24#gmx_tengu.\n                                Use `.update_modules()` to update the lock file\n2024-04-10 17:21:43,636 - rush - WARNING - Module gmx_mmpbsa has a different version on the server: github:talo/tengu-gmx/b8b9f617eaada271beec74d9b7500916cfdfa803#gmx_mmpbsa_tengu.\n                                Use `.update_modules()` to update the lock file\n2024-04-10 17:21:43,636 - rush - WARNING - Module prepare_protein has a different version on the server: github:talo/prepare_protein/fbeca1ad893cd763b00dc275c43806c0edce03de#prepare_protein_tengu.\n                                Use `.update_modules()` to update the lock file\n2024-04-10 17:21:43,636 - rush - WARNING - Module hermes_energy_batch has a different version on the server: github:talo/tengu-prelude/464d2641a6109f6b831ec0e62a846b9283652d0f#hermes_energy_batch.\n                                Use `.update_modules()` to update the lock file\n2024-04-10 17:21:43,636 - rush - WARNING - Module github:talo/colabfold_tengu/9709de515acd5ddbe2a1cdc295da40367fcc8a32#colabfold_tengu_fold is not in the lock file\n2024-04-10 17:21:43,637 - rush - WARNING - Module github:talo/colabfold_tengu/807cdf3f1a618b2ede4f47b549d667f754df395d#colabfold_tengu_fasta_fold is not in the lock file\n2024-04-10 17:21:43,637 - rush - WARNING - Module dubai has a different version on the server: github:talo/Dubai/cf7835b4c099e19ea77e0f28e999136bcaf62e5a#dubai_tengu.\n                                Use `.update_modules()` to update the lock file\n2024-04-10 17:21:43,637 - rush - WARNING - Module pbsa has a different version on the server: github:talo/pbsa-cuda/03a11fe0a52f047a5fa424514a7c89d5f106a5d9#pbsa_tengu.\n                                Use `.update_modules()` to update the lock file",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Tutorials",
      "GROMACS Resume -  Start a long GROMACS run that times out, and resume it"
    ]
  },
  {
    "objectID": "Previous Versions/Tutorials/gmx_restart.html#input-download-and-selection",
    "href": "Previous Versions/Tutorials/gmx_restart.html#input-download-and-selection",
    "title": "GROMACS Resume - Start a long GROMACS run that times out, and resume it",
    "section": "0.1) Input Download and Selection",
    "text": "0.1) Input Download and Selection\n\n!pdb_fetch '1B39' | pdb_selchain -A | pdb_delhetatm &gt; '1B39_A_nohet.pdb'",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Tutorials",
      "GROMACS Resume -  Start a long GROMACS run that times out, and resume it"
    ]
  },
  {
    "objectID": "Previous Versions/Tutorials/gmx_restart.html#input-preparation",
    "href": "Previous Versions/Tutorials/gmx_restart.html#input-preparation",
    "title": "GROMACS Resume - Start a long GROMACS run that times out, and resume it",
    "section": "1) Input Preparation",
    "text": "1) Input Preparation\n\n_, prepared_protein_pdb = client.prepare_protein(\n    Path.cwd() / \"1B39_A_nohet.pdb\", None, None\n)",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Tutorials",
      "GROMACS Resume -  Start a long GROMACS run that times out, and resume it"
    ]
  },
  {
    "objectID": "Previous Versions/Tutorials/gmx_restart.html#run-gromacs-modules-gmx-gmx_resume",
    "href": "Previous Versions/Tutorials/gmx_restart.html#run-gromacs-modules-gmx-gmx_resume",
    "title": "GROMACS Resume - Start a long GROMACS run that times out, and resume it",
    "section": "2.1) Run GROMACS (modules: gmx, gmx_resume)",
    "text": "2.1) Run GROMACS (modules: gmx, gmx_resume)\nNext we will run a molecular dynamics simulation on our protein using gromacs via the gmx module.\nWe’ll set timeout_duration_mins = 1 so that the run times out before it finishes, and then resume via the gmx_resume module using the first output, which is the archive that contains all the necessary data for resuming the run from the last saved checkpoint.\nWe’ll set checkpoint_interval_mins = 1.0/60 so that the checkpointing takes place once per second.\nWe can restart as many times as we need to in order for the run to finish. Use a unique tag for each restarted run so that each sequential restart will be tagged and cached appropriately. See below for an example.\nFor each restarted run, please pass the same config file that was passed to the original gmx call. There is no support for shortening or extending runs, or changing any other run parameters, of runs that have already been started. Passing the same config ensures that progress is reported properly and that there are no other inconsistencies. So, the initial run config should specify the full desired run.\nOne current limitation is that the frame selection can only operate on the data generated by the last call to gmx or gmx_restart. Otherwise, the output xtc files from all the calls must be joined and processed manually.\n\ngmx_config = {\n    \"params_overrides\": {\n        \"nvt\": {\"nsteps\": 2000},\n        \"npt\": {\"nsteps\": 2000},\n        \"md\": {\"nsteps\": 150000},\n    },\n    \"frame_sel\": {\n        \"start_time_ps\": 290,\n        \"end_time_ps\": 300,\n        \"delta_time_ps\": 1,\n    },\n    \"checkpoint_interval_mins\": 1.0 / 60,\n    \"timeout_duration_mins\": 1,\n    \"num_gpus\": 1,\n    \"save_wets\": False,\n}\n\n\nresume_files_first, streaming_outputs, static_outputs, *rest = client.gmx(\n    None,\n    prepared_protein_pdb,\n    None,\n    gmx_config,\n    resources={\"gpus\": 1, \"storage\": 1, \"storage_units\": \"GB\"},\n)\n\n\nresume_files_first.get()\n\n2024-04-10 17:21:47,053 - rush - INFO - Argument ff370371-90b6-4995-8aab-41064ea67fbf is now ModuleInstanceStatus.RESOLVING\n2024-04-10 17:22:20,612 - rush - INFO - Argument ff370371-90b6-4995-8aab-41064ea67fbf is now ModuleInstanceStatus.ADMITTED\n2024-04-10 17:22:22,778 - rush - INFO - Argument ff370371-90b6-4995-8aab-41064ea67fbf is now ModuleInstanceStatus.DISPATCHED\n2024-04-10 17:22:23,853 - rush - INFO - Argument ff370371-90b6-4995-8aab-41064ea67fbf is now ModuleInstanceStatus.RUNNING\n2024-04-10 17:23:48,697 - rush - INFO - Argument ff370371-90b6-4995-8aab-41064ea67fbf is now ModuleInstanceStatus.AWAITING_UPLOAD\n\n\n'https://storage.googleapis.com/qdx-store/58c8901d-6ed7-4a35-a1d5-f7607878f9e1?x-goog-signature=0bfb96d595cdead3286c86597620807aafd6aea903df258a76fc8ee49a31d103c48b3838c8ca11f4394c427a566ce280728b5d46b0a09c5cb6b1e1f75bc6a887988f128378e1de7dfa3af7a41f6bad52f3512ce6d875a7582e36f212fd2275ec7b288b872c41d89ac87ce1fb4f690fa9827a62ea014c10b22e6eeeb2e923704f1dffa000649998f4286cce2d6c33f7dd5669d724d70f3e5966ccf8feff3751f381a68e66e31832a128c4b0644a2f0c51df8a24bbf70cf9537ab5e8da5035fc5cf36b5722017d89a7a8ee7b8c1e1d3188aca2810fa0c26eee4a1cedf89b1c327976a72cd1bed12b706d0701db5c7727389f72163675cda5a6c0e341aca268e794&x-goog-algorithm=GOOG4-RSA-SHA256&x-goog-credential=qdx-store-user%40humming-bird-321603.iam.gserviceaccount.com%2F20240410%2Fasia-southeast1%2Fstorage%2Fgoog4_request&x-goog-date=20240410T092421Z&x-goog-expires=3600&x-goog-signedheaders=host'",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Tutorials",
      "GROMACS Resume -  Start a long GROMACS run that times out, and resume it"
    ]
  },
  {
    "objectID": "Previous Versions/Tutorials/gmx_restart.html#checking-progress-of-gromacs-run",
    "href": "Previous Versions/Tutorials/gmx_restart.html#checking-progress-of-gromacs-run",
    "title": "GROMACS Resume - Start a long GROMACS run that times out, and resume it",
    "section": "Checking progress of GROMACS run",
    "text": "Checking progress of GROMACS run\nTo determine if your GROMACS run is done, or if further runs are required, you can look at the progress output. How to check this output is demonstrated below.\nThis is an example progress event that indicates that the job has not completed, and will require resuming. n is the number of execution steps in the GMX module. If n is less than n_expected, or done is false the run is not yet completed.\ngmx_resume_tengu progress: {   \"n\": 600,   \"n_expected\": 601,   \"n_max\": 601,   \"done\": false }\nWe keep running resume until the progress is done\n\nhelp(client.gmx_resume)\n\nHelp on function gmx_resume in module rush.provider:\n\ngmx_resume(*args: *tuple[RushObject[bytes], Record], target: 'Target | None' = None, resources: 'Resources | None' = None, tags: 'list[str] | None' = None, restore: 'bool | None' = None) -&gt; tuple[RushObject[bytes], RushObject[bytes], RushObject[bytes], RushObject[bytes], RushObject[bytes], RushObject[bytes], RushObject[bytes]]\n    Runs a molecular dynamics simluation using GROMACS from either protein, resuming from a checkpoint.\n    Uses GMX 2023.3 https://doi.org/10.5281/zenodo.10017686 and Acpype https://doi.org/10.1186/1756-0500-5-367\n\n    Module version:\n    `github:talo/tengu-gmx/eaaa2472bd2dc67eed931fa1816fd0b46c509599#gmx_resume_tengu`\n\n    QDX Type Description:\n\n        resume_files: Object[@$Bytes];\n        gmx_config: GMXTenguConfig {\n            frame_sel: FrameSelConfig {\n                delta_time_ps: u32,\n                start_time_ps: u32,\n                end_time_ps: u32\n            }?,\n            timeout_duration_mins: u32?,\n            force_field: string?,\n            ignore_hydrogens: bool?,\n            num_gpus: u8,\n            save_wets: bool?,\n            num_replicas: u8?,\n            params_overrides: GMXOverrides {\n                npt: NPTOverrides {\n                    fourierspacing: f64?,\n                    rvdw: f64?,\n                    coulombtype: string?,\n                    constraints: string?,\n                    rlist: f64?,\n                    disp_corr: string?,\n                    pbc: string?,\n                    cutoff_scheme: string?,\n                    nstlog: i32?,\n                    nstenergy: i32?,\n                    pme_order: i32?,\n                    define: string?,\n                    tau_p: f64?,\n                    lincs_iter: i32?,\n                    rcoulomb: f64?,\n                    refcoord_scaling: string?,\n                    pcoupltype: string?,\n                    constraint_algorithm: string?,\n                    dt: f64?,\n                    tcoupl: string?,\n                    lincs_order: i32?,\n                    nsteps: i32?,\n                    rvdw_switch: f64?,\n                    compressibility: f64?,\n                    ref_t: [f64]?,\n                    pcoupl: string?,\n                    gen_vel: string?,\n                    tc_grps: string?,\n                    vdwtype: string?,\n                    ref_p: f64?,\n                    vdw_modifier: string?,\n                    nstxout_compressed: i32?,\n                    continuation: string?,\n                    tau_t: [f64]?,\n                    integrator: string?\n                }?,\n                md: MDOverrides {\n                    rvdw: f64?,\n                    ref_p: f64?,\n                    cutoff_scheme: string?,\n                    fourierspacing: f64?,\n                    constraint_algorithm: string?,\n                    integrator: string?,\n                    constraints: string?,\n                    vdwtype: string?,\n                    tau_t: [f64]?,\n                    tcoupl: string?,\n                    rvdw_switch: f64?,\n                    pcoupltype: string?,\n                    tc_grps: string?,\n                    nsteps: i32?,\n                    compressibility: f64?,\n                    rcoulomb: f64?,\n                    pcoupl: string?,\n                    dt: f64?,\n                    tau_p: f64?,\n                    gen_vel: string?,\n                    nstenergy: i32?,\n                    nstxout_compressed: i32?,\n                    lincs_order: i32?,\n                    disp_corr: string?,\n                    nstlog: i32?,\n                    rlist: f64?,\n                    pme_order: i32?,\n                    continuation: string?,\n                    pbc: string?,\n                    lincs_iter: i32?,\n                    coulombtype: string?,\n                    vdw_modifier: string?,\n                    ref_t: [f64]?\n                }?,\n                nvt: NVTOverrides {\n                    dt: f64?,\n                    continuation: string?,\n                    vdw_modifier: string?,\n                    nstlog: i32?,\n                    gen_vel: string?,\n                    constraints: string?,\n                    lincs_order: i32?,\n                    tau_t: [f64]?,\n                    rlist: f64?,\n                    nsteps: i32?,\n                    constraint_algorithm: string?,\n                    ref_t: [f64]?,\n                    define: string?,\n                    nstxout_compressed: i32?,\n                    tc_grps: string?,\n                    disp_corr: string?,\n                    fourierspacing: f64?,\n                    pme_order: i32?,\n                    tcoupl: string?,\n                    integrator: string?,\n                    pbc: string?,\n                    vdwtype: string?,\n                    rvdw: f64?,\n                    gen_temp: f64?,\n                    rcoulomb: f64?,\n                    nstenergy: i32?,\n                    cutoff_scheme: string?,\n                    lincs_iter: i32?,\n                    coulombtype: string?,\n                    rvdw_switch: f64?,\n                    gen_seed: i32?,\n                    pcoupl: string?\n                }?,\n                ions: IonsOverrides {\n                    coulombtype: string?,\n                    nstlog: i32?,\n                    nsteps: i32?,\n                    rvdw: f64?,\n                    rlist: f64?,\n                    pbc: string?,\n                    cutoff_scheme: string?,\n                    emstep: f64?,\n                    integrator: string?,\n                    rcoulomb: f64?,\n                    emtol: f64?\n                }?,\n                em: EMOverrides {\n                    nsteps: i32?,\n                    rcoulomb: f64?,\n                    rlist: f64?,\n                    emtol: f64?,\n                    cutoff_scheme: string?,\n                    integrator: string?,\n                    pbc: string?,\n                    emstep: f64?,\n                    rvdw: f64?,\n                    nstlog: i32?,\n                    coulombtype: string?\n                }?\n            }?,\n            water_box_size: f32?,\n            perf_flags_override: string?,\n            ligand_charge: i8?,\n            checkpoint_interval_mins: f32?\n        }\n        -&gt;\n        resume_files: Object[@$Bytes];\n        streaming_outputs: Object[@$Bytes];\n        static_outputs: Object[@$Bytes];\n        output_xtcs_dry: Object[@$Bytes];\n        output_frames_pdb_dry: Object[@$Bytes];\n        output_xtcs_wet: Object[@$Bytes];\n        output_frames_pdb_wet: Object[@$Bytes]\n\n\n    :param resume_files: The untouched tar.gz resume_files output from a past run, to resume from\n    :param gmx_config: Configuration record\n    :return resume_files: .tpr, .cpt, .ndx, .top, & .itp files of the production MD runs, plus the input ligand pdb\n    :return streaming_outputs: .edr, .log, & .xtc files of the production MD runs\n    :return static_outputs: .gro & .xvg files files from the runs\n    :return output_xtcs_dry: Processed dry trajectories, i.e., without water molecules, from the production MD runs\n    :return output_frames_pdb_dry: Outputs of select_frame; pdb frames without water\n    :return output_xtcs_wet: Processed wet trajectories, i.e. with water molecules, from the production MD runs\n    :return output_frames_pdb_wet: Outputs of select_frame; pdb frames with water\n\n\n\n\ndone = False\nresumes = 0\nresume_files = resume_files_first\nwhile not done:\n    resume_files, _, _, xtc_dry, pdb_dry, _, _ = client.gmx_resume(\n        resume_files,\n        gmx_config,\n        tags=[f\"gmx-resume-{resumes}\"],\n        restore=False,\n        resources={\"gpus\": 1, \"storage\": 1, \"storage_units\": \"GB\"},\n    )\n    # wait for module to finish\n    resume_files.get()\n    progress = client.module_instance_blocking(resume_files.source).progress\n    print(progress)\n    done = progress.done\n    resumes += 1\n\n2024-04-10 17:24:22,169 - rush - INFO - Argument e8a349bc-a6ab-4753-ba70-b1bd867eaa1f is now ModuleInstanceStatus.RESOLVING\n2024-04-10 17:24:23,277 - rush - INFO - Argument e8a349bc-a6ab-4753-ba70-b1bd867eaa1f is now ModuleInstanceStatus.ADMITTED\n2024-04-10 17:24:29,853 - rush - INFO - Argument e8a349bc-a6ab-4753-ba70-b1bd867eaa1f is now ModuleInstanceStatus.RUNNING\n2024-04-10 17:25:00,050 - rush - INFO - Argument e8a349bc-a6ab-4753-ba70-b1bd867eaa1f is now ModuleInstanceStatus.AWAITING_UPLOAD\nn=154000 n_expected=154000 n_max=154000 done=True",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Tutorials",
      "GROMACS Resume -  Start a long GROMACS run that times out, and resume it"
    ]
  },
  {
    "objectID": "Previous Versions/Tutorials/convert.html",
    "href": "Previous Versions/Tutorials/convert.html",
    "title": "Convert — Run a simple conversion of a PDB to the QDXF format",
    "section": "",
    "text": "This notebook shows how to perform a simple conversion of PDBs to the QDXF format",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Tutorials",
      "Convert — Run a simple conversion of a PDB to the QDXF format"
    ]
  },
  {
    "objectID": "Previous Versions/Tutorials/convert.html#imports",
    "href": "Previous Versions/Tutorials/convert.html#imports",
    "title": "Convert — Run a simple conversion of a PDB to the QDXF format",
    "section": "1.0) Imports",
    "text": "1.0) Imports\n\nimport os\nfrom glob import glob\nfrom pathlib import Path\n\nfrom pdbtools import pdb_fetch\n\nimport rush",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Tutorials",
      "Convert — Run a simple conversion of a PDB to the QDXF format"
    ]
  },
  {
    "objectID": "Previous Versions/Tutorials/convert.html#configuration",
    "href": "Previous Versions/Tutorials/convert.html#configuration",
    "title": "Convert — Run a simple conversion of a PDB to the QDXF format",
    "section": "1.1) Configuration",
    "text": "1.1) Configuration\n\n# Define our project information\nDESCRIPTION = \"rush-py batch notebook\"\nTAGS = [\"qdx\", \"rush-py-v2\", \"demo\", \"convert\"]\nWORK_DIR = Path.home() / \"qdx\" / \"convert\"\n\n# Set our inputs\nPROTEIN_PDB_FOLDER_PATH = WORK_DIR / \"proteins\"\n\n\nos.makedirs(PROTEIN_PDB_FOLDER_PATH, exist_ok=True)",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Tutorials",
      "Convert — Run a simple conversion of a PDB to the QDXF format"
    ]
  },
  {
    "objectID": "Previous Versions/Tutorials/convert.html#build-your-client",
    "href": "Previous Versions/Tutorials/convert.html#build-your-client",
    "title": "Convert — Run a simple conversion of a PDB to the QDXF format",
    "section": "1.2) Build your client",
    "text": "1.2) Build your client\nInitialize our rush client and fetch available module paths.\n\n# Get our client, for calling modules and using the rush API\nos.environ[\"RUSH_TOKEN\"] = YOUR_TOKEN\n\nclient = rush.build_blocking_provider_with_functions(\n    workspace=WORK_DIR,\n    batch_tags=TAGS,\n)",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Tutorials",
      "Convert — Run a simple conversion of a PDB to the QDXF format"
    ]
  },
  {
    "objectID": "Previous Versions/Tutorials/colabfold_mmseqs2.html",
    "href": "Previous Versions/Tutorials/colabfold_mmseqs2.html",
    "title": "MMseqs2 and Colabfold — sequence to 3D protein structure prediction using AlphaFold",
    "section": "",
    "text": "See the quickstart notebook for a short example of how to go from sequence to 3D protein conformer.",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Tutorials",
      "MMseqs2 and Colabfold — sequence to 3D protein structure prediction using AlphaFold"
    ]
  },
  {
    "objectID": "Previous Versions/Tutorials/colabfold_mmseqs2.html#quickstart",
    "href": "Previous Versions/Tutorials/colabfold_mmseqs2.html#quickstart",
    "title": "MMseqs2 and Colabfold — sequence to 3D protein structure prediction using AlphaFold",
    "section": "",
    "text": "See the quickstart notebook for a short example of how to go from sequence to 3D protein conformer.",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Tutorials",
      "MMseqs2 and Colabfold — sequence to 3D protein structure prediction using AlphaFold"
    ]
  },
  {
    "objectID": "Previous Versions/Tutorials/colabfold_mmseqs2.html#imports",
    "href": "Previous Versions/Tutorials/colabfold_mmseqs2.html#imports",
    "title": "MMseqs2 and Colabfold — sequence to 3D protein structure prediction using AlphaFold",
    "section": "1.0) Imports",
    "text": "1.0) Imports\n\nimport os\nfrom pathlib import Path\nimport rush\nimport json\nimport requests\nimport py3Dmol",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Tutorials",
      "MMseqs2 and Colabfold — sequence to 3D protein structure prediction using AlphaFold"
    ]
  },
  {
    "objectID": "Previous Versions/Tutorials/colabfold_mmseqs2.html#configuration",
    "href": "Previous Versions/Tutorials/colabfold_mmseqs2.html#configuration",
    "title": "MMseqs2 and Colabfold — sequence to 3D protein structure prediction using AlphaFold",
    "section": "1.1) Configuration",
    "text": "1.1) Configuration\n\n# Define our project information\nDESCRIPTION = \"colabfold notebook\"\nTAGS = [\"qdx\", \"rush-py-v2\", \"demo\", \"colabfold\"]\nWORK_DIR = Path.home() / \"qdx\" / \"colabfold\"",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Tutorials",
      "MMseqs2 and Colabfold — sequence to 3D protein structure prediction using AlphaFold"
    ]
  },
  {
    "objectID": "Previous Versions/Tutorials/colabfold_mmseqs2.html#build-your-client",
    "href": "Previous Versions/Tutorials/colabfold_mmseqs2.html#build-your-client",
    "title": "MMseqs2 and Colabfold — sequence to 3D protein structure prediction using AlphaFold",
    "section": "1.2) Build your client",
    "text": "1.2) Build your client\nInitialize our rush client and fetch available modules.\n\n# Get our client, for calling modules and using the rush API\nos.environ[\"RUSH_TOKEN\"] = YOUR_TOKEN\n\nclient = rush.build_blocking_provider_with_functions(\n    workspace=WORK_DIR, batch_tags=TAGS, access_token=YOUR_TOKEN\n)\n\n2024-05-08 10:58:56,526 - rush - INFO - Restoring by default via env",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Tutorials",
      "MMseqs2 and Colabfold — sequence to 3D protein structure prediction using AlphaFold"
    ]
  },
  {
    "objectID": "Previous Versions/Tutorials/colabfold_mmseqs2.html#get-a-sample-fasta-sequence",
    "href": "Previous Versions/Tutorials/colabfold_mmseqs2.html#get-a-sample-fasta-sequence",
    "title": "MMseqs2 and Colabfold — sequence to 3D protein structure prediction using AlphaFold",
    "section": "2.0) Get a sample FASTA sequence",
    "text": "2.0) Get a sample FASTA sequence\nHere, we have a FASTA sequence already, but you can source your FASTA sequences from anywhere, and save them in your workspace directory.\nWe need to perform some pre-processing of the FASTA sequence – stripping the comment line.\nWe then load it to a string so we can pass it to mmseqs2 to produce a MSA from the initial amino acid sequence.\n\nFASTA_SEQUENCE = \"\"\"\nMALGELKDDDFEKISELGAGNGGVVFKVSHKPSGLVMARKLIHLEIKPAIRNQIIRELQVLHECNSPYIVGFYGAFYSDGEISICMEHMDGGSLDQVLKKAGRIPEQILGKVSIAVIKGLTYLR\nEKHKIMHRDVKPSNILVNSRGEIKLCDFGVSGQLIDEMANEFVGTRSYMSPERLQGTHYSVQSDIWSMGLSLVEMAVGRYPRPPMAIFELLDYIVNEPPPKLPSAVFSLEFQDFVNKCLIKNPAE\nRADLKQLMVHAFIKRSDAEEVDFAGWLCSTIGLNQPSTPTHAAGEGHHHHHH\"\"\"\nFASTA_SEQUENCE = FASTA_SEQUENCE.replace(\"\\n\", \"\")\n\nwith open(\"mek1.fasta\", \"w\") as file:\n    # Use print function to write text to the file\n    print(FASTA_SEQUENCE, file=file)\n\n\ndef load_file_to_string(file_path):\n    try:\n        with open(file_path, \"r\") as file:\n            return file.read()\n    except FileNotFoundError:\n        print(f\"The file {file_path} was not found.\")\n        return None\n    except Exception as e:\n        print(f\"An error occurred while reading the file: {e}\")\n        return None\n\n\nfasta_sequence = load_file_to_string(\"mek1.fasta\").strip()\nfasta_sequence\n\n'MALGELKDDDFEKISELGAGNGGVVFKVSHKPSGLVMARKLIHLEIKPAIRNQIIRELQVLHECNSPYIVGFYGAFYSDGEISICMEHMDGGSLDQVLKKAGRIPEQILGKVSIAVIKGLTYLREKHKIMHRDVKPSNILVNSRGEIKLCDFGVSGQLIDEMANEFVGTRSYMSPERLQGTHYSVQSDIWSMGLSLVEMAVGRYPRPPMAIFELLDYIVNEPPPKLPSAVFSLEFQDFVNKCLIKNPAERADLKQLMVHAFIKRSDAEEVDFAGWLCSTIGLNQPSTPTHAAGEGHHHHHH'",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Tutorials",
      "MMseqs2 and Colabfold — sequence to 3D protein structure prediction using AlphaFold"
    ]
  },
  {
    "objectID": "Previous Versions/Tutorials/colabfold_mmseqs2.html#run-mmseqs2-on-your-fasta-sequence-to-get-a-sequence-alignment",
    "href": "Previous Versions/Tutorials/colabfold_mmseqs2.html#run-mmseqs2-on-your-fasta-sequence-to-get-a-sequence-alignment",
    "title": "MMseqs2 and Colabfold — sequence to 3D protein structure prediction using AlphaFold",
    "section": "2.1) Run mmseqs2 on your FASTA sequence to get a sequence alignment",
    "text": "2.1) Run mmseqs2 on your FASTA sequence to get a sequence alignment\nAll outputs of Tengu modules are tuples, so we need to destructure the tuple first. Please note that mmseqs2 requires significant computational resources and access to a storage mount on the GADI supercomputer containing the sequence database.\n\n(msa,) = client.mmseqs2(\n    {\"fasta\": [fasta_sequence]},\n    resources={\n        \"gpus\": 0,\n        \"cpus\": 48,\n        \"mem\": 128 * 1024,\n        \"storage_mounts\": [\"gdata/if89\"],\n        \"walltime\": 360,\n    },\n    target=\"GADI\",\n)\n\n2024-05-08 10:58:58,912 - rush - INFO - Trying to restore job with tags: ['qdx', 'rush-py-v2', 'demo', 'colabfold'] and path: github:talo/colabfold_tengu/279da07e4f58e122981bcfcf9398a51cf4b38471#mmseqs2_tengu\n2024-05-08 10:58:58,991 - rush - WARNING - Multiple module instances found with the same tags and path\n2024-05-08 10:58:58,992 - rush - WARNING - Multiple module instances found with the same tags and path\n2024-05-08 10:58:59,069 - rush - INFO - Restoring job from previous run with id 7e2de897-dea1-4a26-b394-b7667c9c0ed5",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Tutorials",
      "MMseqs2 and Colabfold — sequence to 3D protein structure prediction using AlphaFold"
    ]
  },
  {
    "objectID": "Previous Versions/Tutorials/colabfold_mmseqs2.html#run-alphafold2-to-get-our-predicted-conformer",
    "href": "Previous Versions/Tutorials/colabfold_mmseqs2.html#run-alphafold2-to-get-our-predicted-conformer",
    "title": "MMseqs2 and Colabfold — sequence to 3D protein structure prediction using AlphaFold",
    "section": "2.2) - Run AlphaFold2 to get our predicted conformer",
    "text": "2.2) - Run AlphaFold2 to get our predicted conformer\nNote here that we were able to pass our MSAs directly to the fold module.\n\n(fold_output, _) = client.colabfold_fold(\n    msa, resources={\"gpus\": 1, \"storage_mounts\": [\"gdata/if89\"]}, target=\"GADI\"\n)\n\n2024-05-08 10:58:59,072 - rush - INFO - Trying to restore job with tags: ['qdx', 'rush-py-v2', 'demo', 'colabfold'] and path: github:talo/colabfold_tengu/f0bfcd1224adc86e54d52bdf49a7b9f1125018eb#colabfold_tengu_fold\n2024-05-08 10:58:59,162 - rush - WARNING - Multiple module instances found with the same tags and path\n2024-05-08 10:58:59,162 - rush - WARNING - Multiple module instances found with the same tags and path\n2024-05-08 10:58:59,240 - rush - INFO - Restoring job from previous run with id f9846de2-3eb3-4191-900e-348799fc2c99\n\n\n\nfolded_conformers_url = fold_output.get()\nfolded_conformers = requests.get(folded_conformers_url).json()\n# spot check the first 10 elements of our folded conformer\nfolded_conformers[0][\"topology\"][\"symbols\"][0:10]\n\n2024-05-08 10:58:59,476 - rush - INFO - Argument d26b2c19-766c-4332-b4ee-80cc5b791e9a is now ModuleInstanceStatus.AWAITING_UPLOAD\n\n\n['N', 'C', 'C', 'C', 'O', 'C', 'S', 'C', 'N', 'C']",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Tutorials",
      "MMseqs2 and Colabfold — sequence to 3D protein structure prediction using AlphaFold"
    ]
  },
  {
    "objectID": "Previous Versions/Tutorials/colabfold_mmseqs2.html#visualise-a-predicted-conformer",
    "href": "Previous Versions/Tutorials/colabfold_mmseqs2.html#visualise-a-predicted-conformer",
    "title": "MMseqs2 and Colabfold — sequence to 3D protein structure prediction using AlphaFold",
    "section": "3.0) - Visualise a predicted conformer",
    "text": "3.0) - Visualise a predicted conformer\nHere, we can visualise one of the outputted conformers within our notebook so that we can review the quality of our protein prediction. Note that we need to convert the predicted conformer first to a PDB as py3Dmol can only visualise PDB files. We also need to open the PDB file saved to the workspace from the objects subdirectory as files downloaded via rush-py are saved there.\n\nwith open(\"folded_conformer.json\", \"w\") as file:\n    # Use print function to write text to the file\n    print(json.dumps(folded_conformers[0]), file=file)\n\n(output_pdb,) = client.to_pdb(client.workspace / \"folded_conformer.json\")\n\noutput_pdb.download(filename=\"folded_conformer_1.pdb\")\n\n2024-05-08 11:01:57,452 - rush - INFO - Trying to restore job with tags: ['qdx', 'rush-py-v2', 'demo', 'colabfold'] and path: github:talo/tengu-prelude/2de4291f1c7371c85a1ee342c622f9942c87fdbd#to_pdb\n2024-05-08 11:01:57,812 - rush - INFO - Argument 8d2e8d7d-d6f6-4d2a-ada5-18b5d9d3e196 is now ModuleInstanceStatus.RESOLVING\n2024-05-08 11:02:00,168 - rush - INFO - Argument 8d2e8d7d-d6f6-4d2a-ada5-18b5d9d3e196 is now ModuleInstanceStatus.ADMITTED\n2024-05-08 11:02:19,656 - rush - INFO - Argument 8d2e8d7d-d6f6-4d2a-ada5-18b5d9d3e196 is now ModuleInstanceStatus.DISPATCHED\n2024-05-08 11:02:20,798 - rush - INFO - Argument 8d2e8d7d-d6f6-4d2a-ada5-18b5d9d3e196 is now ModuleInstanceStatus.AWAITING_UPLOAD\n2024-05-08 11:02:32,809 - rush - INFO - Argument 8d2e8d7d-d6f6-4d2a-ada5-18b5d9d3e196 is now ModuleInstanceStatus.COMPLETED\n\n\nPosixPath('/home/machineer/qdx/colabfold/objects/folded_conformer_1.pdb')\n\n\n\nview = py3Dmol.view()\nwith open(client.workspace / \"objects\" / \"folded_conformer_1.pdb\", \"r\") as f:\n    view.addModel(f.read(), \"pdb\")\n    view.setStyle({\"cartoon\": {\"color\": \"spectrum\"}})\n    view.zoomTo()\n    view.show()\n\n\n        3Dmol.js failed to load for some reason.  Please check your browser console for error messages.",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Tutorials",
      "MMseqs2 and Colabfold — sequence to 3D protein structure prediction using AlphaFold"
    ]
  },
  {
    "objectID": "Previous Versions/Tutorials/batch_run_protein_prep_async.html",
    "href": "Previous Versions/Tutorials/batch_run_protein_prep_async.html",
    "title": "prepare_protein — Run a batch protein preperation in parallel",
    "section": "",
    "text": "This notebook shows how to load a large amount of data and execute runs on them in parallel",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Tutorials",
      "prepare_protein — Run a batch protein preperation in parallel"
    ]
  },
  {
    "objectID": "Previous Versions/Tutorials/batch_run_protein_prep_async.html#imports",
    "href": "Previous Versions/Tutorials/batch_run_protein_prep_async.html#imports",
    "title": "prepare_protein — Run a batch protein preperation in parallel",
    "section": "1.0) Imports",
    "text": "1.0) Imports\n\nimport os\nimport asyncio\nfrom glob import glob\nfrom datetime import datetime\nfrom pathlib import Path\n\nfrom pdbtools import (\n    pdb_fetch,\n    pdb_delhetatm,\n    pdb_selchain,\n    pdb_rplresname,\n    pdb_keepcoord,\n    pdb_selresname,\n)\nimport py3Dmol\n\nimport rush",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Tutorials",
      "prepare_protein — Run a batch protein preperation in parallel"
    ]
  },
  {
    "objectID": "Previous Versions/Tutorials/batch_run_protein_prep_async.html#configuration",
    "href": "Previous Versions/Tutorials/batch_run_protein_prep_async.html#configuration",
    "title": "prepare_protein — Run a batch protein preperation in parallel",
    "section": "1.1) Configuration",
    "text": "1.1) Configuration\n\n# Define our project information\nDESCRIPTION = \"rush-py batch notebook\"\nTAGS = [\"qdx\", \"rush-py-v2\", \"demo\", \"batch-prep\"]\nWORK_DIR = Path.home() / \"qdx\" / \"rush-py-batch-prep\"\n\n# Set our inputs\nPROTEIN_PDB_FOLDER_PATH = WORK_DIR / \"proteins\"\n\nTARGET = \"BULLET_2\"\n\nEnsure your workdir exists\n\nos.makedirs(WORK_DIR, exist_ok=True)\nos.makedirs(PROTEIN_PDB_FOLDER_PATH, exist_ok=True)",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Tutorials",
      "prepare_protein — Run a batch protein preperation in parallel"
    ]
  },
  {
    "objectID": "Previous Versions/Tutorials/batch_run_protein_prep_async.html#build-your-client",
    "href": "Previous Versions/Tutorials/batch_run_protein_prep_async.html#build-your-client",
    "title": "prepare_protein — Run a batch protein preperation in parallel",
    "section": "1.2) Build your client",
    "text": "1.2) Build your client\nInitialize our rush client and fetch available module paths.\n\nos.environ[\"RUSH_TOKEN\"] = YOUR_TOKEN\n\n# Get our client, for calling modules and using the rush API\nclient = await rush.build_provider_with_functions(\n    batch_tags=TAGS, workspace=WORK_DIR\n)\n\n\n# fetch datafiles\nfor pdb in [\"1B39\", \"4QXI\", \"8FSU\"]:\n    complex = list(pdb_fetch.fetch_structure(pdb))\n    protein = pdb_delhetatm.remove_hetatm(pdb_selchain.select_chain(complex, \"A\"))\n\n    with open(PROTEIN_PDB_FOLDER_PATH / f\"{pdb}_protein.pdb\", \"w\") as f:\n        for l in protein:\n            f.write(str(l))\n\n\nhelp(client.prepare_protein)\n\nHelp on function prepare_protein in module rush.provider:\n\nasync prepare_protein(*args: *tuple[RushObject[bytes], Optional[float], Optional[EnumValue]], target: 'Target | None' = None, resources: 'Resources | None' = {'storage': 138, 'storage_units': 'MB', 'gpus': 1}, tags: 'list[str] | None' = None, restore: 'bool | None' = None) -&gt; tuple[RushObject[list[Record]], RushObject[bytes]]\n    Prepare a PDB for downstream tasks: protonate, fill missing atoms, etc.\n\n    Module version:\n    `github:talo/prepare_protein/9af3512509062490f73302e3c8c7d4296036e678#prepare_protein_tengu`\n\n    QDX Type Description:\n\n        input_pdb: Object[@$PDB];\n        ph: f32?;\n        naming_scheme: NamingScheme[Amber | Charmm]?\n        -&gt;\n        output_qdxf: Object[[Conformer]];\n        output_pdb: Object[@$PDB]\n\n\n    :param input_pdb: An input protein as a file; one PDB file\n    :param ph: The ph for determining protonation states; 0-14\n    :param naming_scheme: \\\n                    The force field naming scheme to use; \\\n                    options are \"amber\" or \"charmm\"; \\\n                    None produces RCSB/IUPAC standard naming\\\n\n    :return output_qdxf: An output protein a vec: one qdxf per model in pdb\n    :return output_pdb: An output protein as a file: one PDB file",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Tutorials",
      "prepare_protein — Run a batch protein preperation in parallel"
    ]
  },
  {
    "objectID": "Previous Versions/Tutorials/hermes_hartree_fock_energy_calculation.html",
    "href": "Previous Versions/Tutorials/hermes_hartree_fock_energy_calculation.html",
    "title": "Hermes — Run a basic Hartree-Fock energy calculation",
    "section": "",
    "text": "In this notebook, we’ll perform a Hermes calculation to get the total Hartree Fock energy on a protein that we prepare with PDBFixer and PDB2PQR.",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Tutorials",
      "Hermes — Run a basic Hartree-Fock energy calculation"
    ]
  },
  {
    "objectID": "Previous Versions/Tutorials/hermes_hartree_fock_energy_calculation.html#imports",
    "href": "Previous Versions/Tutorials/hermes_hartree_fock_energy_calculation.html#imports",
    "title": "Hermes — Run a basic Hartree-Fock energy calculation",
    "section": "1.0) Imports",
    "text": "1.0) Imports\n\nimport json\nimport os\nimport sys\nimport tarfile\n\nfrom pdbtools import *\nimport requests\nfrom datetime import datetime\nfrom pathlib import Path\nimport py3Dmol\n\nimport rush",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Tutorials",
      "Hermes — Run a basic Hartree-Fock energy calculation"
    ]
  },
  {
    "objectID": "Previous Versions/Tutorials/hermes_hartree_fock_energy_calculation.html#configuration",
    "href": "Previous Versions/Tutorials/hermes_hartree_fock_energy_calculation.html#configuration",
    "title": "Hermes — Run a basic Hartree-Fock energy calculation",
    "section": "1.1) Configuration",
    "text": "1.1) Configuration\n\nEXPERIMENT = \"rush-py hermes energy demo\"\nSYSTEM = \"1B39\"\nLIGAND = \"ATP\"\nTAGS = [\"qdx\", EXPERIMENT, SYSTEM, LIGAND]\n\nBuild our client\n\nos.environ[\"RUSH_TOKEN\"] = YOUR_TOKEN\n\nclient = rush.build_blocking_provider_with_functions(batch_tags=TAGS)",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Tutorials",
      "Hermes — Run a basic Hartree-Fock energy calculation"
    ]
  },
  {
    "objectID": "Previous Versions/Tutorials/hermes_hartree_fock_energy_calculation.html#input-selection",
    "href": "Previous Versions/Tutorials/hermes_hartree_fock_energy_calculation.html#input-selection",
    "title": "Hermes — Run a basic Hartree-Fock energy calculation",
    "section": "1.2) Input selection",
    "text": "1.2) Input selection\n\n# fetch datafiles\nPROTEIN_PDB_PATH = client.workspace / f\"{SYSTEM}_P.pdb\"\n\ncomplex = list(pdb_fetch.fetch_structure(SYSTEM))\nprotein = pdb_delhetatm.remove_hetatm(pdb_selchain.select_chain(complex, \"A\"))\n# write our files to the locations defined in the config block\nwith open(PROTEIN_PDB_PATH, \"w\") as f:\n    for l in protein:\n        f.write(str(l))",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Tutorials",
      "Hermes — Run a basic Hartree-Fock energy calculation"
    ]
  },
  {
    "objectID": "Previous Versions/Tutorials/hermes_hartree_fock_energy_calculation.html#arguments",
    "href": "Previous Versions/Tutorials/hermes_hartree_fock_energy_calculation.html#arguments",
    "title": "Hermes — Run a basic Hartree-Fock energy calculation",
    "section": "4.0) Arguments",
    "text": "4.0) Arguments\n\nhelp(client.hermes_energy)\n\nHelp on function hermes_energy in module rush.provider:\n\nhermes_energy(*args: *tuple[RushObject[Record], Record, Optional[Record], Optional[Record], Optional[Record], Optional[Record]], target: 'Target | None' = None, resources: 'Resources | None' = None, tags: 'list[str] | None' = None, restore: 'bool | None' = None) -&gt; tuple[RushObject[Record]]\n    Runs a HERMES energy calculation given a topology, and optionally model and keyword configurations.\n    Will use the default model and keywords if none are provided\n\n    Module version:\n    `github:talo/tengu-prelude/3d11b61a2092fbec721966ffa99743f8bfabe6c2#hermes_energy`\n\n    QDX Type Description:\n\n        input: Object[Conformer];\n        system: System {\n            teams_per_node: u32?,\n            gpus_per_team: u32?,\n            max_gpu_memory_mb: u32?,\n            oversubscribe_gpus: bool?\n        };\n        model: Model {\n            aux_basis: string?,\n            force_cartesian_basis_sets: bool?,\n            basis: string,\n            standard_orientation: string?\n        }?;\n        scf keywords: SCF {\n            max_iters: u32?,\n            batch_size: u32?,\n            density_threshold: f64?,\n            use_ri: bool?,\n            max_diis_history_length: u32?,\n            density_basis_set_projection_fallback_enabled: bool?,\n            convergence_metric: string?,\n            convergence_threshold: f64?\n        }?;\n        frag keywords: Frag {\n            cutoffs: FragCutoffs {dimer: f64?, trimer: f64?, tetramer: f64?}?,\n            reference_fragment: u32?,\n            level: FragLevel[Monomer | Dimer | Trimer | Tetramer],\n            included_fragments: [u32]?,\n            cutoff_type: CutoffType[Centroid | ClosestPair]?\n        }?;\n        guess keywords: Guess {\n            bsp: bool?,\n            smd: bool?,\n            ssfd_scf_keywords: GuessSCF {\n                max_iters: u32?,\n                density_threshold: f64?,\n                use_ri: bool?,\n                convergence_metric: ConvergenceMetric[Energy | DIIS | Density]?,\n                max_diis_history_length: u32?,\n                batch_size: u32?,\n                density_basis_set_projection_fallback_enabled: bool?,\n                convergence_threshold: f64?\n            }?,\n            ssfd: bool?,\n            ssfd_only_converge_in_bsp_basis: bool?,\n            bsp_basis: string?,\n            ssfd_target_size: u32?,\n            bsp_scf_keywords: SCF {\n                max_iters: u32?,\n                batch_size: u32?,\n                density_threshold: f64?,\n                convergence_threshold: f64?,\n                use_ri: bool?,\n                max_diis_history_length: u32?,\n                convergence_metric: string?,\n                density_basis_set_projection_fallback_enabled: bool?\n            }?\n        }?\n        -&gt;\n        energy: Object {\n            format: ObjectFormat[json | bin]?,\n            path: @QMMBE {\n                distance_metric: CutoffType[Centroid | ClosestPair]?,\n                expanded_hf_gradients: [f64]?,\n                expanded_mp2_os_correction: f64?,\n                reference_fragment: u32?,\n                expanded_density: Tensorf64 {\n                    kind: TensorKind[Dense | SquareSymmetric | LowerTriangular],\n                    shape: [u32],\n                    data: [f64]\n                }?,\n                expanded_mp2_gradients: [f64]?,\n                nmers: [[Nmer {\n                    coeffs_final: Tensorf64 {\n                        kind: TensorKind[Dense | SquareSymmetric | LowerTriangular],\n                        shape: [u32],\n                        data: [f64]\n                    }?,\n                    hf_gradients: [f64]?,\n                    mp2_os_correction: f64?,\n                    fock: Tensorf64 {\n                        kind: TensorKind[Dense | SquareSymmetric | LowerTriangular],\n                        shape: [u32],\n                        data: [f64]\n                    }?,\n                    delta_mp2_ss_correction: f64?,\n                    coeffs_initial: Tensorf64 {\n                        kind: TensorKind[Dense | SquareSymmetric | LowerTriangular],\n                        data: [f64],\n                        shape: [u32]\n                    }?,\n                    delta_hf_energy: f64?,\n                    density: Tensorf64 {\n                        shape: [u32],\n                        data: [f64],\n                        kind: TensorKind[Dense | SquareSymmetric | LowerTriangular]\n                    }?,\n                    num_iters: u32,\n                    num_basis_fns: u32,\n                    h_caps: [u32]?,\n                    mulliken_charges: [f64]?,\n                    h_core: Tensorf64 {\n                        data: [f64],\n                        kind: TensorKind[Dense | SquareSymmetric | LowerTriangular],\n                        shape: [u32]\n                    }?,\n                    mp2_ss_correction: f64?,\n                    hf_energy: f64?,\n                    delta_mp2_os_correction: f64?,\n                    fragments: [u32],\n                    mp2_gradients: [f64]?,\n                    fragment_distance: f64?,\n                    molecular_orbital_energies: [f64]?,\n                    overlap: Tensorf64 {\n                        data: [f64],\n                        kind: TensorKind[Dense | SquareSymmetric | LowerTriangular],\n                        shape: [u32]\n                    }?,\n                    bond_orders: [[f64]]?\n                }]],\n                expanded_hf_energy: f64?,\n                expanded_mp2_ss_correction: f64?\n            },\n            size: u32\n        }\n\n\n    :param input: Conformer with topology\n    :param system: system resources configuration\n    :param model: Optional Model configuration\n    :param scf keywords: Optional Self Consistent Field configuration\n    :param frag keywords: Optional Fragmentation configuration\n    :param guess keywords: Optional initial guess configuration\n    :return energy: energy results\n\n\n\n\nHERMES_RESOURCES = {\n    \"gpus\": 1,\n    \"storage\": 100,\n    \"storage_units\": \"MB\",\n    \"walltime\": 60,\n}\n\n\n(hermes_energy,) = client.hermes_energy(\n    fragmented_protein,\n    {},\n    {\n        \"basis\": \"STO-3G\",\n        \"aux_basis\": \"6-31G\",\n        \"method\": \"RestrictedHF\",\n    },  # configuration for a fast converging, low accuracy run\n    None,\n    {\n        \"cutoffs\": {\"dimer\": 22},\n        \"cutoff_type\": \"Centroid\",\n        \"level\": \"Dimer\",\n        # only get interaction energies against the terminal residue\n        \"reference_fragment\": len(\n            fragmented_protein_qdxf[\"topology\"][\"fragments\"]\n        )\n        - 1,\n    },\n    None,\n    resources=HERMES_RESOURCES,\n)\n\n\nenergy = json.load(hermes_energy.download(\"hermes_energy.json\").open())\n# Let's look at the expanded Hartree Fock energy\nenergy[\"expanded_hf_energy\"]\n\n2024-05-10 14:15:02,274 - rush - INFO - Argument a5ed3aa8-6c88-4681-8bd0-8701a9a392cf is now ModuleInstanceStatus.RESOLVING\n2024-05-10 14:15:05,962 - rush - INFO - Argument a5ed3aa8-6c88-4681-8bd0-8701a9a392cf is now ModuleInstanceStatus.ADMITTED\n2024-05-10 14:15:17,114 - rush - INFO - Argument a5ed3aa8-6c88-4681-8bd0-8701a9a392cf is now ModuleInstanceStatus.DISPATCHED\n2024-05-10 14:15:23,163 - rush - INFO - Argument a5ed3aa8-6c88-4681-8bd0-8701a9a392cf is now ModuleInstanceStatus.RUNNING\n2024-05-10 14:17:23,141 - rush - INFO - Argument a5ed3aa8-6c88-4681-8bd0-8701a9a392cf is now ModuleInstanceStatus.AWAITING_UPLOAD\n\n\n0.8083406411751639",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Tutorials",
      "Hermes — Run a basic Hartree-Fock energy calculation"
    ]
  },
  {
    "objectID": "Previous Versions/Tutorials/hermes_hartree_fock_energy_calculation.html#log-output",
    "href": "Previous Versions/Tutorials/hermes_hartree_fock_energy_calculation.html#log-output",
    "title": "Hermes — Run a basic Hartree-Fock energy calculation",
    "section": "4.1) Log output",
    "text": "4.1) Log output\nLet’s look at the first 15 lines of the first page of the logs.\n\nlogs_output = client.logs(hermes_energy.source, kind=\"stdout\")\n\n\nnext(logs_output)[0:15]\n\n['',\n '                 _..--+~/@-~--.      _____  __  __  _____   ____    ____',\n '             _-=~      (  .   \"}    | ____| \\\\ \\\\/ / | ____| / ___|  / ___|',\n '          _-~     _.--=.\\\\ \\\\\"\"\"\"     |  _|    \\\\  /  |  _|   \\\\___ \\\\  \\\\___ \\\\',\n '        _~      _-       \\\\ \\\\_\\\\      | |___   /  \\\\  | |___   ___) |  ___) |',\n \"       =      _=          '--'      |_____| /_/\\\\_\\\\ |_____| |____/  |____/\",\n \"      '      =\",\n '     :      :     ____            EXtreme-scale Electronic Structure Software',\n '___ |      ;                               Enjoy the power of GPUs!',\n '    ;       ;',\n '  ___=       \\\\ ___ __     __..-...__',\n '     :        =_     _.-~~          ~~--.__',\n '_____ \\\\         ~-+-~                   ___~=_______',\n '       == ...______ __ ___ _--~~--_',\n '  ']",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Tutorials",
      "Hermes — Run a basic Hartree-Fock energy calculation"
    ]
  },
  {
    "objectID": "Previous Versions/Tutorials/hermes_hartree_fock_energy_calculation.html#viewing-all-logs",
    "href": "Previous Versions/Tutorials/hermes_hartree_fock_energy_calculation.html#viewing-all-logs",
    "title": "Hermes — Run a basic Hartree-Fock energy calculation",
    "section": "4.2) Viewing all logs",
    "text": "4.2) Viewing all logs\nIf we wanted to view all the logs, we could do this:\n\n# If we wanted to view all the logs, we could do this:\n# async for log_page in client.logs(\n#     hermes_energy.source, kind=\"stdout\", print_logs=False\n# ):\n#     for log in log_page:\n#         print(log)",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Tutorials",
      "Hermes — Run a basic Hartree-Fock energy calculation"
    ]
  },
  {
    "objectID": "Previous Versions/comprehensive_guide.html",
    "href": "Previous Versions/comprehensive_guide.html",
    "title": "Comprehensive Guide",
    "section": "",
    "text": "Below we’ll walk through the process of building and running a drug discovery workflow explaining concepts in the Rush SDK, where we prepare a protein and ligand for molecular dynamics simulation, run the molecular dynamics and perform a mmpbsa energy calculation.\nFirst, install the following modules via pip - we require Python &gt; 3.9. Only rush-py is neccessary for interacting with the api, but we use additional packages in this notebook for fetching and visualizing data.",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Comprehensive Guide"
    ]
  },
  {
    "objectID": "Previous Versions/comprehensive_guide.html#imports",
    "href": "Previous Versions/comprehensive_guide.html#imports",
    "title": "Comprehensive Guide",
    "section": "Imports",
    "text": "Imports\n\nimport os\nimport tarfile\nfrom datetime import datetime\nfrom pathlib import Path\n\nfrom pdbtools import (\n    pdb_fetch,\n    pdb_delhetatm,\n    pdb_selchain,\n    pdb_rplresname,\n    pdb_keepcoord,\n    pdb_selresname,\n)\nimport py3Dmol\n\nimport rush",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Comprehensive Guide"
    ]
  },
  {
    "objectID": "Previous Versions/comprehensive_guide.html#credentials",
    "href": "Previous Versions/comprehensive_guide.html#credentials",
    "title": "Comprehensive Guide",
    "section": "Credentials",
    "text": "Credentials\nRetrieve your api token from the Rush UI.\nYou can either set the RUSH_TOKEN and RUSH_URL environment variables, or provide them as variables to the client directly.\nTo see how to set environment variables, Wikipedia has an extensive article\n\nRUSH_TOKEN = os.getenv(\"RUSH_TOKEN\") or \"YOUR_TOKEN_HERE\"\nRUSH_URL = os.getenv(\"RUSH_URL\") or \"https://tengu.qdx.ai\"",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Comprehensive Guide"
    ]
  },
  {
    "objectID": "Previous Versions/comprehensive_guide.html#configuration",
    "href": "Previous Versions/comprehensive_guide.html#configuration",
    "title": "Comprehensive Guide",
    "section": "Configuration",
    "text": "Configuration\nLets set some global variables that define our project, these are not required, but are good practice to help organize the jobs that will be persisted under your account.\nMake sure you create a unique set of tags for each run. Good practice is to have at least each of the experiment name and system name as a tag.\n\nEXPERIMENT = \"rush-py-v2-explainer\"\nSYSTEM = \"1B39\"\nLIGAND = \"ATP\"\nTAGS = [\"qdx\", EXPERIMENT, SYSTEM, LIGAND]",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Comprehensive Guide"
    ]
  },
  {
    "objectID": "Previous Versions/comprehensive_guide.html#build-your-client",
    "href": "Previous Versions/comprehensive_guide.html#build-your-client",
    "title": "Comprehensive Guide",
    "section": "Build your client",
    "text": "Build your client\nGet our client, for calling modules and using the Rush API.\nAs mentioned earlier access_token and url are optional, if you have set the env variables RUSH_TOKEN and RUSH_URL.\nbatch_tags will be applied to each run that is spawned by this client.\nA folder called .rush will be created in your workspace directory (defaults to the current working directory), can be overridden by passing workspace= to the provider builder\n\n# By using the `build_provider_with_functions` method,\n# we will also build helper functions calling each module\nclient = rush.build_blocking_provider_with_functions(\n    access_token=RUSH_TOKEN, url=RUSH_URL, batch_tags=TAGS\n)\n\n2024-05-20 10:58:24,776 - rush - INFO - Restoring by default via env",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Comprehensive Guide"
    ]
  },
  {
    "objectID": "Previous Versions/comprehensive_guide.html#input-file-paths",
    "href": "Previous Versions/comprehensive_guide.html#input-file-paths",
    "title": "Comprehensive Guide",
    "section": "Input file paths",
    "text": "Input file paths\nSet where we want to save our inputs\n\nSYSTEM_PDB_PATH = client.workspace / f\"{SYSTEM}.pdb\"\nPROTEIN_PDB_PATH = client.workspace / f\"{SYSTEM}_P.pdb\"\nLIGAND_SMILES_STR = \"c1nc(c2c(n1)n(cn2)[C@H]3[C@@H]([C@@H]([C@H](O3)CO[P@@](=O)(O)O[P@](=O)(O)OP(=O)(O)O)O)O)N\"\nLIGAND_FILE_PATH = client.workspace / f\"{SYSTEM}L.smi\"\nLIGAND_PDB_PATH = client.workspace / f\"{LIGAND}_L.pdb\"\n\nFetch datafiles from rcsb\n\ncomplex = list(pdb_fetch.fetch_structure(SYSTEM))\nprotein = pdb_delhetatm.remove_hetatm(pdb_selchain.select_chain(complex, \"A\"))\n# select the ATP residue\nligand = pdb_selresname.filter_residue_by_name(complex, LIGAND)\n# we require ligands to be labelled as UNL\nligand = pdb_rplresname.rename_residues(ligand, LIGAND, \"UNL\")\n# we don't want to repeat all of the remark / metadata that is already in the\n# protein\nligand = pdb_keepcoord.keep_coordinates(ligand)\n# write our files to the locations defined in the config block\nwith open(SYSTEM_PDB_PATH, \"w\") as f:\n    for l in complex:\n        f.write(str(l))\nwith open(PROTEIN_PDB_PATH, \"w\") as f:\n    for l in protein:\n        f.write(str(l))\nwith open(LIGAND_PDB_PATH, \"w\") as f:\n    for l in ligand:\n        f.write(str(l))",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Comprehensive Guide"
    ]
  },
  {
    "objectID": "Previous Versions/comprehensive_guide.html#view-rush-modules",
    "href": "Previous Versions/comprehensive_guide.html#view-rush-modules",
    "title": "Comprehensive Guide",
    "section": "View rush modules",
    "text": "View rush modules\nRush modules are “functions” that perform various computational chemistry tasks can be run on HPC infrastructure. We maintain multiple versions of these functions so that your scripts will stay stable over upgrades.\n\n# Get our latest modules as a dict[module_name, module_path]\n# If a lock file exists, load it so that the run is reproducible\n# This will be done automatically if you use the `build_provider_with_functions`\n# method\nmodules = client.get_latest_module_paths_blocking()\n\n\nmodule_name = \"hermes_energy\"\nmodule_path = modules[module_name]\nprint(module_path)\n\ngithub:talo/tengu-prelude/3d11b61a2092fbec721966ffa99743f8bfabe6c2#hermes_energy\n\n\n\nmodule_name is a descriptive string and indicates the “function” the module is calling;\nmodule_path is a versioned rush “endpoint” for a module accessible via the client.\n\nUsing the same module_path string across multiple runs provides reproducibility.",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Comprehensive Guide"
    ]
  },
  {
    "objectID": "Previous Versions/comprehensive_guide.html#use-module-functions",
    "href": "Previous Versions/comprehensive_guide.html#use-module-functions",
    "title": "Comprehensive Guide",
    "section": "Use module functions",
    "text": "Use module functions\nNext, we’ll use helper functions for the modules that we’ve fetched\nIf we have built a provider with functions, we can use the python help() function to describe their usage.\nThe QDX Type Description is a standard type definition across multiple programing languages to assist in interoperablility. @ indicates that the type is stored in a file, which will be synced to cloud storage\n\nhelp(client.convert)\n\nHelp on function convert in module rush.provider:\n\nconvert(*args: *tuple[EnumValue, RushObject[bytes]], target: 'Target | None' = None, resources: 'Resources | None' = None, tags: 'list[str] | None' = None, restore: 'bool | None' = None) -&gt; tuple[RushObject[list[Record]]]\n    Convert biomolecular and chemical file formats to the QDX file format. Supports PDB and SDF\n\n    Module version:\n    `github:talo/tengu-prelude/3d11b61a2092fbec721966ffa99743f8bfabe6c2#convert`\n\n    QDX Type Description:\n\n        format: Format[PDB | SDF];\n        input: Object {format: ObjectFormat[json | bin]?, size: u32, path: @$Bytes}\n        -&gt;\n        output: Object[[Conformer]]\n\n\n    :param format: the format of the input file\n    :param input: the input file\n    :return output: the output conformers",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Comprehensive Guide"
    ]
  },
  {
    "objectID": "Previous Versions/comprehensive_guide.html#updating-modules",
    "href": "Previous Versions/comprehensive_guide.html#updating-modules",
    "title": "Comprehensive Guide",
    "section": "Updating Modules",
    "text": "Updating Modules\nNew modules and new versions of modules are constantly being deployed. We ensure that interface and behavioural changes don’t affect your current scripts by “locking” module versions the first time you build a provider. You can fetch new versions of modules by using the .update_modules function, like so:\n\nclient.update_modules()",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Comprehensive Guide"
    ]
  },
  {
    "objectID": "Previous Versions/comprehensive_guide.html#preparation",
    "href": "Previous Versions/comprehensive_guide.html#preparation",
    "title": "Comprehensive Guide",
    "section": "Preparation",
    "text": "Preparation\n\nPrepare the protein\nFirst we will run the protein preparation routine (using pdbfixer and pdb2pqr internally) to prepare the protein for molecular dynamics\n\n# we can check the arguments and outputs for prepare_protein with help()\nhelp(client.prepare_protein)\n\nHelp on function prepare_protein in module rush.provider:\n\nprepare_protein(*args: *tuple[RushObject[bytes], Optional[float], Optional[EnumValue]], target: 'Target | None' = None, resources: 'Resources | None' = None, tags: 'list[str] | None' = None, restore: 'bool | None' = None) -&gt; tuple[RushObject[list[Record]], RushObject[bytes]]\n    Prepare a PDB for downstream tasks: protonate, fill missing atoms, etc.\n\n    Module version:\n    `github:talo/prepare_protein/9af3512509062490f73302e3c8c7d4296036e678#prepare_protein_tengu`\n\n    QDX Type Description:\n\n        input_pdb: Object[@$PDB];\n        ph: f32?;\n        naming_scheme: NamingScheme[Amber | Charmm]?\n        -&gt;\n        output_qdxf: Object[[Conformer]];\n        output_pdb: Object[@$PDB]\n\n\n    :param input_pdb: An input protein as a file; one PDB file\n    :param ph: The ph for determining protonation states; 0-14\n    :param naming_scheme: \\\n                    The force field naming scheme to use; \\\n                    options are \"amber\" or \"charmm\"; \\\n                    None produces RCSB/IUPAC standard naming\\\n\n    :return output_qdxf: An output protein a vec: one qdxf per model in pdb\n    :return output_pdb: An output protein as a file: one PDB file\n\n\n\n\n# Here we run the function, it will return a Provider.Arg which you can use to\n# fetch the results\n# We set restore = True so that we can restore a previous run to the same path\n# with the same tags\nprepared_protein_qdxf, prepared_protein_pdb = client.prepare_protein(\n    PROTEIN_PDB_PATH, None, None\n)\n# This initially only has the id of your result; we will show how to fetch the\n# actual value later\nprint(f\"{datetime.now().time()} | Running protein prep!\")\n\n2024-05-20 10:58:43,032 - rush - INFO - Trying to restore job with tags: ['qdx', 'rush-py-v2-explainer', '1B39', 'ATP'] and path: github:talo/prepare_protein/9af3512509062490f73302e3c8c7d4296036e678#prepare_protein_tengu\n2024-05-20 10:58:43,189 - rush - WARNING - Multiple module instances found with the same tags and path\n2024-05-20 10:58:43,190 - rush - WARNING - Multiple module instances found with the same tags and path\n2024-05-20 10:58:43,190 - rush - WARNING - Multiple module instances found with the same tags and path\n2024-05-20 10:58:43,190 - rush - WARNING - Multiple module instances found with the same tags and path\n2024-05-20 10:58:43,190 - rush - WARNING - Multiple module instances found with the same tags and path\n2024-05-20 10:58:43,191 - rush - WARNING - Multiple module instances found with the same tags and path\n2024-05-20 10:58:43,191 - rush - WARNING - Multiple module instances found with the same tags and path\n2024-05-20 10:58:43,191 - rush - WARNING - Multiple module instances found with the same tags and path\n2024-05-20 10:58:43,191 - rush - WARNING - Multiple module instances found with the same tags and path\n2024-05-20 10:58:43,191 - rush - WARNING - Multiple module instances found with the same tags and path\n2024-05-20 10:58:43,191 - rush - WARNING - Multiple module instances found with the same tags and path\n2024-05-20 10:58:43,192 - rush - WARNING - Multiple module instances found with the same tags and path\n2024-05-20 10:58:43,192 - rush - WARNING - Multiple module instances found with the same tags and path\n2024-05-20 10:58:43,302 - rush - INFO - Restoring job from previous run with id 476f7282-4bc6-4597-afc2-b755979c6377\n10:58:43.304105 | Running protein prep!\n\n\n\n\nChecking results\n\nRun statuses\nThis will show the status of all of your runs\n\nclient.status()\n\n{}\n\n\n\n\nRun Logs\nIf any of our runs fail, we can check their logs with or view them in the Rush UI\n\nfor instance_id, (status, name, count) in (client.status()).items():\n    if status.value == \"FAILED\":\n        client.logs(instance_id, \"stderr\")\n\n\n\nRun Values\nThis will return the “value” of the output from the function - for files you will recieve a url that you can download, otherwise you will recieve them as python types\n\nprepared_protein_pdb.get()\n\n'https://storage.googleapis.com/rush_store_default/ce5f515b-fa97-4b70-84a2-91c6a1d7a1d3?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=qdx-store-user%40humming-bird-321603.iam.gserviceaccount.com%2F20240520%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20240520T025843Z&X-Goog-Expires=3600&X-Goog-SignedHeaders=host&X-Goog-Signature=40b392c54574c2769b79f952bfc6c7c3016daee36267af926b37248cefcc15500856804725d6e07a57edeedd00c8d13eace4b174cd1818b4d4e01c9278e63ca52c527ff4ed8d3471abd942eedc5a63bd7dd76884e934c38db9efe310f7b596a1b513109b892b29950d7149ffb127d0d8f16a0bee2a3b7bc3c15f15c6cb28b6fe3c014522cb1e2683accafd41c05a16fe601555533c30d25a024b714dd5c2c3e55b825db4cdc6fafddc3472351c476d8c4195e7dc2756811f2e82f335f684ab455d4c7435c1e009c221f06ce8f567810fd940080fd120c89f041d7be48f01748532b6029b75dd5e00f46e3a647b16f05bf70a2feff1ac7295d2e73254b663be09'\n\n\n\n\nDownloads\nWe provide a utility to download files into your workspace, you can either provide a filename, which will be saved in workspace/objects/[filename], or you can provide your own filepath which the client will use as-is\n\ndownloaded_protein_path = prepared_protein_pdb.download(\n    filename=\"01_prepared_protein.pdb\", overwrite=True\n)\n\nWe can read our prepared protein pdb like this\n\nwith open(downloaded_protein_path, \"r\") as f:\n    print(f.readline(), \"...\")\n\nREMARK   1 CREATED WITH OPENMM 8.0, 2024-05-10\n ...\n\n\nYou should visualize your prepared protein to spot check any incorrectly transformed residues\n\nview = py3Dmol.view()\nwith open(client.workspace / \"objects\" / \"01_prepared_protein.pdb\", \"r\") as f:\n    view.addModel(f.read(), \"pdb\")\n    view.setStyle({\"cartoon\": {\"color\": \"spectrum\"}})\n    view.zoomTo()\n    view.show()\n\n\n        3Dmol.js failed to load for some reason.  Please check your browser console for error messages.\n        \n\n\n\n\n\n\nPrepare the ligand\nNext we will prepare the ligand (using auto3d internally)\n\n# we can check the inputs for prepare_ligand with help()\nhelp(client.auto3d)\n\nHelp on function auto3d in module rush.provider:\n\nauto3d(*args: *tuple[RushObject[bytes], str, Record], target: 'Target | None' = None, resources: 'Resources | None' = None, tags: 'list[str] | None' = None, restore: 'bool | None' = None) -&gt; tuple[RushObject[bytes], RushObject[list[Record]]]\n    Generate 3D conformers from SMILES strings and other inputs\n\n    Module version:\n    `github:talo/tengu-auto3d/05fbc5014bf4e7f2890e70428c62234cdb902336#auto3d_tengu`\n\n    QDX Type Description:\n\n        molecule_file: Object {format: ObjectFormat[json | bin]?, path: @$Bytes, size: u32};\n        molecule_file_type: string;\n        options: Auto3dOptions {\n            max_confs: u32?,\n            convergence_threshold: f32?,\n            use_gpu: bool?,\n            job_name: string?,\n            enumerate_tautomer: bool?,\n            memory: u32?,\n            threshold: f32?,\n            batchsize_atoms: u32?,\n            k: i32?,\n            verbose: bool?,\n            gpu_idx: [u32]?,\n            window: f32?,\n            capacity: u32?,\n            optimizing_engine: Auto3dOptimizingEngines[ANI2x | ANI2xt | AIMNET]?,\n            mpi_np: u32?,\n            opt_steps: u32?,\n            patience: u32?,\n            enumerate_isomer: bool?\n        }\n        -&gt;\n        conformer_sdf: Object[@$SDF, format: ObjectFormat[json | bin]?];\n        conformers: Object[[Conformer]]\n\n\n    :param molecule_file: The input molecules as a file; either one SMILES string per line, or an SDF\n    :param molecule_file_type: The string 'smi' or 'sdf', depending on the input type\n    :param options: A dict with options to pass; see auto3d docs for details\n    :return conformer_sdf: A sdf file containing the ligand(s)'s conformers\n    :return conformers: A vec of qdxf conformers\n\n\n\n\nwith open(LIGAND_FILE_PATH, \"w\") as f:\n    print(f\"{LIGAND_SMILES_STR} {LIGAND_SMILES_STR}\", file=f)\n\n# takes a path with the SMILES\n(ligand_sdf, ligand_qdxf) = client.auto3d(\n    LIGAND_FILE_PATH,\n    \"smi\",\n    {\"k\": 2, \"use_gpu\": True},\n    resources={\"gpus\": 1, \"storage\": \"5\", \"storage_units\": \"MB\"},\n)\n\nprint(f\"{datetime.now().time()} | Running ligand prep!\")\n\n2024-05-20 10:58:44,182 - rush - INFO - Trying to restore job with tags: ['qdx', 'rush-py-v2-explainer', '1B39', 'ATP'] and path: github:talo/tengu-auto3d/05fbc5014bf4e7f2890e70428c62234cdb902336#auto3d_tengu\n2024-05-20 10:58:44,318 - rush - INFO - Restoring job from previous run with id d5b738c8-67d6-4b9d-a552-1e0a5c62af66\n10:58:44.318748 | Running ligand prep!\n\n\n\n# we can check the status again\nclient.status()\n\n{}\n\n\n\n# we can download our outputs\nligand_sdf.download(filename=\"01_prepped_ligand.sdf\", overwrite=True)\n\nprint(f\"{datetime.now().time()} | Downloaded prepped ligand!\")\n\n10:58:44.797451 | Downloaded prepped ligand!\n\n\n\n# we can read our outputs\nwith open(client.workspace / \"objects\" / \"01_prepped_ligand.sdf\", \"r\") as f:\n    print(f.readline(), f.readline(), \"...\")\n\nc1nc(c2c(n1)n(cn2)[C@H]3[C@@H]([C@@H]([C@H](O3)CO[P@@](=O)(O)O[P@](=O)(O)OP(=O)(O)O)O)O)N\n      RDKit          3D\n ...",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Comprehensive Guide"
    ]
  },
  {
    "objectID": "Previous Versions/comprehensive_guide.html#run-gromacs",
    "href": "Previous Versions/comprehensive_guide.html#run-gromacs",
    "title": "Comprehensive Guide",
    "section": "Run GROMACS",
    "text": "Run GROMACS\nNext we will run a molecular dynamics simulation on our protein and ligand, using gromacs (gmx)\n\nhelp(client.gmx)\n\nHelp on function gmx in module rush.provider:\n\ngmx(*args: *tuple[Optional[RushObject[Record]], Optional[RushObject[bytes]], Optional[RushObject[bytes]], Record], target: 'Target | None' = None, resources: 'Resources | None' = None, tags: 'list[str] | None' = None, restore: 'bool | None' = None) -&gt; tuple[RushObject[bytes], RushObject[bytes], RushObject[bytes], RushObject[bytes], RushObject[bytes], RushObject[bytes], RushObject[bytes]]\n    Runs a molecular dynamics simluation using GROMACS from either protein, ligand pdbs or conformers as inputs.\n\n    Note that the residue (i.e. amino acid) and atom naming in any input PDB files must match the naming scheme of the chosen force field (which defaults to amber14SB-OL15). The code makes a best-effort attempt to map residue and atom names from standard version 3.0 PDB files (i.e. those obtained from RCSB or following the IUPAC naming recommendations) to those required by the chosen force field, but no guarantees are made. Files produced by the \"prepare_protein\" module are guaranteed to work.\n\n    Uses GMX 2023.3 https://doi.org/10.5281/zenodo.10017686 and Acpype https://doi.org/10.1186/1756-0500-5-367\n\n    Module version:\n    `github:talo/tengu-gmx/e94bc9ca4b7ba774d59aeb5f0e07917af22b6a80#gmx_tengu`\n\n    QDX Type Description:\n\n        conformer: Object[Conformer];\n        protein: Object[@$Bytes]?;\n        ligand: Object[@$Bytes, format: ObjectFormat[json | bin]?]?;\n        gmx_config: GMXTenguConfig {\n            timeout_duration_mins: u32?,\n            save_wets: bool?,\n            frame_sel: FrameSelConfig {\n                end_time_ps: u32,\n                start_time_ps: u32,\n                delta_time_ps: u32\n            }?,\n            perf_flags_override: string?,\n            params_overrides: GMXOverrides {\n                nvt: NVTOverrides {\n                    lincs_iter: i32?,\n                    tau_t: [f64]?,\n                    pbc: string?,\n                    rcoulomb: f64?,\n                    lincs_order: i32?,\n                    dt: f64?,\n                    integrator: string?,\n                    fourierspacing: f64?,\n                    vdwtype: string?,\n                    vdw_modifier: string?,\n                    nstenergy: i32?,\n                    nstlog: i32?,\n                    disp_corr: string?,\n                    rvdw_switch: f64?,\n                    pcoupl: string?,\n                    gen_temp: f64?,\n                    rvdw: f64?,\n                    cutoff_scheme: string?,\n                    define: string?,\n                    nsteps: i32?,\n                    tc_grps: string?,\n                    gen_vel: string?,\n                    coulombtype: string?,\n                    nstxout_compressed: i32?,\n                    pme_order: i32?,\n                    tcoupl: string?,\n                    gen_seed: i32?,\n                    constraint_algorithm: string?,\n                    continuation: string?,\n                    rlist: f64?,\n                    ref_t: [f64]?,\n                    constraints: string?\n                }?,\n                ions: IonsOverrides {\n                    coulombtype: string?,\n                    cutoff_scheme: string?,\n                    integrator: string?,\n                    pbc: string?,\n                    rvdw: f64?,\n                    emtol: f64?,\n                    emstep: f64?,\n                    nsteps: i32?,\n                    nstlog: i32?,\n                    rlist: f64?,\n                    rcoulomb: f64?\n                }?,\n                em: EMOverrides {\n                    emstep: f64?,\n                    integrator: string?,\n                    coulombtype: string?,\n                    cutoff_scheme: string?,\n                    nstlog: i32?,\n                    rlist: f64?,\n                    rvdw: f64?,\n                    pbc: string?,\n                    emtol: f64?,\n                    rcoulomb: f64?,\n                    nsteps: i32?\n                }?,\n                md: MDOverrides {\n                    fourierspacing: f64?,\n                    disp_corr: string?,\n                    tau_p: f64?,\n                    nstlog: i32?,\n                    tau_t: [f64]?,\n                    rcoulomb: f64?,\n                    ref_t: [f64]?,\n                    rvdw_switch: f64?,\n                    pme_order: i32?,\n                    vdw_modifier: string?,\n                    vdwtype: string?,\n                    rvdw: f64?,\n                    constraints: string?,\n                    nstenergy: i32?,\n                    coulombtype: string?,\n                    tcoupl: string?,\n                    lincs_iter: i32?,\n                    rlist: f64?,\n                    nsteps: i32?,\n                    nstxout_compressed: i32?,\n                    gen_vel: string?,\n                    constraint_algorithm: string?,\n                    integrator: string?,\n                    pcoupl: string?,\n                    ref_p: f64?,\n                    continuation: string?,\n                    lincs_order: i32?,\n                    pbc: string?,\n                    cutoff_scheme: string?,\n                    dt: f64?,\n                    tc_grps: string?,\n                    pcoupltype: string?,\n                    compressibility: f64?\n                }?,\n                npt: NPTOverrides {\n                    nstxout_compressed: i32?,\n                    dt: f64?,\n                    ref_p: f64?,\n                    tau_p: f64?,\n                    rvdw: f64?,\n                    define: string?,\n                    pcoupltype: string?,\n                    continuation: string?,\n                    fourierspacing: f64?,\n                    disp_corr: string?,\n                    refcoord_scaling: string?,\n                    rcoulomb: f64?,\n                    ref_t: [f64]?,\n                    integrator: string?,\n                    constraints: string?,\n                    cutoff_scheme: string?,\n                    compressibility: f64?,\n                    coulombtype: string?,\n                    pcoupl: string?,\n                    gen_vel: string?,\n                    rvdw_switch: f64?,\n                    constraint_algorithm: string?,\n                    nstlog: i32?,\n                    pbc: string?,\n                    pme_order: i32?,\n                    nstenergy: i32?,\n                    vdw_modifier: string?,\n                    nsteps: i32?,\n                    tcoupl: string?,\n                    tc_grps: string?,\n                    tau_t: [f64]?,\n                    vdwtype: string?,\n                    lincs_order: i32?,\n                    lincs_iter: i32?,\n                    rlist: f64?\n                }?\n            }?,\n            num_gpus: u8,\n            num_replicas: u8?,\n            ignore_hydrogens: bool?,\n            checkpoint_interval_mins: f32?,\n            ligand_charge: i8?,\n            force_field: string?,\n            water_box_size: f32?\n        }\n        -&gt;\n        resume_files: Object[@$Bytes];\n        streaming_outputs: Object {\n            size: u32,\n            path: @$Bytes,\n            format: ObjectFormat[json | bin]?\n        };\n        static_outputs: Object {format: ObjectFormat[json | bin]?, size: u32, path: @$Bytes};\n        output_xtcs_dry: Object {\n            format: ObjectFormat[json | bin]?,\n            path: @$Bytes,\n            size: u32\n        };\n        output_frames_pdb_dry: Object {\n            path: @$Bytes,\n            size: u32,\n            format: ObjectFormat[json | bin]?\n        };\n        output_xtcs_wet: Object {\n            size: u32,\n            format: ObjectFormat[json | bin]?,\n            path: @$Bytes\n        };\n        output_frames_pdb_wet: Object {\n            format: ObjectFormat[json | bin]?,\n            path: @$Bytes,\n            size: u32\n        }\n\n\n    :param conformer: Optional Conformer in QDXF format; must provide either this argument, or the Protein PDB argument\n    :param protein: Protein PDB file; provide this if no Conformer QDXF is provided\n    :param ligand: Ligand PDB file\n    :param gmx_config: Configuration record\n    :return resume_files: .tpr, .cpt, .ndx, .top, & .itp files of the production MD runs\n    :return streaming_outputs: .edr, .log, & .xtc files from the production MD runs\n    :return static_outputs: .gro & .xvg files files from the runs\n    :return output_xtcs_dry: Processed dry trajectories, i.e., without water molecules, from the production MD runs\n    :return output_frames_pdb_dry: Outputs of select_frame; pdb frames without water\n    :return output_xtcs_wet: Processed wet trajectories, i.e., with water molecules, from the production MD runs\n    :return output_frames_pdb_wet: Outputs of select_frame; pdb frames with water\n\n\n\n\nimport json\nimport qdx_py\n\nPREPARED_LIGAND_PATH = client.workspace / \"prepared_ligand.pdb\"\nwith open(ligand_qdxf.download(overwrite=True)) as f:\n    ligand_qdxf_out = json.load(f)\nprepared_ligand_str = qdx_py.conformer_to_pdb(\n    json.dumps(ligand_qdxf_out[0])\n).replace(\"LIG\", \"UNL\")\nwith open(PREPARED_LIGAND_PATH, \"w\") as f:\n    f.write(prepared_ligand_str)\n\n\ngmx_config = {\n    \"params_overrides\": {\n        \"em\": {\"nsteps\": 5000},\n        \"nvt\": {\"nsteps\": 2000},\n        \"npt\": {\"nsteps\": 2000},\n        \"md\": {\"nsteps\": 5000},\n        \"ions\": {},\n    },\n    \"num_gpus\": 0,\n    \"num_replicas\": 1,\n    \"ligand_charge\": None,\n    \"save_wets\": False,\n    \"frame_sel\": {\n        \"start_time_ps\": 0,\n        \"end_time_ps\": 10,\n        \"delta_time_ps\": 1,\n    },\n}\n# we pass the outputs from our prior runs directly, instead of their values,\n# to prevent them from being re-uploaded\n_, _, gmx_static_outputs, _, gmx_dry_frames, _, _ = client.gmx(\n    None,\n    prepared_protein_pdb,\n    PREPARED_LIGAND_PATH,\n    gmx_config,\n    resources={\n        \"gpus\": 1,\n        \"storage\": 1,\n        \"storage_units\": \"GB\",\n    },\n)\nprint(f\"{datetime.now().time()} | Running GROMACS simulation!\")\n\n2024-05-20 10:58:45,349 - rush - INFO - Trying to restore job with tags: ['qdx', 'rush-py-v2-explainer', '1B39', 'ATP'] and path: github:talo/tengu-gmx/e94bc9ca4b7ba774d59aeb5f0e07917af22b6a80#gmx_tengu\n2024-05-20 10:58:45,540 - rush - WARNING - Multiple module instances found with the same tags and path\n2024-05-20 10:58:45,541 - rush - WARNING - Multiple module instances found with the same tags and path\n2024-05-20 10:58:45,541 - rush - WARNING - Multiple module instances found with the same tags and path\n2024-05-20 10:58:45,541 - rush - WARNING - Multiple module instances found with the same tags and path\n2024-05-20 10:58:45,541 - rush - WARNING - Multiple module instances found with the same tags and path\n2024-05-20 10:58:45,541 - rush - WARNING - Multiple module instances found with the same tags and path\n2024-05-20 10:58:45,657 - rush - INFO - Restoring job from previous run with id 8d59a470-cfb7-4731-b9b3-7f7c3ac4d094\n10:58:45.658512 | Running GROMACS simulation!\n\n\n\n# we can check the status again\nclient.status()\n\n{}\n\n\n\nprint(\"Fetching gmx results\")\n\ngmx_static_outputs.download(\n    filename=\"02_gmx_static_outputs.tar.gz\", overwrite=True\n)\ngmx_dry_frames.download(filename=\"02_gmx_dry_frames.tar.gz\", overwrite=True)\n\nprint(f\"{datetime.now().time()} | Downloaded GROMACS output!\")\n\nFetching gmx results\n10:58:46.636429 | Downloaded GROMACS output!\n\n\n\n# Extract the \"dry\" (i.e. non-solvated) pdb frames we asked for\nwith tarfile.open(\n    client.workspace / \"objects\" / \"02_gmx_dry_frames.tar.gz\", \"r\"\n) as tf:\n    selected_frame_pdbs = [\n        tf.extractfile(member).read()\n        for member in tf\n        if \"pdb\" in member.name and member.isfile()\n    ]\n    for i, frame in enumerate(selected_frame_pdbs):\n        with open(\n            client.workspace / \"objects\" / f\"02_gmx_output_frame_{i}.pdb\", \"w\"\n        ) as pf:\n            print(frame.decode(\"utf-8\"), file=pf)\n\n\n# Extract the ligand.gro file\nwith tarfile.open(\n    client.workspace / \"objects\" / \"02_gmx_static_outputs.tar.gz\", \"r\"\n) as tf:\n    gro = [\n        tf.extractfile(member).read()\n        for member in tf\n        if \"md.ligand_in.0.gro\" in member.name\n    ][0]\n    with open(client.workspace / \"objects\" / f\"md.ligand_in.0.gro\", \"w\") as pf:\n        print(gro.decode(\"utf-8\"), file=pf)\n\n\n(client.workspace / \"objects\" / f\"md.ligand_in.0.gro\").read_text()[0:50]\n\n'Protein in water\\n47836\\n    1MET      N    1   4.89'",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Comprehensive Guide"
    ]
  },
  {
    "objectID": "Previous Versions/Quickstarts/convert-sample.html",
    "href": "Previous Versions/Quickstarts/convert-sample.html",
    "title": "Convert — Run a simple conversion of a PDB to the QDXF format",
    "section": "",
    "text": "See the tutorial for a more detailed explanation.\n\n# Get a pdb to work with\n# We use the pdb-tools cli here but you can download directly from rcsb.org\n!pdb_fetch '1brs' | pdb_selchain -A | pdb_delhetatm &gt; '1B39_A_nohet.pdb'\n!ls\n\n1B39_A_nohet.pdb\n\n\n\nfrom pathlib import Path\n\nimport rush\n\nclient = rush.build_blocking_provider_with_functions(batch_tags=[\"convert\"])\n\n(conformer,) = client.convert(\n    \"PDB\", Path.cwd() / \"1B39_A_nohet.pdb\", target=\"TINY\"\n)\nprint(conformer.download().read_text()[0:70], \"...\")\n\n2024-04-23 13:25:53,424 - rush - INFO - Argument 990429dc-90c8-486d-8e21-708dc17fab82 is now ModuleInstanceStatus.RESOLVING\n2024-04-23 13:25:54,601 - rush - INFO - Argument 990429dc-90c8-486d-8e21-708dc17fab82 is now ModuleInstanceStatus.ADMITTED\n2024-04-23 13:25:59,464 - rush - INFO - Argument 990429dc-90c8-486d-8e21-708dc17fab82 is now ModuleInstanceStatus.RUNNING\n2024-04-23 13:26:00,693 - rush - INFO - Argument 990429dc-90c8-486d-8e21-708dc17fab82 is now ModuleInstanceStatus.AWAITING_UPLOAD\n[{\"topology\": {\"symbols\": [\"N\", \"C\", \"C\", \"O\", \"C\", \"C\", \"C\", \"N\", \"C\" ...",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Quickstarts",
      "Convert — Run a simple conversion of a PDB to the QDXF format"
    ]
  },
  {
    "objectID": "Previous Versions/Quickstarts/batch_run-protein_prep_async-sample.html",
    "href": "Previous Versions/Quickstarts/batch_run-protein_prep_async-sample.html",
    "title": "prepare_protein — Run a batch protein preperation in parallel",
    "section": "",
    "text": "See the tutorial.\nThis quickstart uses the async functionality to download files in parallel. If running outside of a Juptyter notebook, you will need to wrap the code in an async main function like this:\nimport asyncio\n\nasync def main():\n    #your code here\n    \nasyncio.run(main())\n\n# Get PDBs to work with\n# We use the pdb-tools cli here but you can download directly from rcsb.org\n!pdb_fetch '1b39' | pdb_delhetatm &gt; '1B39_nohet.pdb'\n!pdb_fetch '4qxi' | pdb_delhetatm &gt; '4QXI_nohet.pdb'\n!pdb_fetch '8fsu' | pdb_delhetatm &gt; '8FSU_nohet.pdb'\n\n\nimport asyncio\nfrom glob import glob\nfrom pathlib import Path\n\nimport rush\n\nclient = await rush.build_provider_with_functions(\n    batch_tags=[\"batch_run_protein_prep\"]\n)\n\nprotein_outputs = []\nfor protein_path in glob(str(Path.cwd() / \"*.pdb\")):\n    print(\"preparing\", protein_path)\n    protein_path = Path(protein_path)\n    name = protein_path.stem\n\n    prepped_protein_qdxf, prepped_protein_pdb = await client.prepare_protein(\n        protein_path,\n        None,\n        None,\n        tags=[\"batch_run_protein_prep\"],\n        resources={\"gpus\": 1, \"storage\": \"10\", \"storage_units\": \"MB\"},\n    )\n    protein_outputs.append((name, prepped_protein_qdxf, prepped_protein_pdb))\n\nawait asyncio.gather(\n    *(\n        [\n            output[1].download(filename=f\"protein_{output[0]}_prepared.qdxf.json\")\n            for output in protein_outputs\n        ]\n        + [\n            output[2].download(filename=f\"protein_{output[0]}_prepared.pdb\")\n            for output in protein_outputs\n        ]\n    )\n)\n\n2024-04-10 15:46:57,187 - rush - INFO - Not restoring by default via default\npreparing /home/machineer/qdx/qs_batch_run_protein_prep/8FSU_nohet.pdb\npreparing /home/machineer/qdx/qs_batch_run_protein_prep/1B39_nohet.pdb\npreparing /home/machineer/qdx/qs_batch_run_protein_prep/4QXI_nohet.pdb\n2024-04-10 15:47:03,897 - rush - INFO - Argument feae45e5-6d88-465f-bc71-722848c6d06e is now ModuleInstanceStatus.RESOLVING\n2024-04-10 15:47:03,961 - rush - INFO - Argument 75bb4f40-0ce6-4093-8add-475d1f38e226 is now ModuleInstanceStatus.RESOLVING\n2024-04-10 15:47:03,992 - rush - INFO - Argument 71189844-b1a3-40c3-8e2e-a2e4d2eace28 is now ModuleInstanceStatus.RESOLVING\n2024-04-10 15:47:04,004 - rush - INFO - Argument 770a9c09-030a-4d12-8e19-252787039875 is now ModuleInstanceStatus.RESOLVING\n2024-04-10 15:47:04,035 - rush - INFO - Argument d280af91-5816-4f32-8120-e6e2ede8b4b1 is now ModuleInstanceStatus.RESOLVING\n2024-04-10 15:47:04,045 - rush - INFO - Argument ea6e2e0f-aa8f-4d20-9192-c2f099859878 is now ModuleInstanceStatus.RESOLVING\n2024-04-10 15:47:05,066 - rush - INFO - Argument 71189844-b1a3-40c3-8e2e-a2e4d2eace28 is now ModuleInstanceStatus.ADMITTED\n2024-04-10 15:47:05,097 - rush - INFO - Argument 770a9c09-030a-4d12-8e19-252787039875 is now ModuleInstanceStatus.ADMITTED\n2024-04-10 15:47:05,118 - rush - INFO - Argument d280af91-5816-4f32-8120-e6e2ede8b4b1 is now ModuleInstanceStatus.ADMITTED\n2024-04-10 15:47:06,082 - rush - INFO - Argument feae45e5-6d88-465f-bc71-722848c6d06e is now ModuleInstanceStatus.ADMITTED\n2024-04-10 15:47:08,387 - rush - INFO - Argument 75bb4f40-0ce6-4093-8add-475d1f38e226 is now ModuleInstanceStatus.ADMITTED\n2024-04-10 15:47:08,438 - rush - INFO - Argument ea6e2e0f-aa8f-4d20-9192-c2f099859878 is now ModuleInstanceStatus.ADMITTED\n2024-04-10 15:47:09,395 - rush - INFO - Argument feae45e5-6d88-465f-bc71-722848c6d06e is now ModuleInstanceStatus.DISPATCHED\n2024-04-10 15:47:09,471 - rush - INFO - Argument 71189844-b1a3-40c3-8e2e-a2e4d2eace28 is now ModuleInstanceStatus.DISPATCHED\n2024-04-10 15:47:10,492 - rush - INFO - Argument feae45e5-6d88-465f-bc71-722848c6d06e is now ModuleInstanceStatus.RUNNING\n2024-04-10 15:47:10,560 - rush - INFO - Argument 71189844-b1a3-40c3-8e2e-a2e4d2eace28 is now ModuleInstanceStatus.RUNNING\n2024-04-10 15:47:11,643 - rush - INFO - Argument 75bb4f40-0ce6-4093-8add-475d1f38e226 is now ModuleInstanceStatus.DISPATCHED\n2024-04-10 15:47:11,744 - rush - INFO - Argument ea6e2e0f-aa8f-4d20-9192-c2f099859878 is now ModuleInstanceStatus.DISPATCHED\n2024-04-10 15:47:12,750 - rush - INFO - Argument 75bb4f40-0ce6-4093-8add-475d1f38e226 is now ModuleInstanceStatus.RUNNING\n2024-04-10 15:47:12,847 - rush - INFO - Argument ea6e2e0f-aa8f-4d20-9192-c2f099859878 is now ModuleInstanceStatus.RUNNING\n2024-04-10 15:47:16,063 - rush - INFO - Argument feae45e5-6d88-465f-bc71-722848c6d06e is now ModuleInstanceStatus.AWAITING_UPLOAD\n2024-04-10 15:47:16,121 - rush - INFO - Argument 71189844-b1a3-40c3-8e2e-a2e4d2eace28 is now ModuleInstanceStatus.AWAITING_UPLOAD\n2024-04-10 15:47:24,979 - rush - INFO - Argument 75bb4f40-0ce6-4093-8add-475d1f38e226 is now ModuleInstanceStatus.AWAITING_UPLOAD\n2024-04-10 15:47:25,046 - rush - INFO - Argument ea6e2e0f-aa8f-4d20-9192-c2f099859878 is now ModuleInstanceStatus.AWAITING_UPLOAD\n2024-04-10 15:47:25,820 - rush - INFO - Argument d280af91-5816-4f32-8120-e6e2ede8b4b1 is now ModuleInstanceStatus.DISPATCHED\n2024-04-10 15:47:25,838 - rush - INFO - Argument 770a9c09-030a-4d12-8e19-252787039875 is now ModuleInstanceStatus.DISPATCHED\n2024-04-10 15:47:26,919 - rush - INFO - Argument 770a9c09-030a-4d12-8e19-252787039875 is now ModuleInstanceStatus.RUNNING\n2024-04-10 15:47:26,920 - rush - INFO - Argument d280af91-5816-4f32-8120-e6e2ede8b4b1 is now ModuleInstanceStatus.RUNNING\n2024-04-10 15:47:33,545 - rush - INFO - Argument d280af91-5816-4f32-8120-e6e2ede8b4b1 is now ModuleInstanceStatus.AWAITING_UPLOAD\n2024-04-10 15:47:33,555 - rush - INFO - Argument 770a9c09-030a-4d12-8e19-252787039875 is now ModuleInstanceStatus.AWAITING_UPLOAD\n\n\n[PosixPath('/home/machineer/qdx/qs_batch_run_protein_prep/objects/protein_8FSU_nohet_prepared.qdxf.json'),\n PosixPath('/home/machineer/qdx/qs_batch_run_protein_prep/objects/protein_1B39_nohet_prepared.qdxf.json'),\n PosixPath('/home/machineer/qdx/qs_batch_run_protein_prep/objects/protein_4QXI_nohet_prepared.qdxf.json'),\n PosixPath('/home/machineer/qdx/qs_batch_run_protein_prep/objects/protein_8FSU_nohet_prepared.pdb'),\n PosixPath('/home/machineer/qdx/qs_batch_run_protein_prep/objects/protein_1B39_nohet_prepared.pdb'),\n PosixPath('/home/machineer/qdx/qs_batch_run_protein_prep/objects/protein_4QXI_nohet_prepared.pdb')]\n\n\n\nOUTPUT_DIR = client.workspace / \"objects\"\n!ls $OUTPUT_DIR\n\nprotein_1B39_nohet_prepared.pdb        protein_4QXI_nohet_prepared.qdxf.json\nprotein_1B39_nohet_prepared.qdxf.json  protein_8FSU_nohet_prepared.pdb\nprotein_4QXI_nohet_prepared.pdb        protein_8FSU_nohet_prepared.qdxf.json",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Quickstarts",
      "prepare_protein — Run a batch protein preperation in parallel"
    ]
  },
  {
    "objectID": "Previous Versions/Quickstarts/gnina.html",
    "href": "Previous Versions/Quickstarts/gnina.html",
    "title": "Docking with Gnina",
    "section": "",
    "text": "First, install the following modules via the command-line (we require Python ≥ 3.9):\n\npip install rush-py pdb-tools py3Dmol rdkit",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Quickstarts",
      "Docking with Gnina"
    ]
  },
  {
    "objectID": "Previous Versions/Quickstarts/gnina.html#import-dependencies-and-create-rush-client",
    "href": "Previous Versions/Quickstarts/gnina.html#import-dependencies-and-create-rush-client",
    "title": "Docking with Gnina",
    "section": "Import dependencies and create Rush client",
    "text": "Import dependencies and create Rush client\n\nfrom rdkit import Chem\nfrom pdbtools import (\n    pdb_delhetatm,\n    pdb_fetch,\n    pdb_rplresname,\n    pdb_selchain,\n    pdb_selresname,\n)\nimport py3Dmol\nimport rush\n\n# create the rush client\nclient = rush.build_blocking_provider_with_functions(\n    access_token=PUT_YOUR_TOKEN_HERE\n)\n\n2024-05-13 15:05:07,152 - rush - INFO - Restoring by default via env",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Quickstarts",
      "Docking with Gnina"
    ]
  },
  {
    "objectID": "Previous Versions/Quickstarts/gnina.html#load-pdb-from-rcsb",
    "href": "Previous Versions/Quickstarts/gnina.html#load-pdb-from-rcsb",
    "title": "Docking with Gnina",
    "section": "Load PDB from RCSB",
    "text": "Load PDB from RCSB\n\n# download the PDB structure using its RCSB ID\nstructure = list(pdb_fetch.fetch_structure(\"1B39\"))\n\n# select the protein chain and save it to a file\nprotein = pdb_delhetatm.remove_hetatm(pdb_selchain.select_chain(structure, \"A\"))\nwith open(client.workspace / \"protein.pdb\", \"w\") as f:\n    for line in protein:\n        f.write(str(line))\n\n# select the ATP residue, rename it to UNL, and save it as an SDF\n# we will use the ATP as a reference ligand for the binding site\natp = pdb_selresname.filter_residue_by_name(structure, \"ATP\")\natp = pdb_rplresname.rename_residues(atp, \"ATP\", \"UNL\")\natp_mol = Chem.MolFromPDBBlock(\"\".join(atp))\nwriter = Chem.SDWriter(client.workspace / \"atp.sdf\")\nwriter.write(atp_mol)\nwriter.close()",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Quickstarts",
      "Docking with Gnina"
    ]
  },
  {
    "objectID": "Previous Versions/Quickstarts/gnina.html#prepare-the-protein",
    "href": "Previous Versions/Quickstarts/gnina.html#prepare-the-protein",
    "title": "Docking with Gnina",
    "section": "Prepare the protein",
    "text": "Prepare the protein\nUsing the client.prepare_protein module we can use PDBFixer and PDB2PQR to automatically prepare our protein for docking.\n\n# run protein preparation which will use a combination of\n# PDBFixer and PDB2PQR to prepare the protein\n_, prepared_protein_pdb_handle = client.prepare_protein(\n    client.workspace / \"protein.pdb\", None, None, tags=[\"gnina_quickstart\"]\n)\n\n2024-05-13 15:05:11,911 - rush - INFO - Trying to restore job with tags: ['gnina_quickstart'] and path: github:talo/prepare_protein/9af3512509062490f73302e3c8c7d4296036e678#prepare_protein_tengu\n2024-05-13 15:05:12,146 - rush - INFO - Restoring job from previous run with id 6046f17e-2760-425b-adc0-7238fb0a50d3",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Quickstarts",
      "Docking with Gnina"
    ]
  },
  {
    "objectID": "Previous Versions/Quickstarts/gnina.html#prepare-the-small-molecule",
    "href": "Previous Versions/Quickstarts/gnina.html#prepare-the-small-molecule",
    "title": "Docking with Gnina",
    "section": "Prepare the small molecule",
    "text": "Prepare the small molecule\nNow we will use an example SMILES string and prepare it for docking using Auto3D.\n\n# setup an SMI file that contains the SMILES string of our ligand\nligand_smi_filename = client.workspace / \"ligand.smi\"\nligand_smi_filename.write_text(\"CN1CC=CCCOc2cccc(c2)-c3ccnc(n3)Nc4cccc(c4)C1 1\")\n\n# run Auto3D which will give us 3 conformers of our ligand\n# in the SDF format and the QDXF format\nligand_sdf_handle, _ = client.auto3d(\n    ligand_smi_filename,  # the filename that stores our ligand\n    \"smi\",  # the format of the file\n    {\n        \"k\": 3,  # number of conformers to generate\n        \"use_gpu\": True,  # use GPU for faster compute\n    },\n    tags=[\"gnina_quickstart\"],\n    resources={\n        \"gpus\": 1,  # the number of GPUs to use\n        \"storage\": 5,  # the amount of storage to use\n        \"storage_units\": \"MB\",  # the units of storage (here we are using megabytes)\n    },\n)\n\n2024-05-13 15:05:12,453 - rush - INFO - Trying to restore job with tags: ['gnina_quickstart'] and path: github:talo/tengu-auto3d/05fbc5014bf4e7f2890e70428c62234cdb902336#auto3d_tengu\n2024-05-13 15:05:12,658 - rush - INFO - Restoring job from previous run with id 7151714d-7027-43c4-bbe0-90f60427c55b",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Quickstarts",
      "Docking with Gnina"
    ]
  },
  {
    "objectID": "Previous Versions/Quickstarts/gnina.html#run-gnina",
    "href": "Previous Versions/Quickstarts/gnina.html#run-gnina",
    "title": "Docking with Gnina",
    "section": "Run Gnina",
    "text": "Run Gnina\n\n# run Gnina to generate 10 poses\nposes_sdf_handle, scores_handle = client.gnina_pdb(\n    prepared_protein_pdb_handle,  # protein\n    ligand_sdf_handle,  # ligand\n    client.workspace\n    / \"atp.sdf\",  # reference ligand so we know where the binding site is\n    {\n        \"exhaustiveness\": 8,  # the exhaustiveness of the pose search\n        \"num_modes\": 10,  # the number of poses that will be generated\n        \"minimise\": False,  # whether or not to minimise the energy\n    },\n    tags=[\"gnina_quickstart\"],\n    # resources\n    resources={\n        \"gpus\": 1,  # the number of GPUs to use\n        \"storage\": 100,  # the amount of storage to use\n        \"storage_units\": \"MB\",  # the units of storage (here we are using megabytes)\n    },\n)\n\n2024-05-13 15:06:37,547 - rush - INFO - Trying to restore job with tags: ['gnina_quickstart'] and path: github:talo/tengu-gnina/226c2d5b94f4e4773c41a13613d588fad41c0eab#gnina_tengu_pdb\n2024-05-13 15:06:37,754 - rush - INFO - Restoring job from previous run with id 09ce76e9-7466-4808-b112-7f5477c90637",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Quickstarts",
      "Docking with Gnina"
    ]
  },
  {
    "objectID": "Previous Versions/Quickstarts/gnina.html#visualize-the-results",
    "href": "Previous Versions/Quickstarts/gnina.html#visualize-the-results",
    "title": "Docking with Gnina",
    "section": "Visualize the results",
    "text": "Visualize the results\n\n# print the status of all jobs\nprint(client.status())\n\n# download the results (this will block until the Gnina job has completed)\nprepared_protein_pdb = prepared_protein_pdb_handle.download(overwrite=True)\nposes_sdf = poses_sdf_handle.download(overwrite=True)\n\n# visualize the results in 3D\nview = py3Dmol.view()\nwith open(prepared_protein_pdb, \"r\") as f:\n    view.addModel(f.read(), \"pdb\")\n    view.setStyle({\"model\": -1}, {\"cartoon\": {\"color\": \"spectrum\"}})\nwith open(poses_sdf, \"r\") as file:\n    for pose in file.read().split(\"$$$$\\n\"):\n        if pose.strip():\n            view.addModel(pose, \"sdf\")\n            view.setStyle({\"model\": -1}, {\"stick\": {\"radius\": 0.2}})\nview.zoomTo()\nview.show()\n\n{'09ce76e9-7466-4808-b112-7f5477c90637': (&lt;ModuleInstanceStatus.COMPLETED: 'COMPLETED'&gt;, 'gnina_pdb', 1), '7151714d-7027-43c4-bbe0-90f60427c55b': (&lt;ModuleInstanceStatus.COMPLETED: 'COMPLETED'&gt;, 'auto3d', 1), '6046f17e-2760-425b-adc0-7238fb0a50d3': (&lt;ModuleInstanceStatus.COMPLETED: 'COMPLETED'&gt;, 'prepare_protein', 1)}\n\n\n\n        3Dmol.js failed to load for some reason.  Please check your browser console for error messages.",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Quickstarts",
      "Docking with Gnina"
    ]
  },
  {
    "objectID": "Previous Versions/Quickstarts/gromacs.html",
    "href": "Previous Versions/Quickstarts/gromacs.html",
    "title": "Simulations with GROMACS",
    "section": "",
    "text": "Install\nFirst, install the following modules via the command-line (we require Python ≥ 3.9):\n\npip install rush-py pdb-tools py3Dmol\n\n\n\nFull Code\n\nfrom pdbtools import (\n    pdb_delhetatm,\n    pdb_fetch,\n    pdb_selchain,\n)\nimport py3Dmol\nimport rush\nimport tarfile\n\n# create the rush client\nclient = rush.build_blocking_provider_with_functions(\n    access_token=PUT_YOUR_TOKEN_HERE\n)\n\n# download the PDB structure using its RCSB ID\nstructure = list(pdb_fetch.fetch_structure(\"1B39\"))\n\n# select the protein chain and save it to a file\nprotein = pdb_delhetatm.remove_hetatm(pdb_selchain.select_chain(structure, \"A\"))\nwith open(client.workspace / \"protein.pdb\", \"w\") as f:\n    for line in protein:\n        f.write(str(line))\n\n# run protein preparation which will use a combination of\n# PDBFixer and PDB2PQR to prepare the protein\n_, prepared_protein_pdb_handle = client.prepare_protein(\n    client.workspace / \"protein.pdb\",\n    None,\n    None,\n    tags=[\"gromacs_quickstart\"],\n)\n\n# seutp some basic parameters for the GROMACS simulation\ngmx_config = {\n    \"params_overrides\": {\n        \"nvt\": {\"nsteps\": 2000},\n        \"npt\": {\"nsteps\": 2000},\n        \"md\": {\n            \"nsteps\": 50000\n        },  # run 50000 steps of MD (at 2 femtoseconds per step)\n    },\n    \"frame_sel\": {\n        \"start_time_ps\": 90,  # start capturing frames at the 90th picosecond\n        \"end_time_ps\": 100,  # stop capturing frames at the 100th picosecond\n        \"delta_time_ps\": 1,  # capture one frame per picosecond\n    },\n    \"num_gpus\": 1,\n    \"save_wets\": False,  # do not save the explicit water molecules\n}\n\n# run the GROMACS simulation\n(\n    resume_files_first,\n    streaming_outputs,\n    static_outputs,\n    xtcs_dry,\n    pdbs_dry,\n    *rest,\n) = client.gmx(\n    None,\n    prepared_protein_pdb_handle,  # protein to simulate (as a PDB)\n    None,  # small molecule to simulate (as an SDF)\n    gmx_config,\n    tags=[\"gromacs_quickstart\"],\n    resources={\"gpus\": 1, \"storage\": 1, \"storage_units\": \"GB\"},\n)\n\n# download the frames in the PDB format, which will\n# return all frame information in a tarball\npdbs_dry_filename = pdbs_dry.download()\n\n# visualize the results in 3D\nview = py3Dmol.view()\n\n# untar the frames and add each one to the visualization\nwith tarfile.open(pdbs_dry_filename, \"r\") as t:\n    pdbs = [\n        t.extractfile(entry).read()\n        for entry in t\n        if \"pdb\" in entry.name and entry.isfile()\n    ]\n    for i, frame in enumerate(pdbs):\n        view.addModel(frame.decode(\"utf-8\"))\n\nview.setStyle({\"cartoon\": {\"color\": \"spectrum\"}})\nview.zoomTo()\nview.show()\n\n2024-05-13 15:02:33,811 - rush - INFO - Restoring by default via env\n2024-05-13 15:02:48,762 - rush - INFO - Trying to restore job with tags: ['gromacs_quickstart'] and path: github:talo/prepare_protein/9af3512509062490f73302e3c8c7d4296036e678#prepare_protein_tengu\n2024-05-13 15:02:49,193 - rush - INFO - Trying to restore job with tags: ['gromacs_quickstart'] and path: github:talo/tengu-gmx/e94bc9ca4b7ba774d59aeb5f0e07917af22b6a80#gmx_tengu\n2024-05-13 15:02:49,751 - rush - INFO - Argument 1883e5c7-066e-4b75-90d4-c6deb2fb1b92 is now ModuleInstanceStatus.RESOLVING\n2024-05-13 15:04:29,460 - rush - INFO - Argument 1883e5c7-066e-4b75-90d4-c6deb2fb1b92 is now ModuleInstanceStatus.ADMITTED\n2024-05-13 15:04:43,073 - rush - INFO - Argument 1883e5c7-066e-4b75-90d4-c6deb2fb1b92 is now ModuleInstanceStatus.DISPATCHED\n2024-05-13 15:04:53,713 - rush - INFO - Argument 1883e5c7-066e-4b75-90d4-c6deb2fb1b92 is now ModuleInstanceStatus.RUNNING\n2024-05-13 15:05:50,448 - rush - INFO - Argument 1883e5c7-066e-4b75-90d4-c6deb2fb1b92 is now ModuleInstanceStatus.AWAITING_UPLOAD\n\n\n\n        3Dmol.js failed to load for some reason.  Please check your browser console for error messages.",
    "crumbs": [
      "API Docs",
      "Previous Versions",
      "Quickstarts",
      "Simulations with GROMACS"
    ]
  },
  {
    "objectID": "Hackathon/run_spec.html",
    "href": "Hackathon/run_spec.html",
    "title": "Run Specifications",
    "section": "",
    "text": "Run specifications tell Rush how to execute the computational drug discovery modules. Most modules (e.g. functions ending in _rex or _s) are dispatched to various high-performancing computing clusters that Rush has access to. When executing these modules, Rush needs to know about the target (which cluster) and the resources (storage, number of CPUs, number of GPUs, etc) needed for the module to execute successfully. This is called the “run spec” and it is always the first argument passed when calling a module.\nHere is an example of a RunSpec that tells Rush that the respective module needs to be executed on the Bullet high-performance computing cluster, that the module needs 10 megabytes of space, and that the module needs access to 1 GPU.\nRunSpec {\n    target = 'Bullet',\n    resources = Resources {\n        storage = some 10,\n        storage_units = some \"MB\",\n        gpus = some 1\n    }\n}\nMeanwhile, here is an example RunSpec that is identical to the previous one, but it only requests CPUs.\nRunSpec {\n    target = 'Bullet',\n    resources = Resources {\n        storage = some 10,\n        storage_units = some \"MB\",\n        gpus = none\n    }\n}",
    "crumbs": [
      "API Docs",
      "Hackathon",
      "Run Specifications"
    ]
  },
  {
    "objectID": "Hackathon/language_ref.html",
    "href": "Hackathon/language_ref.html",
    "title": "Language Reference",
    "section": "",
    "text": "The Option type in Rex is like the Optional i.e. T | None type in Python, ? type from TypeScript, the Option type from Rust, or the Maybe type from Haskell. It represents a value that may or may not be present.\nExample\n{- create a value that is present -}\nsome 42\n\n{- create a value that is not present -}\nnone\n\n\n\nThe Result type in Rex is like the Result type from Rust. It allows a value to be one of two variants, the successful result of a calculation, or an error results from a calculation that failed in some way.\nExample\n{- a result representing a successful calculation -}\nok 42\n\n{- a result representing an error occurred, and in this case a message is returned -}\nerr \"something went wrong!\"\n\n{- an example of a safe division -}\nlet \n    safe_div = \\x y -&gt; if y == 0 then err \"divide by zero\" else ok (x / y) \nin\n    {- this should result in: ok 10 -}\n    safe_div 420 42",
    "crumbs": [
      "API Docs",
      "Hackathon",
      "Language Reference"
    ]
  },
  {
    "objectID": "Hackathon/language_ref.html#types",
    "href": "Hackathon/language_ref.html#types",
    "title": "Language Reference",
    "section": "",
    "text": "The Option type in Rex is like the Optional i.e. T | None type in Python, ? type from TypeScript, the Option type from Rust, or the Maybe type from Haskell. It represents a value that may or may not be present.\nExample\n{- create a value that is present -}\nsome 42\n\n{- create a value that is not present -}\nnone\n\n\n\nThe Result type in Rex is like the Result type from Rust. It allows a value to be one of two variants, the successful result of a calculation, or an error results from a calculation that failed in some way.\nExample\n{- a result representing a successful calculation -}\nok 42\n\n{- a result representing an error occurred, and in this case a message is returned -}\nerr \"something went wrong!\"\n\n{- an example of a safe division -}\nlet \n    safe_div = \\x y -&gt; if y == 0 then err \"divide by zero\" else ok (x / y) \nin\n    {- this should result in: ok 10 -}\n    safe_div 420 42",
    "crumbs": [
      "API Docs",
      "Hackathon",
      "Language Reference"
    ]
  },
  {
    "objectID": "Hackathon/language_ref.html#functions",
    "href": "Hackathon/language_ref.html#functions",
    "title": "Language Reference",
    "section": "Functions",
    "text": "Functions\n\nMap\nArguments\n\nf - A function from any type a to any type b.\nxs - A list of values of type a.\n\nReturns\n\nA list of values of type b.\n\nExample\n{- double integers in a list -}\nmap ((*) 2) [1, 2, 3, 4, 5]\n\n{- add an explamation mark to a list of words -}\nmap (\\x -&gt; x ++ \"!\") [\"hello\", \"world\"]\n\n\nFilter\nArguments\n\npredicate - A function from any type a to a bool.\nxs - A list of values of type a.\n\nReturns\n\nA list of values of type a for which the predicate returned true.\n\nExample\n{- keep all numbers less than or equal to 10 -}\nfilter ((&lt;=) 10) [8, 9, 10, 11, 12]\n\n{- keep all numbers greater than 10 -}\nfilter (\\x -&gt; x &gt; 10) [8, 9, 10, 11, 12]\n\n\nTake\nArguments\n\nn - A positive int value.\nxs - A list of values.\n\nReturns\n\nThe first n values in xs. If xs has fewer than n values, all values are returned.\n\nExample\n{- take the first 3 numbers from a list -}\ntake 5 [1, 2, 3, 5, 6, 7, 8]\n\n{- take the first 4 words from a list -}\ntake 4 [\"these\", \"will\", \"be\", \"kept\", \"these\", \"will\", \"not\"]\n\n\nZip\nArguments\n\nxy - A list of values of any type a.\nys - A list of values of any type b.\n\nReturns\n\nA list of tuples of type (a, b) that has paired up the values from xs and ys. If the lists are not the same length, the returned list will be truncated to the size of the smaller list.\n\nExample\n{- pair up even numbers with odd numbers -}\n{- this will result in: [(2, 1), (4, 3), (6, 5)] -}\nzip [2, 4, 6] [1, 3, 5, 7, 9]\n\n\nGet\nThere are multiple versions of the get function that work on different types. But - in general - they all follow the same pattern: the first argument is what you want to extract from a value, and the second argument is the value from which you will extract.\nArguments\n\nkey - If the second argument is a list, this argument must be an unsigned integer. If the second argument is a tuple, this argument must be an unsigned integer. If the second argument is a dictionary, this argument must be a string. If the second argument is an Option, this argument must be \"some\". If the second argument is a Result, this argument must be \"ok\" or \"err\". If you provide an invalid key, your program will crash during execution.\ncollection - A list, a tuple, a dictionary, an option, or a result.\n\nExample\n{- get the third value from a list (indexing starts at zero) -}\nget 2 [\"hello\", \"world\", \"!\"]\n\n{- get the second value from a tuple (indexing starts at zero) -}\nget 1 (\"hello\", 420, true, 3.14)\n\n{- get the hello key from a dictionary -}\nget \"hello\" ({ \"hello\": 420, \"world\": true, \"!\": 3.14 })\n\n{- unwrap an optional, crashing if it is not present -}\nget \"some\" (some \"hello\")\n\n{- unwrap a result, crashing if it is an error -}\nget \"ok\" (ok 420)\n\n\nLen\nArguments\n\ncollection - A list, tuple, or string.\n\nReturns\n\nThe length of the list, tuple, or string.\n\nExample\n{- returns 0 -}\nlen []\n\n{- returns 2 -}\nlen [\"hello\", \"world\"]\n\n{- returns 3 -}\nlen (\"hello\", 420, true)\n\n{- return 5 -}\nlen \"hello\"\n\n\nHas\nArguments\n\nkey - A string that we are searching for in the dictionary.\ncollection - A dictionary or result.\n\nReturns\n\nIf the key is present in the dict, then true, otherwise false. Because result is currently implemented via dict, we can check for ok and err on a result the same way we check for a key in a dict. Note: it only searches for keys in the dict, not values.\n\nExample\n{- returns true -}\nhas \"hello\" ({ \"hello\": \"world\" })\n\n{- returns false -}\nhas \"world\" ({ \"hello\": \"world\" })\n\n{- returns true -}\nhas \"ok\" (ok \"hello world\")\n\n{- returns false -}\nhas \"err\" (ok \"hello world\")\n\n{- returns true -}\nhas \"err\" (err \"goodbye cruel world\")",
    "crumbs": [
      "API Docs",
      "Hackathon",
      "Language Reference"
    ]
  },
  {
    "objectID": "Hackathon/types_builtins_and_utilities.html",
    "href": "Hackathon/types_builtins_and_utilities.html",
    "title": "Types, Built-in Functions, and Utilities",
    "section": "",
    "text": "There are 3 numeric types: int, uint, and float, representing integers, unsigned integers, and floating-point numbers. These are all collectively referred to as numbers.\nCasting allows us to convert a variable from one numeric type to another. Here are the following supported types for conversion to, using the name of the type as the function:\n\n\nConverts other numbers to ints, using truncation (i.e. nearest int in the direction of 0).\nExample\n{- returns 1 -}\nint 1.0\n{- returns 1 -}\nint 1.5\n{- returns -1 -}\nint (0.0 - 1.5)\n{- don't use negative floats directly in expressions, they are currently broken -}\nint -1.5\n\n\n\nExample\n{- returns 1 -}\nuint 1.0\n{- error -}\nuint -1\n\n\n\nExample\n{- returns 1.0 -}\nfloat 1",
    "crumbs": [
      "API Docs",
      "Hackathon",
      "Types, Built-in Functions, and Utilities"
    ]
  },
  {
    "objectID": "Hackathon/types_builtins_and_utilities.html#numeric-types-and-casting",
    "href": "Hackathon/types_builtins_and_utilities.html#numeric-types-and-casting",
    "title": "Types, Built-in Functions, and Utilities",
    "section": "",
    "text": "There are 3 numeric types: int, uint, and float, representing integers, unsigned integers, and floating-point numbers. These are all collectively referred to as numbers.\nCasting allows us to convert a variable from one numeric type to another. Here are the following supported types for conversion to, using the name of the type as the function:\n\n\nConverts other numbers to ints, using truncation (i.e. nearest int in the direction of 0).\nExample\n{- returns 1 -}\nint 1.0\n{- returns 1 -}\nint 1.5\n{- returns -1 -}\nint (0.0 - 1.5)\n{- don't use negative floats directly in expressions, they are currently broken -}\nint -1.5\n\n\n\nExample\n{- returns 1 -}\nuint 1.0\n{- error -}\nuint -1\n\n\n\nExample\n{- returns 1.0 -}\nfloat 1",
    "crumbs": [
      "API Docs",
      "Hackathon",
      "Types, Built-in Functions, and Utilities"
    ]
  },
  {
    "objectID": "Hackathon/types_builtins_and_utilities.html#lists-and-list-utilities",
    "href": "Hackathon/types_builtins_and_utilities.html#lists-and-list-utilities",
    "title": "Types, Built-in Functions, and Utilities",
    "section": "Lists and list utilities",
    "text": "Lists and list utilities\nLists are flexible containers that can be used for data manipulation.\n\nlist\nArguments\n\nd - A dict.\n\nReturns\n\nA list of list where each inner list represent each key-value pair in d.\n\nExample\n{- returns [[\"hello\", 5], [\"world\", 5], [\"its\", 3], [\"me\", 2]] -}\nlist {hello = 5, world = 5, its = 3, me = 2}\n\n\nunzip\nArguments\n\nxs - A list of tuple where each tuple has 2 elements.\n\nReturns\n\nA list of exactly 2 tuples where the first tuple contains the first element of each tuple in xs and the second tuple contains the second element of each tuple in xs.\n\nExample\n{- returns [(\"hello\", \"world\", \"its\", \"me\"), (5, 5, 3, 2)] -}\nunzip [(\"hello\", 5), (\"world\", 5), (\"its\", 3), (\"me\", 2)]\n\n\navg\nArguments\n\nxs - A list of numbers.\n\nReturns\n\nA float representing the average of the values in the list.\n\nExample\n{- returns 10 -}\navg [8, 9, 10, 11, 12]\n\n\nlist_min\nArguments\n\nxs - A list of numbers.\n\nReturns\n\nThe minimum value in the list as a float.\n\nExample\n{- returns 8.0 -}\nlist_min [8, 9, 10, 11, 12]\n\n\nlist_min_by\nArguments\n\nf - A function from any type a to a numeric type.\nxs - A list of values of type a.\n\nReturns\n\nPerform f on each number in xs and returns the initial value that produced the minimum output as a float.\n\nExample\n{- returns 12.0 -}\nlist_min_by (\\x -&gt; 1.0/x) [8.0, 9.0, 10.0, 11.0, 12.0]\n\n\nlist_max\nArguments\n\nxs - A list of numbers.\n\nReturns\n\nThe maximum value in the list as a float.\n\nExample\n{- returns 12.0 -}\nlist_min [8, 9, 10, 11, 12]\n\n\nlist_max_by\nArguments\n\nf - A function from any type a to a numeric type.\nxs - A list of values of type a.\n\nReturns\n\nPerform f on each number in xs and returns the initial value that produced the minimum output as a float.\n\nExample\n{- returns 8.0 -}\nlist_max_by (\\x -&gt; 1.0/x) [8.0, 9.0, 10.0, 11.0, 12.0]",
    "crumbs": [
      "API Docs",
      "Hackathon",
      "Types, Built-in Functions, and Utilities"
    ]
  },
  {
    "objectID": "Hackathon/types_builtins_and_utilities.html#data-management-utilities",
    "href": "Hackathon/types_builtins_and_utilities.html#data-management-utilities",
    "title": "Types, Built-in Functions, and Utilities",
    "section": "Data management utilities",
    "text": "Data management utilities\n\nload\nArguments\n\nid - A string UUID corresponding to the ID of the data to load.\ndata_type - A string representing the data type to load.\n\nReturns\n\nThe requested data.\n\nExample\nload \"ee4b901e-d2d7-469f-bb3e-3511ba508829\" \"Protein\"\n\n\nsave\nArguments\n\nA data variable.\n\nReturns\n\nA string UUID corresponding to the ID of the saved entity.\n\nExample\n{- saves BindingAffinity data and returns a string ID (example: \"ee4b901e-d2d7-469f-bb3e-3511ba508829\") for use to access it later via load -}\nsave (Protein {\n    sequence = \"MNMSKQPVSNVRAIQANINIPMGAFRPGAGQPPRRKECTPEVEEGVPPTSDEEKKPIPGAKKLPGPAVNLSEIQNIKSELKYVPKAEQ\",\n    uniprot_id = some \"Q9UHP9\",\n    metadata = Metadata {\n        name = \"Small muscular protein\",\n        description = none,\n        tags = []\n    }\n})",
    "crumbs": [
      "API Docs",
      "Hackathon",
      "Types, Built-in Functions, and Utilities"
    ]
  },
  {
    "objectID": "Modules/dojo.html",
    "href": "Modules/dojo.html",
    "title": "Dojo",
    "section": "",
    "text": "The module takes an dict of module-specific options, a [TRObject] representing the molecules to include in the simulation, and an [Object&lt;XML&gt;] that corresponds to additional force field parameters used for simulating smols accurately. These XML files can be generated using the ffgen module.\n\n\n\noptions: dict\ntrcs: [TRObject]\nforce_fields: [Object&lt;XML&gt;] - one for each smol appearing in the input TRCObjects\n\n\n\n\n\nfinal_frame_trc: [TRObject] - representing the state of each input on the simulation’s final frame\nframes: Object&lt;[dict]&gt; - stores the requested data for the output frames of the simulation as per the configuration",
    "crumbs": [
      "API Docs",
      "Modules",
      "Dojo"
    ]
  },
  {
    "objectID": "Modules/dojo.html#module-specification",
    "href": "Modules/dojo.html#module-specification",
    "title": "Dojo",
    "section": "",
    "text": "The module takes an dict of module-specific options, a [TRObject] representing the molecules to include in the simulation, and an [Object&lt;XML&gt;] that corresponds to additional force field parameters used for simulating smols accurately. These XML files can be generated using the ffgen module.\n\n\n\noptions: dict\ntrcs: [TRObject]\nforce_fields: [Object&lt;XML&gt;] - one for each smol appearing in the input TRCObjects\n\n\n\n\n\nfinal_frame_trc: [TRObject] - representing the state of each input on the simulation’s final frame\nframes: Object&lt;[dict]&gt; - stores the requested data for the output frames of the simulation as per the configuration",
    "crumbs": [
      "API Docs",
      "Modules",
      "Dojo"
    ]
  },
  {
    "objectID": "Modules/dojo.html#options",
    "href": "Modules/dojo.html#options",
    "title": "Dojo",
    "section": "Options",
    "text": "Options\nDojo has a lot of options!\nThe following documents the structure of the config dict along with what each field represents and possible default values.\nThis markdown file is broken down into sections, one for each non-trivial type defined. Within a section for a given type, there will be a schematic description of the structure of the type, followed by a description of each of the fields. In the description of the fields, there will be given its name, type, default value (if any) and a short description. The type can either be a basic type (int, float, bool, list&lt;T&gt;) or a non-trivial type, in which case the name of the type will be written in CamelCase and will have a corresponding section in this file. If a default for a field is given, no value need be provided for this field, and if none is provided it will assume the value of the default.\nAny parameters marked with an asterisk (*) are either unused, unimplemented, broken, or not relevant when called as a module.\n\nParameters\nThe top level structure that is passed to Dojo.\nParameters\n ├ num_gpus\n ├ single_frame_serialise\n ├ nonbonded_method\n ├ nonbonded_cutoff_nm\n ├ constraints\n ├ remove_cm_motion\n ├ generate_ff_indices\n ├ force_fields\n ├ qm_region\n │ ├ engine\n │ └ regions\n ├ qm_cutoff_distance_ang\n ├ simulation\n │ ├ step_size_ps\n │ ├ periodic_box_vectors_nm\n │ │ ├ v1\n │ │ ├ v2\n │ │ └ v3\n │ └ stages\n ├ implicit_solvent\n ├ solvation\n ├ metadynamics\n ├ bias_potentials\n ├ bias_schedule\n │ ├ active_potentials\n │ └ triggers\n ├ termination_condition\n │ ├ tail_steps\n │ └ bonds\n ├ frames\n │ ├ start\n │ ├ stop\n │ └ interval\n ├ trajectory\n │ ├ interval\n │ ├ minimisation\n │ ├ forces\n │ ├ info\n │ ├ windowed\n │ ├ window_size\n │ └ residues\n ├ save_final_trcs\n ├ save_final_velocities\n └ qdxf_export\n\n\n\n\n\n\n\n\n\nName\nType\nDefault\nDescription\n\n\n\n\nnum_gpus*\nint\n1\nNumber of GPUs to use for the calculation. When called as a module, this is ignored; please use the Resources struct instead.\n\n\nsingle_frame_serialise*\nbool\nfalse\nSave the positions and forces of the initial system in a special format. Not currently wired up to the module.\n\n\nnonbonded_method\nstring\n“NoCutoff”\nWhich cutoff method to use for nonbonded forces. Options are “NoCutoff”, “CutoffNonPeriodic”, “CutoffPeriodic”, “Ewald”, “PME”, “LJPME”.\n\n\nnonbonded_cutoff_nm\nfloat\n1.0\nCutoff for the nonbonded forces, in nm.\n\n\nconstraints\nstring\n“None”\nWhich constraints to use. Options are “None”, “HBonds”, “AllBonds”, “HAngles”.\n\n\nremove_cm_motion\nbool\ntrue\nWhether or not to remove the centre of mass motion.\n\n\ngenerate_ff_indices*\nlist&lt;int&gt;\n[]\nWhich input files to generate FF parameters for. Currently not supported.\n\n\nforce_fields\nlist&lt;string&gt;\n[ “Ff14sb”, “Tip3pStandard” ]\nWhich force fields to use for the simulation. Options are “Ff14sb”, “Tip3pStandard” and “Custom”.\n\n\nqm_region\nQMRegion\n{ “engine”: “None”, “regions”: [] }\nDefinition of the QM region.\n\n\nqm_cutoff_distance_ang\nfloat\n0.0\nAll residues within this distance of the QM region will also be added to the QM region. Units of angstroms.\n\n\nsimulation\nSimulation\n\nDefinition of the simulation.\n\n\nimplicit_solvent*\nbool\nfalse\nWhether or not to use an implicit solvent. Currently not working.\n\n\nsolvation\nSolvationParameters\nnull\nDefinition of the solvation for the system.\n\n\nmetadynamics\nlist&lt;Metadynamics&gt;\n[]\nDefinition of any metadynamics used for the simulation.\n\n\nbias_potentials\nlist&lt;BiasPotential&gt;\n[]\nList of bias potentials to use in the simulation.\n\n\nbias_schedule\nBiasSchedule\nnull\nDefinition of the schedule for the bias potentials.\n\n\ntermination_condition\nTerminationCondition\nnull\nDefinition of the termination condition for the simulation.\n\n\nframes*\nFrames\nnull\nDefinition of output frames. Currently unused.\n\n\ntrajectory\nTrajectory\nnull\nDefinition of the output trajectory. This trajectory is the main result obtained from running the module.\n\n\nsave_final_trcs*\nbool\nfalse\nWhether or not to save the structures that are the final geometry of the simulation. Currently not output by the module, even if set.\n\n\nsave_final_velocities*\nbool\nfalse\nWhether or not to save the velocities in the outputs generated if save_final_trcs is enabled.\n\n\nqdxf_export*\nQDXFExport\nnull\nWhether or not to save outputs that can be used as inputs to PBSA calculations. Currently not output by the module, even if set.\n\n\n\n\n\nQMRegion\nA description of how the QM region is evaluated and which parts of the system are included in the QM region for QM/MM simulations.\nQMRegion\n ├ engine\n └ regions\n\n\n\n\n\n\n\n\n\nName\nType\nDefault\nDescription\n\n\n\n\nengine\nstring\n\nWhich engine to use for the QM calculations. Options are “None”, “QChem”, “Xtb”, “Exess”. Currently only “Xtb” is supported.\n\n\nregions\nlist&lt;QMRegionEntry&gt;\n\nWhich parts of the system are included in the QM region.\n\n\n\n\n\nQMRegionEntry\nA description of which parts of the system constitute the QM region.\nQMRegionEntry\n ├ file_index\n └ residues\n\n\n\n\n\n\n\n\n\nName\nType\nDefault\nDescription\n\n\n\n\nfile_index\nint\n\nIndex of the file supplied to Dojo, starting from 0.\n\n\nresidues\nlist&lt;int&gt;\n\nList of residue indices for the QM residues. Indices start from 0.\n\n\n\n\n\nSimulation\nThe parameters for the simulation. At the top level ther are parameters that apply to the whole simulation, and then the sequence of simulation stages that are to occur\nSimulation\n ├ step_size_ps\n ├ periodic_box_vectors_nm\n │ ├ v1\n │ ├ v2\n │ └ v3\n └ stages\n\n\n\n\n\n\n\n\n\nName\nType\nDefault\nDescription\n\n\n\n\nstep_size_ps\nfloat\n\nThe step size to use for dynamics, in ps.\n\n\nperiodic_box_vectors_nm\nBoxVectors\nnull\nVectors to use for periodic boundary conditions.\n\n\nstages\nlist&lt;SimulationStage&gt;\n\nSequence of simulation stages.\n\n\n\n\n\nBoxVectors\nCollection of three vectors defining a box.\nBoxVectors\n ├ v1\n ├ v2\n └ v3\n\n\n\n\n\n\n\n\n\nName\nType\nDefault\nDescription\n\n\n\n\nv1\nlist&lt;float&gt;\n\nFirst vector. Expected to have exactly 3 coordinates in the list.\n\n\nv2\nlist&lt;float&gt;\n\nSecond vector. Expected to have exactly 3 coordinates in the list.\n\n\nv3\nlist&lt;float&gt;\n\nThird vector. Expected to have exactly 3 coordinates in the list.\n\n\n\n\n\nSimulation Stage\nDescription of an individual stage of the simulation.\nThis type represents a discrimated union, and so only one of the fields may be present.\nSimulationStage\n ├ Minimisation\n ├ Nvt\n └ Npt\n\n\n\n\n\n\n\n\n\nName\nType\nDefault\nDescription\n\n\n\n\nMinimisation\nMinimisationParameters\n\nParameters for a minimisation stage.\n\n\nNvt\nNvtParameters\n\nParameters for an NVT ensemble stage.\n\n\nNpt\nNptParameters\n\nParameters for an NPT ensemble stage.\n\n\n\n\n\nMinimisationParameters\nSystem minimisation stage.\nMinimisationParameters\n ├ qm_minimisation_technique\n ├ max_iterations\n ├ err_tol_kj_per_mol_per_nm\n └ use_bias\n\n\n\n\n\n\n\n\n\nName\nType\nDefault\nDescription\n\n\n\n\nqm_minimisation_technique\nstring\n“None”\nMinimisation technique to use when there is a QM region present. Options are “None”, “Dynamics” and “Bfgs”. “Bfgs” is the BFGS gradient descent algorithm. “Dynamics” is an approximate technique that propagates dynamics, scaling the velocities down at each step. If “None” is selected and the system has a QM region, there will be an error\n\n\nmax_iterations\nint\n0\nMaximum number of iterations to run for minimisation. A value of 0 means that it will iterate until the err tolerance is met. If there is a QM region behaviour is uncertain.\n\n\nerr_tol_kj_per_mol_per_nm\nfloat\n10.0\nError tolerance for the RMSD of forces in the system that will trigger the end of minimisation. Units are kJ/mol/nm. May not actually be wired up to the module properly.\n\n\nuse_bias\nbool\nfalse\nWhether or not to include bias potentials during the minimisation.\n\n\n\n\n\nNvtParameters\nNVT ensemble stage.\nNvtParameters\n ├ temperature_kelvin\n ├ steps\n ├ starting_temperature_kelvin\n └ temperature_step\n\n\n\n\n\n\n\n\n\nName\nType\nDefault\nDescription\n\n\n\n\ntemperature_kelvin\nfloat\n\nTemperature at which to run the dynamics, in Kelvin.\n\n\nsteps\nint\n\nNumber of steps to run the stage for.\n\n\nstarting_temperature_kelvin\nfloat\ntemperature_kelvin\nStarting temperature for a gradual temperature increase. If set equal to temperature_kelvin, temperature will stay constant during this stage.\n\n\ntemperature_step\nfloat\n0.1 * (temperature_kelvin - starting_temperature_kelvin)\nHow much to change the thermostat at each step of the gradual increase.\n\n\n\n\n\nNptParameters\nNPT ensemble stage.\nNptParameters\n ├ temperature_kelvin\n ├ pressure_atm\n └ steps\n\n\n\n\n\n\n\n\n\nName\nType\nDefault\nDescription\n\n\n\n\ntemperature_kelvin\nfloat\n\nTemperature at which to run the dynamics, in Kelvin.\n\n\npressure_atm\nfloat\n\nPressure at which to run the dynamics, in atmospheres.\n\n\nsteps\nint\n\nNumber of steps to run the stage for.\n\n\n\n\n\nSolvationParameters\nDescription for solvent added to the system.\nThis type represents a discrimated union, and so only one of the fields may be present.\nBoxSizeNm\n ├ BoxSizeNm\n ├ BoxVectorsNm\n ├ PaddingNm\n └ NumAdded\n\n\n\n\n\n\n\n\n\nName\nType\nDefault\nDescription\n\n\n\n\nBoxSizeNm\nlist&lt;float&gt;\n\nDimensions of the final solvent box, in nm. Not current supported.\n\n\nBoxVectorsNm\nBoxVectors\n\nList of vectors describing the solvent box, in nm. Not current supported.\n\n\nPaddingNm\nfloat\n\nSolvent padding to add around the system, in nm.\n\n\nNumAdded\nint\n\nNumber of solvent atoms to add. Not current supported.\n\n\n\n\n\nMetadynamics\nDescription of metadynamics that will be used during the simulation.\nMetadynamics\n ├ bias_period\n ├ exp_sigma\n ├ height\n ├ csv_output\n └ cvs\n\n\n\n\n\n\n\n\n\nName\nType\nDefault\nDescription\n\n\n\n\nbias_period\nint\n\nNumber of steps between adding exponentials to the bias potential.\n\n\nexp_sigma\nfloat\n\nSigma for the exponential functions that are added to the bias, where the exponential functions have the form form h * exp(-0.5 * x^2 / sigma).\n\n\nheight\nMTDHeight\n\nHeight of the exponential functions added to the bias potential.\n\n\ncsv_output\nstring\nnull\nFilename for the CSV formatted representation of the final bias potential at the end of the simulation. Not currently wired up to the module.\n\n\ncvs\nlist&lt;MTDCVParameters&gt;\n\nList of collective variables used to define the metadynamics.\n\n\n\n\n\nMTDHeight\nDefinition of the height of the exponential functions that are added to the bias potential during metadynamics.\nThis type represents a discrimated union, and so only one of the fields may be present.\nMTDHeight\n ├ Constant\n └ WellTempered\n\n\n\n\n\n\n\n\n\nName\nType\nDefault\nDescription\n\n\n\n\nConstant\nConstant\n\nParameters for a constant height exponential.\n\n\nWellTempered\nWellTempered\n\nParameters for an adaptive height exponential.\n\n\n\n\n\nConstant\nExponential height that is a fixed constant.\nConstant\n └ height\n\n\n\nName\nType\nDefault\nDescription\n\n\n\n\nheight\nfloat\n\nHeight of each exponential to be added.\n\n\n\n\n\nWellTempered\nAdaptive exponential height based on the well tempered metadynamics protocol.\nMTDHeight\n ├ delta_t\n └ initial_deposition_rate\n\n\n\n\n\n\n\n\n\nName\nType\nDefault\nDescription\n\n\n\n\ndelta_t\nfloat\n\nDelta T parameter from the paper.\n\n\ninitial_deposition_rate\nfloat\n\nInitial deposition rate parameter from the paper.\n\n\n\n\n\nMTDCVParameters\nParameters for a given collective variable.\nMTDCVParameters\n ├ num_samples\n ├ min\n ├ max\n └ variable\n\n\n\n\n\n\n\n\n\nName\nType\nDefault\nDescription\n\n\n\n\nnum_samples\nint\n\nNumber of sample points in the discretised representation of the bias potential.\n\n\nmin\nfloat\n\nMinimum of the range of the CV.\n\n\nmax\nfloat\n\nMaximum of the range of the CV.\n\n\nvariable\nCV\n\nDescription of the CV.\n\n\n\n\n\nCV\nDefinition of a collective variable (CV).\nThis type represents a discrimated union, and so only one of the fields may be present.\nCV\n ├ Bond\n ├ Dihedral\n ├ Centroid\n └ RMSD\n\n\n\nName\nType\nDefault\nDescription\n\n\n\n\nBond\nBond\n\nBond length CV.\n\n\nDihedral\nDihedral\n\nDihedral angle CV.\n\n\nCentroid\nCentroid\n\nCentroid distance CV.\n\n\nRMSD\nRMSD\n\nRMSD CV.\n\n\n\n\n\nBond\nBond between two atoms.\nBond\n ├ index1\n └ index2\n\n\n\n\n\n\n\n\n\nName\nType\nDefault\nDescription\n\n\n\n\nindex1\nint\n\nAtom index of the first atom defining the bond.\n\n\nindex2\nint\n\nAtom index of the second atom defining the bond.\n\n\n\n\n\nDihedral\nDihedral angle CV.\nDihedral\n ├ index1\n ├ index2\n ├ index3\n └ index4\n\n\n\n\n\n\n\n\n\nName\nType\nDefault\nDescription\n\n\n\n\nindex1\nint\n\nAtom index of the first atom defining the dihedral.\n\n\nindex2\nint\n\nAtom index of the second atom defining the dihedral.\n\n\nindex3\nint\n\nAtom index of the third atom defining the dihedral.\n\n\nindex4\nint\n\nAtom index of the fourth atom defining the dihedral.\n\n\n\n\n\nCentroid\nCentroid distance CV.\nThis type represents a discrimated union, and so only one of the fields may be present.\nCentroid\n ├ Indices\n ├ Residues\n └ Files\n\n\n\n\n\n\n\n\n\nName\nType\nDefault\nDescription\n\n\n\n\nIndices\nIndices\n\nCentroid distance based on atom indices.\n\n\nResidues\nResidues\n\nCentroid distance based on residues.\n\n\nFiles\nFiles\n\nCentroid distance based on files.\n\n\n\n\n\nIndices\nAtom index based definition of a centroid distance.\nIndices\n ├ group1\n └ group2\n\n\n\n\n\n\n\n\n\nName\nType\nDefault\nDescriptions\n\n\n\n\ngroup1\nlist&lt;int&gt;\n\nAtom indices defining the first centroid.\n\n\ngroup2\nlist&lt;int&gt;\n\nAtom indices defining the second centroid.\n\n\n\n\n\nResidues\nResidue based definition of a centroid distance.\nResidues\n ├ file_index1\n ├ residues1\n ├ file_index2\n └ residues2\n\n\n\n\n\n\n\n\n\nName\nType\nDefault\nDescription\n\n\n\n\nfile_index1\nint\n\nIndex of the file containing the residues for the first centroid.\n\n\nresidues1\nlist&lt;int&gt;\n\nList of residues defining the first centroid.\n\n\nfile_index2\nint\n\nIndex of the file containing the residues for the second centroid.\n\n\nresidues2\nlist&lt;int&gt;\n\nList of residues defining the second centroid.\n\n\n\n\n\nFiles\nFile based definition of a centroid distance.\nResidues\n ├ file1\n └ file2\n\n\n\n\n\n\n\n\n\nName\nType\nDefault\nDescription\n\n\n\n\nfile1\nint\n\nIndex of the file that contains the atoms that define the first centroid.\n\n\nfile2\nint\n\nIndex of the file that contains the atoms that define the second centroid.\n\n\n\n\n\nRMSD\nRMSD CV.\nRMSD\n ├ reference_positions\n └ atom_indices\n\n\n\n\n\n\n\n\n\nName\nType\nDefault\nDescription\n\n\n\n\nreference_positions\nlist&lt;float&gt;\n\nThe reference positions from which to measure the RMSD, as a flat list of coordinates x1, y1, z1, x2, y2, z2, …\n\n\natom_indices\nlist&lt;int&gt;\n\nThe atom indices used to measure the RMSD. The length of the reference positions list should be exactly 3 times the length of this list.\n\n\n\n\n\nBiasPotential\nDescription of an external bias potential used in the simulation dynamics.\nThis type represents a discrimated union, and so only one of the fields may be present.\nBiasPotential\n ├ BondLinear\n ├ RmsdExp\n ├ MovingBondHarmonic\n └ HarmonicCv\n\n\n\n\n\n\n\n\n\nName\nType\nDefault\nDescription\n\n\n\n\nBondLinear\nBondLinearParameters\n\nLinear bond length based force parameters.\n\n\nRmsdExp\nRmsdExpParameters\n\nExponential RMSD based force parameters.\n\n\nMovingBondHarmonic\nMovingBondHarmonicParameters\n\nHarmonic bond length force that moves at a constant speed\n\n\nHarmonicCv\nHarmonicCVParameters\n\nHarmonic force that is defined on a given CV\n\n\n\n\n\nBondLinearParameters\nParameters for a linear force based on a bond distance.\nBondLinearParameters\n ├ index1\n ├ index2\n ├ slope\n └ offset\n\n\n\n\n\n\n\n\n\nName\nType\nDefault\nDescription\n\n\n\n\nindex1\nint\n\nAtom index of the first atom defining the bond length.\n\n\nindex2\nint\n\nAtom index of the first atom defining the bond length.\n\n\nslope\nfloat\n\nSlope of the linear potential, i.e. k in k * (distance - offset).\n\n\noffset\nfloat\n\nOffset of the linear potential.\n\n\n\n\n\nRmsdExpParameters\nParameters for a force equal to the exponential of the RMSD between a subset of atoms and a reference set of positions.\nRmsdExpParameters\n ├ reference_positions\n ├ atom_indices\n ├ height\n ├ sigma\n └ offset\n\n\n\n\n\n\n\n\n\nName\nType\nDefault\nDescription\n\n\n\n\nreference_positions\nlist&lt;float&gt;\n\nThe reference positions from which to measure the RMSD, as a flat list of coordinates x1, y1, z1, x2, y2, z2, …\n\n\natom_indices\nlist&lt;int&gt;\n\nThe atom indices used to measure the RMSD. The length of the reference positions list should be exactly 3 times the length of this list.\n\n\nheight\nfloat\n\nHeight parameter of the exponential function, i.e. h in the formula h * exp(-0.5 * (rmsd - offset)^2 / sigma).\n\n\nsigma\nfloat\n\nSigma parameter of the exponential function.\n\n\noffset\nfloat\n\nOffset parameter of the exponential function.\n\n\n\n\n\nMovingHarmonicBondParameters\nParameters for a harmonic force based on a bond length that moves at a constant speed between to given lengths.\nMovingHarmonicBondParameters\n ├ index1\n ├ index2\n ├ k\n ├ initial_offset_nm\n ├ final_offset_nm\n ├ resolution_nm\n └ rate_nm_per_ps\n\n\n\n\n\n\n\n\n\nName\nType\nDefault\nDescription\n\n\n\n\nindex1\nint\n\nAtom index of the first atom defining the bond length.\n\n\nindex2\nint\n\nAtom index of the first atom defining the bond length.\n\n\nk\nfloat\n\nSlope of the potential, i.e. k in k * (distance - offset)^2.\n\n\ninitial_offset_nm\nfloat\nnull\nInitial offset of the potential. If not provided it will be set to the current bond length at the time when the bias potential becomes active.\n\n\nfinal_offset_nm\nfloat\nnull\nFinal offset of the potential. If not provided it will be set to an estimate of the covalent bond length of the two atoms defined by index1 and index2.\n\n\nresolution_nm\nfloat\n0.01\nThe resolution at which to update the offset.\n\n\nrate_nm_per_ps\nfloat\n\nThe speed at which the offset will “move”.\n\n\n\n\n\nHarmonicCVParameters\nParameters for a harmonic force that is defined by and acts upon a given collective variable.\nHarmonicCVParameters\n ├ k\n ├ offset\n └ cv\n\n\n\n\n\n\n\n\n\nName\nType\nDefault\nDescription\n\n\n\n\nk\nfloat\n\nSlope of the potential, i.e. k in k * (cv_value - offset)^2.\n\n\noffset\nfloat\n\nOffset for the potential.\n\n\ncv\nCV\n\nThe collective variable that defines the force.\n\n\n\n\n\nBiasSchedule\nSchedule for when in the simulation to activate and deactivate the bias potentials defined in the parameters.\nRmsdExpParameters\n ├ active_potentials\n └ triggers\n\n\n\n\n\n\n\n\n\nName\nType\nDefault\nDescription\n\n\n\n\nactive_potentials\nlist&lt;list&lt;int&gt;&gt;\n\nThe length of this list is the number of separate phases in the simulation. Each list it contains is the indices of the bias potentials that are active during this phase (all other bias potentials will be turned off). Indices start at 0 and correspond to the order that they appear in the parameters file.\n\n\ntriggers\nlist&lt;list&lt;Trigger&gt;&gt;\n\nEach item of this list is a condition that once met will advance the bias schedule to the next phase. Therefore this should have length one less than the length of the active_potentials list. Each list it contains is a list of trigger conditions.\n\n\n\n\n\nTrigger\nTrigger bond condition between two atoms.\nTrigger\n ├ index1\n ├ index2\n └ broken\n\n\n\n\n\n\n\n\n\nName\nType\nDefault\nDescription\n\n\n\n\nindex1\nint\n\nAtom index of the first atom defining the bond.\n\n\nindex2\nint\n\nAtom index of the second atom defining the bond.\n\n\nbroken\nbool\nfalse\nWhether the condition is defined by breaking instead of forming the bond.\n\n\n\n\n\nTerminationCondition\nDescription of if and when to terminate the simulation early.\nTerminationCondition\n ├ tail_steps\n └ bonds\n\n\n\n\n\n\n\n\n\nName\nType\nDefault\nDescription\n\n\n\n\ntail_steps\nint\n100\nFor how many steps to continue simulating after the termination condition has been met.\n\n\nbonds\nlist&lt;Trigger&gt;\n\nThe bonds defining the termination condition.\n\n\n\n\n\nFrames\nDefinition of which frames to save from the simulation and what information is contained in the frames. Currently unused.\nFrames\n ├ start\n ├ stop\n └ interval\n\n\n\n\n\n\n\n\n\nName\nType\nDefault\nDescription\n\n\n\n\nstart\nint\n\nFirst step to start recording.\n\n\nstop\nint\n\nLast step to record.\n\n\ninterval\nint\n\nThe interval between steps at which to record.\n\n\n\n\n\nTrajectory\nDescription of the trajectory, in xyz format, that will be recorded from the simulation.\nTrajectory\n ├ interval\n ├ minimisation\n ├ forces\n ├ info\n ├ windowed\n ├ window_size\n └ residues\n\n\n\n\n\n\n\n\n\nName\nType\nDefault\nDescription\n\n\n\n\ninterval\nint\n1\nNumber of steps between recorded xyz frames.\n\n\nminimisation\nbool\nfalse\nWhether or not to include the the minimisation frames in the trajectory. Does nothing for classical minimisation.\n\n\nforces\nstring\n“None”\nWhat forces to record in the xyz frames, if any. Options are “None”, “Dynamics”, “Bias”, “Mtd”.\n\n\ninfo\nbool\nfalse\nWhether to include the step number and system energy in the comment line in the xyz frames.\n\n\nwindowed\nbool\nfalse\nWhether to only record windows around the trigger conditions in the bias schedule, if present.\n\n\nwindow_size\nint\n200\nSize of windows that are recorded (centred on when the frame that the condition triggered).\n\n\nresidues\nlist&lt;ResidueSpecification&gt;\n[]\nWhich specific residues to record. If empty, the whole system is recorded.\n\n\n\n\n\nResidueSpecification\nSpecification of a subset of residues from an input file.\nResidueSpecification\n ├ file_index\n └ residues\n\n\n\n\n\n\n\n\n\nName\nType\nDefault\nDescription\n\n\n\n\nfile_index\nint\n\nIndex of the input file that the residues are in.\n\n\nresidues\nlist&lt;int&gt;\n\nIndices of the residues in the input file.\n\n\n\n\n\nQDXFExport\nParameters for exporting information that can be used as inputs for PBSA calculations.\nQDXFExport\n └ interval\n\n\n\n\n\n\n\n\n\nName\nType\nDefault\nDescription\n\n\n\n\ninterval\nint\n\nNumber of steps between frames that will be recorded.",
    "crumbs": [
      "API Docs",
      "Modules",
      "Dojo"
    ]
  },
  {
    "objectID": "Modules/dojo.html#function-usage",
    "href": "Modules/dojo.html#function-usage",
    "title": "Dojo",
    "section": "Function Usage",
    "text": "Function Usage\nlet\n    options = {\n        simulation = {\n            step_size_ps = 0.001,\n            stages = [\n                {\n                    Nvt = {\n                        temperature_kelvin = 300,\n                        steps = 1000\n                    }\n                }\n            ]\n        },\n        trajectory = {\n            interval = 100,\n            info = true\n        }\n    },\n    dojo = \\protein_trc -&gt; dojo_rex_s default_runspec options [protein_trc] []\nin\n    \\protein_trc -&gt; dojo protein_trc",
    "crumbs": [
      "API Docs",
      "Modules",
      "Dojo"
    ]
  },
  {
    "objectID": "Modules/auto3d.html",
    "href": "Modules/auto3d.html",
    "title": "Auto3d",
    "section": "",
    "text": "The module takes an dict of module-specific options and [TrcObject] representing proteins, prepares those proteins, and outputs them as a new [TRCObject] containing the prepared versions.\n\n\n\noptions: dict\nsmiles: [str] - each str should be a valid SMILES string representing a small molecule\n\n\n\n\n\nsmol_trcs: [TRCObject]\n\n\n\n\nThe options dict has the following fields:\n\n\n\n\n\n\n\n\n\nName\nType\nDefault\nDescription\n\n\n\n\nk\nint\nnone\n(Optional) Output top k structures for each molecule.\n\n\nwindow\nfloat\nnone\n(Optional) Outputs structures whose energies are within \\(x\\) kcal/mol from the lowest energy conformer.\n\n\nmax_confs\nuint\nnone\n(Optional) Maximum number of isomers per SMILES. Defaults to a dynamic value (heavy_atoms - 1).\n\n\nenumerate_tautomer\nbool\nfalse\n(Optional) When true, enumerates tautomers for the input.\n\n\nenumerate_isomer\nbool\ntrue\n(Optional) When true, cis/trans and R/S isomers are enumerated.\n\n\noptimizing_engine\n{\"ANI2x\"\\| \"ANI2xt\" \\| \"AIMNET\"}\n\"AIMNET\"\n(Optional) The engine used for optimization.\n\n\nopt_steps\nuint\n5000\n(Optional) Maximum number of optimization steps.\n\n\nconvergence_threshold\nfloat\n0.003\n(Optional) Optimization is considered converged if maximum force is below this threshold.\n\n\npatience\nuint\n1000\n(Optional) If force does not decrease for patience steps, conformer drops out of optimization loop.\n\n\nthreshold\nfloat\n0.3\n(Optional) If RMSD between two conformers is within this threshold, one is removed as a duplicate.\n\n\nverbose\nbool\nfalse\n(Optional) When true, saves all metadata while running.\n\n\ncapacity\nuint\n40\n(Optional) Number of SMILES the model handles per 1GB of memory.\n\n\nbatchsize_atoms\nuint\n1024\n(Optional) Number of atoms in one optimization batch per 1GB memory.\n\n\n\n\n\n\nlet\n    auto3d = \\smi -&gt; map to_data (get 0 (\n        auto3d_rex_s default_runspec_gpu { k = 1, optimizing_engine = \"ANI2xt\" } [smi]\n    ))\nin\n    \\smi -&gt; \n        let \n            smol_trcobj = auto3d smi {- outputs the smol conformer TRCObj -}\n        in\n            {- do something with the result here :) -}",
    "crumbs": [
      "API Docs",
      "Modules",
      "Auto3d"
    ]
  },
  {
    "objectID": "Modules/auto3d.html#module-specification",
    "href": "Modules/auto3d.html#module-specification",
    "title": "Auto3d",
    "section": "",
    "text": "The module takes an dict of module-specific options and [TrcObject] representing proteins, prepares those proteins, and outputs them as a new [TRCObject] containing the prepared versions.\n\n\n\noptions: dict\nsmiles: [str] - each str should be a valid SMILES string representing a small molecule\n\n\n\n\n\nsmol_trcs: [TRCObject]\n\n\n\n\nThe options dict has the following fields:\n\n\n\n\n\n\n\n\n\nName\nType\nDefault\nDescription\n\n\n\n\nk\nint\nnone\n(Optional) Output top k structures for each molecule.\n\n\nwindow\nfloat\nnone\n(Optional) Outputs structures whose energies are within \\(x\\) kcal/mol from the lowest energy conformer.\n\n\nmax_confs\nuint\nnone\n(Optional) Maximum number of isomers per SMILES. Defaults to a dynamic value (heavy_atoms - 1).\n\n\nenumerate_tautomer\nbool\nfalse\n(Optional) When true, enumerates tautomers for the input.\n\n\nenumerate_isomer\nbool\ntrue\n(Optional) When true, cis/trans and R/S isomers are enumerated.\n\n\noptimizing_engine\n{\"ANI2x\"\\| \"ANI2xt\" \\| \"AIMNET\"}\n\"AIMNET\"\n(Optional) The engine used for optimization.\n\n\nopt_steps\nuint\n5000\n(Optional) Maximum number of optimization steps.\n\n\nconvergence_threshold\nfloat\n0.003\n(Optional) Optimization is considered converged if maximum force is below this threshold.\n\n\npatience\nuint\n1000\n(Optional) If force does not decrease for patience steps, conformer drops out of optimization loop.\n\n\nthreshold\nfloat\n0.3\n(Optional) If RMSD between two conformers is within this threshold, one is removed as a duplicate.\n\n\nverbose\nbool\nfalse\n(Optional) When true, saves all metadata while running.\n\n\ncapacity\nuint\n40\n(Optional) Number of SMILES the model handles per 1GB of memory.\n\n\nbatchsize_atoms\nuint\n1024\n(Optional) Number of atoms in one optimization batch per 1GB memory.\n\n\n\n\n\n\nlet\n    auto3d = \\smi -&gt; map to_data (get 0 (\n        auto3d_rex_s default_runspec_gpu { k = 1, optimizing_engine = \"ANI2xt\" } [smi]\n    ))\nin\n    \\smi -&gt; \n        let \n            smol_trcobj = auto3d smi {- outputs the smol conformer TRCObj -}\n        in\n            {- do something with the result here :) -}",
    "crumbs": [
      "API Docs",
      "Modules",
      "Auto3d"
    ]
  },
  {
    "objectID": "Modules/prepare_protein.html",
    "href": "Modules/prepare_protein.html",
    "title": "Prepare Protein",
    "section": "",
    "text": "The module takes an dict of module-specific options and a list of TRC tuples representing proteins, prepares those proteins, and outputs them as a new list of TRC tuples.\n\n\n\noptions: dict\nprotein_trcs: [TRC]\n\n\n\n\n\nprepped_protein_trcs: [TRC]\n\n\n\n\nThe options dict has the following fields:\n\n\n\n\n\n\n\n\n\nName\nType\nDefault\nDescription\n\n\n\n\nph\nOption&lt;float&gt;\n7.0\nThe pH to perform the hydrogen atom assignment at.\n\n\nnaming_scheme\nOption&lt;str&gt;\n\"Amber\"\nWhat naming scheme to use for the amino acids. Stick with none for standardized names, or use “Amber” or “Charmm” if the outputs will be used for MD simulation using that force field.\n\n\ntruncation_threshold\nOption&lt;uint&gt;\n2\nAdding long sequences of amino acids to the end of chains isn’t an accurate procedure. If this many or more are missing from the end of a chain, don’t add amino acids to that end.\n\n\ncapping_style\nOption&lt;str&gt;\n\"Truncated\"\nWhether to add caps at the ends of the protein chains. Generally good for MD, but if the chain is totally complete, may not be necessary. One of: “Never”, “Truncated”, “Always”.",
    "crumbs": [
      "API Docs",
      "Modules",
      "Prepare Protein"
    ]
  },
  {
    "objectID": "Modules/prepare_protein.html#module-specification",
    "href": "Modules/prepare_protein.html#module-specification",
    "title": "Prepare Protein",
    "section": "",
    "text": "The module takes an dict of module-specific options and a list of TRC tuples representing proteins, prepares those proteins, and outputs them as a new list of TRC tuples.\n\n\n\noptions: dict\nprotein_trcs: [TRC]\n\n\n\n\n\nprepped_protein_trcs: [TRC]\n\n\n\n\nThe options dict has the following fields:\n\n\n\n\n\n\n\n\n\nName\nType\nDefault\nDescription\n\n\n\n\nph\nOption&lt;float&gt;\n7.0\nThe pH to perform the hydrogen atom assignment at.\n\n\nnaming_scheme\nOption&lt;str&gt;\n\"Amber\"\nWhat naming scheme to use for the amino acids. Stick with none for standardized names, or use “Amber” or “Charmm” if the outputs will be used for MD simulation using that force field.\n\n\ntruncation_threshold\nOption&lt;uint&gt;\n2\nAdding long sequences of amino acids to the end of chains isn’t an accurate procedure. If this many or more are missing from the end of a chain, don’t add amino acids to that end.\n\n\ncapping_style\nOption&lt;str&gt;\n\"Truncated\"\nWhether to add caps at the ends of the protein chains. Generally good for MD, but if the chain is totally complete, may not be necessary. One of: “Never”, “Truncated”, “Always”.",
    "crumbs": [
      "API Docs",
      "Modules",
      "Prepare Protein"
    ]
  },
  {
    "objectID": "Modules/prepare_protein.html#function-usage",
    "href": "Modules/prepare_protein.html#function-usage",
    "title": "Prepare Protein",
    "section": "Function usage",
    "text": "Function usage\nlet\n    options = {\n        ph = some 7.4,\n        naming_scheme = some \"Amber\"\n    },\n    prepare_protein = \\protein_conformer_trc -&gt; \n        map to_data (get 0 (\n            prepare_protein_rex_s default_runspec options [protein_conformer_trc]\n        ))\nin\n    \\unprepped_trc -&gt; prepare_protein unprepped_trc {- outputs the prepped TRCObject -}",
    "crumbs": [
      "API Docs",
      "Modules",
      "Prepare Protein"
    ]
  },
  {
    "objectID": "Modules/rxdock.html",
    "href": "Modules/rxdock.html",
    "title": "RxDock",
    "section": "",
    "text": "Inputs\n\noptions: dict\nprotein_trcs: [TRC], the proteins to dock the smols onto.\nsmol_trcs: [TRC], to dock all against each protein.\n\n\n\nOptions\n\n\n\n\n\n\n\n\n\nParameter\nType\nDefault\nDescription\n\n\n\n\nn_runs\nOption&lt;int&gt;\n1\nNumber of docking attempts per ligand.\n\n\nradius\nOption&lt;float&gt;\n10.0\nRadius of the cavity mapping region (in Å).\n\n\nmin_volume\nOption&lt;float&gt;\n100.0\nMinimum cavity volume to accept (in Å³, not grid points).\n\n\nsmall_sphere\nOption&lt;float&gt;\n1.0\nRadius of the small probe (in Å).\n\n\n\n\n\nFunction usage for benchmarking\nThis workflow incorporates RxDock as the docking software in the benchmark runs.\n\nfrom rush import build_blocking_provider\n\n\nclient = build_blocking_provider(\n    access_token=PUT_YOUR_TOKEN_HERE,\n    url = RUSH_URL,\n    # for example, if your token is 00000000-dddd-cccc-0000-11111111,\n    # then you should put access_token=\"00000000-dddd-cccc-0000-11111111\"\n    # (including the double quotes)\n)\nbenchmark = client.benchmark(name=\"OpenFF CDK2 RMSD17 Benchmark\")\n\n2025-02-07 10:49:09,515 - rush - INFO - Not restoring by default via env\n\n\n\n\nlet\n    auto3d = \\smi -&gt;  map to_data (get 0 (auto3d_rex_s default_runspec_gpu { k = 1 } [smi])),\n\n    rxdock_options = {\n            n_runs = 1,\n            radius = 8.0,\n            min_volumn = none,\n            small_sphere = none\n        },\n\n    rxdock = \\protein_conformer_trc -&gt; \\small_molecule_conformer_tr -&gt;\n            rxdock_rex_s default_runspec rxdock_options protein_conformer_trc small_molecule_conformer_tr none,\n\n    prepare_protein_options = {\n        truncation_threshold = none,\n        capping_style = some 'Never',\n        naming_scheme = some 'Amber',\n        ph = some 7.4\n    },\n\n    prepare_protein = \\protein_conformer_trc -&gt; \n        map to_data (get 0 ( prepare_protein_rex_s default_runspec prepare_protein_options [protein_conformer_trc] ))\n\nin\n\\input -&gt;\n    let\n        \n        protein = load (id (get 0 input)) 'ProteinConformer',\n        protein_structure = load (structure_id protein) 'Structure',\n        protein_trc = [\n            topology protein_structure,\n            residues protein_structure,\n            chains protein_structure\n        ],\n        prepare_protein_result =  prepare_protein protein_trc ,\n        \n        prepared_trc = [ \n            get 0 (prepare_protein_result), \n            get 1 (prepare_protein_result), \n            get 2 (prepare_protein_result) \n        ],\n\n        smol_id = id (get 1 input),\n        smiles = smi (load smol_id 'Smol'),\n        smol_structure = auto3d smiles,\n        \n        docked_result = rxdock prepared_trc [smol_structure],\n        \n        min_affinity =  get \"score\" ( get 2 ( get 0 (get \"Ok\" (get 0 docked_result)))),\n\n        binding_affinity = BindingAffinity {\n            affinity = min_affinity,\n            affinity_metric = 'kcal/mol',\n            protein_id = protein_id protein,\n            smol_id = smol_id,\n            metadata = Metadata {\n                name = \"blah\",\n                description = none,\n                tags = []\n            }\n        }\n    in\n        [BenchmarkArg {\n            entity = \"BindingAffinity\",\n            id = save binding_affinity\n        }]\n\n\n\nsubmission = client.run_benchmark(\n    benchmark.id, \n    rex_code_above, \n    \"rxdock w prepare protein\", \n    sample=0.01)\n\nView your submission at https://rush-qdx-2-staging.web.app/project/07c7d14a-3a55-491c-ab50-65cca07ec7a0/runs?selectedRunId=7e04a1e2-674d-433c-b18f-502b9233d2c1",
    "crumbs": [
      "API Docs",
      "Modules",
      "RxDock"
    ]
  }
]